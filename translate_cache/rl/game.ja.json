{
 "<h1>Atari wrapper with multi-processing</h1>\n": "<h1>\u30de\u30eb\u30c1\u30d7\u30ed\u30bb\u30c3\u30b7\u30f3\u30b0\u6a5f\u80fd\u3092\u5099\u3048\u305f Atari \u30e9\u30c3\u30d1\u30fc</h1>\n",
 "<h2>Worker Process</h2>\n<p>Each worker process runs this method</p>\n": "<h2>\u30ef\u30fc\u30ab\u30fc\u30d7\u30ed\u30bb\u30b9</h2>\n<p>\u5404\u30ef\u30fc\u30ab\u30fc\u30d7\u30ed\u30bb\u30b9\u306f\u3053\u306e\u30e1\u30bd\u30c3\u30c9\u3092\u5b9f\u884c\u3057\u307e\u3059</p>\n",
 "<h3>Reset environment</h3>\n<p>Clean up episode info and 4 frame stack</p>\n": "<h3>\u74b0\u5883\u3092\u30ea\u30bb\u30c3\u30c8</h3>\n<p>\u30a8\u30d4\u30bd\u30fc\u30c9\u60c5\u5831\u30684\u30d5\u30ec\u30fc\u30e0\u30b9\u30bf\u30c3\u30af\u306e\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7</p>\n",
 "<h3>Step</h3>\n<p>Executes <span translate=no>_^_0_^_</span> for 4 time steps and  returns a tuple of (observation, reward, done, episode_info).</p>\n<ul><li><span translate=no>_^_1_^_</span>: stacked 4 frames (this frame and frames for last 3 actions) </li>\n<li><span translate=no>_^_2_^_</span>: total reward while the action was executed </li>\n<li><span translate=no>_^_3_^_</span>: whether the episode finished (a life lost) </li>\n<li><span translate=no>_^_4_^_</span>: episode information if completed</li></ul>\n": "<h3>\u30b9\u30c6\u30c3\u30d7</h3>\n<p><span translate=no>_^_0_^_</span>4\u3064\u306e\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u3092\u5b9f\u884c\u3057\u3001(\u89b3\u6e2c\u3001\u5831\u916c\u3001\u5b8c\u4e86\u3001\u30a8\u30d4\u30bd\u30fc\u30c9\u60c5\u5831) \u306e\u30bf\u30d7\u30eb\u3092\u8fd4\u3057\u307e\u3059\u3002</p>\n<ul><li><span translate=no>_^_1_^_</span>: 4 \u3064\u306e\u30d5\u30ec\u30fc\u30e0\u3092\u7a4d\u307f\u91cd\u306d\u305f (\u3053\u306e\u30d5\u30ec\u30fc\u30e0\u3068\u6700\u5f8c\u306e 3 \u30a2\u30af\u30b7\u30e7\u30f3\u306e\u30d5\u30ec\u30fc\u30e0)</li>\n<li><span translate=no>_^_2_^_</span>: \u30a2\u30af\u30b7\u30e7\u30f3\u5b9f\u884c\u4e2d\u306e\u5831\u916c\u306e\u5408\u8a08</li>\n<li><span translate=no>_^_3_^_</span>: \u30a8\u30d4\u30bd\u30fc\u30c9\u304c\u7d42\u308f\u3063\u305f\u304b\u3069\u3046\u304b (\u547d\u304c\u5931\u308f\u308c\u305f)</li>\n</ul><li><span translate=no>_^_4_^_</span>: \u30a8\u30d4\u30bd\u30fc\u30c9\u60c5\u5831 (\u5b8c\u4e86\u3057\u305f\u5834\u5408)</li>\n",
 "<h4>Process game frames</h4>\n<p>Convert game frames to gray and rescale to 84x84</p>\n": "<h4>\u30b2\u30fc\u30e0\u30d5\u30ec\u30fc\u30e0\u306e\u51e6\u7406</h4>\n<p>\u30b2\u30fc\u30e0\u30d5\u30ec\u30fc\u30e0\u3092\u30b0\u30ec\u30fc\u306b\u5909\u63db\u3057\u300184x84\u306b\u518d\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</p>\n",
 "<p> <a id=\"GameEnvironment\"></a></p>\n<h2>Game environment</h2>\n<p>This is a wrapper for OpenAI gym game environment. We do a few things here:</p>\n<p>1. Apply the same action on four frames and get the last frame 2. Convert observation frames to gray and scale it to (84, 84) 3. Stack four frames of the last four actions 4. Add episode information (total reward for the entire episode) for monitoring 5. Restrict an episode to a single life (game has 5 lives, we reset after every single life)</p>\n<h4>Observation format</h4>\n<p>Observation is tensor of size (4, 84, 84). It is four frames (images of the game screen) stacked on first axis. i.e, each channel is a frame.</p>\n": "<p><a id=\"GameEnvironment\"></a></p>\n<h2>\u30b2\u30fc\u30e0\u74b0\u5883</h2>\n<p>\u3053\u308c\u306fOpenAI\u30b8\u30e0\u30b2\u30fc\u30e0\u74b0\u5883\u306e\u30e9\u30c3\u30d1\u30fc\u3067\u3059\u3002\u3053\u3053\u3067\u306f\u3044\u304f\u3064\u304b\u306e\u3053\u3068\u3092\u884c\u3044\u307e\u3059\u3002</p>\n<p>1\u30024 \u3064\u306e\u30d5\u30ec\u30fc\u30e0\u306b\u540c\u3058\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u9069\u7528\u3057\u3001\u6700\u5f8c\u306e\u30d5\u30ec\u30fc\u30e0 2 \u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\u89b3\u6e2c\u30d5\u30ec\u30fc\u30e0\u3092\u30b0\u30ec\u30fc\u306b\u5909\u63db\u3057\u3001(84\u300184) 3 \u306b\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3057\u307e\u3059\u3002\u6700\u5f8c\u306e4\u3064\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u30924\u30d5\u30ec\u30fc\u30e0\u91cd\u306d\u308b 4.\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0\u7528\u306e\u30a8\u30d4\u30bd\u30fc\u30c9\u60c5\u5831 (\u30a8\u30d4\u30bd\u30fc\u30c9\u5168\u4f53\u306e\u5831\u916c\u7dcf\u984d) \u3092\u8ffd\u52a0 5.\u30a8\u30d4\u30bd\u30fc\u30c9\u30921\u3064\u306e\u30e9\u30a4\u30d5\u306b\u5236\u9650\u3057\u307e\u3059\uff08\u30b2\u30fc\u30e0\u306b\u306f\u30e9\u30a4\u30d5\u304c5\u3064\u3042\u308a\u3001\u30e9\u30a4\u30d5\u304c1\u3064\u5897\u3048\u308b\u305f\u3073\u306b\u30ea\u30bb\u30c3\u30c8\u3055\u308c\u307e\u3059</p>\uff09\n<h4>\u89b3\u6e2c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</h4>\n<p>\u89b3\u6e2c\u5024\u306f\u30b5\u30a4\u30ba (4, 84, 84) \u306e\u30c6\u30f3\u30bd\u30eb\u3067\u3059\u3002\u6700\u521d\u306e\u8ef8\u306b\u7a4d\u307f\u91cd\u306d\u3089\u308c\u305f4\u3064\u306e\u30d5\u30ec\u30fc\u30e0\uff08\u30b2\u30fc\u30e0\u753b\u9762\u306e\u753b\u50cf\uff09\u3067\u3059\u3002\u3064\u307e\u308a\u3001\u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u306f\u30d5\u30ec\u30fc\u30e0\u3067\u3059</p>\u3002\n",
 "<p> Creates a new worker and runs it in a separate process.</p>\n": "<p>\u65b0\u3057\u3044\u30ef\u30fc\u30ab\u30fc\u3092\u4f5c\u6210\u3057\u3001\u5225\u306e\u30d7\u30ed\u30bb\u30b9\u3067\u5b9f\u884c\u3057\u307e\u3059\u3002</p>\n",
 "<p>and number of lives left </p>\n": "<p>\u305d\u3057\u3066\u6b8b\u3055\u308c\u305f\u547d\u306e\u6570</p>\n",
 "<p>buffer to keep the maximum of last 2 frames </p>\n": "<p>\u6700\u5f8c\u306e 2 \u30d5\u30ec\u30fc\u30e0\u307e\u3067\u4fdd\u5b58\u3059\u308b\u30d0\u30c3\u30d5\u30a1</p>\n",
 "<p>create environment </p>\n": "<p>\u74b0\u5883\u3092\u4f5c\u6210</p>\n",
 "<p>create game </p>\n": "<p>\u30b2\u30fc\u30e0\u4f5c\u6210</p>\n",
 "<p>execute the action in the OpenAI Gym environment </p>\n": "<p>OpenAI \u30b8\u30e0\u74b0\u5883\u3067\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b</p>\n",
 "<p>get number of lives left </p>\n": "<p>\u6b8b\u308a\u30e9\u30a4\u30d5\u6570\u3092\u53d6\u5f97</p>\n",
 "<p>get the max of last two frames </p>\n": "<p>\u6700\u5f8c\u306e 2 \u30d5\u30ec\u30fc\u30e0\u306e\u6700\u5927\u5024\u3092\u53d6\u5f97</p>\n",
 "<p>if finished, set episode information if episode is over, and reset </p>\n": "<p>\u7d42\u4e86\u3057\u305f\u3089\u3001\u30a8\u30d4\u30bd\u30fc\u30c9\u304c\u7d42\u4e86\u3057\u305f\u3089\u30a8\u30d4\u30bd\u30fc\u30c9\u60c5\u5831\u3092\u8a2d\u5b9a\u3057\u3001\u30ea\u30bb\u30c3\u30c8\u3057\u307e\u3059</p>\n",
 "<p>keep track of the episode rewards </p>\n": "<p>\u30a8\u30d4\u30bd\u30fc\u30c9\u306e\u5831\u916c\u3092\u628a\u63e1\u3057\u3066\u304a\u3051</p>\n",
 "<p>maintain rewards for each step </p>\n": "<p>\u5404\u30b9\u30c6\u30c3\u30d7\u306e\u5831\u916c\u3092\u7dad\u6301</p>\n",
 "<p>push it to the stack of 4 frames </p>\n": "<p>4\u30d5\u30ec\u30fc\u30e0\u306e\u30b9\u30bf\u30c3\u30af\u306b\u30d7\u30c3\u30b7\u30e5</p>\n",
 "<p>reset OpenAI Gym environment </p>\n": "<p>OpenAI \u30b8\u30e0\u74b0\u5883\u3092\u30ea\u30bb\u30c3\u30c8</p>\n",
 "<p>reset caches </p>\n": "<p>\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u30ea\u30bb\u30c3\u30c8</p>\n",
 "<p>reset if a life is lost </p>\n": "<p>\u547d\u304c\u5931\u308f\u308c\u305f\u3089\u30ea\u30bb\u30c3\u30c8</p>\n",
 "<p>run for 4 steps </p>\n": "<p>4 \u30b9\u30c6\u30c3\u30d7\u5b9f\u884c</p>\n",
 "<p>tensor for a stack of 4 frames </p>\n": "<p>4\u30d5\u30ec\u30fc\u30e0\u306e\u30b9\u30bf\u30c3\u30af\u306e\u30c6\u30f3\u30bd\u30eb</p>\n",
 "<p>wait for instructions from the connection and execute them </p>\n": "<p>\u63a5\u7d9a\u304b\u3089\u306e\u6307\u793a\u3092\u5f85\u3063\u3066\u5b9f\u884c\u3059\u308b</p>\n",
 "Atari wrapper with multi-processing": "\u30de\u30eb\u30c1\u30d7\u30ed\u30bb\u30c3\u30b7\u30f3\u30b0\u6a5f\u80fd\u3092\u5099\u3048\u305f Atari \u30e9\u30c3\u30d1\u30fc",
 "This implements the Atari games with multi-processing.": "\u3053\u308c\u306b\u3088\u308a\u3001Atari\u306e\u30b2\u30fc\u30e0\u304c\u30de\u30eb\u30c1\u30d7\u30ed\u30bb\u30c3\u30b7\u30f3\u30b0\u3067\u5b9f\u88c5\u3055\u308c\u307e\u3059\u3002"
}