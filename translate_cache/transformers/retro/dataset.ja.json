{
 "<h1>RETRO training dataset</h1>\n<p>We pre-retrieve nearest neighbors from the <a href=\"database.html\">key-value database</a>  and create the dataset to train the <a href=\"index.html\">RETRO</a>  <a href=\"model.html\">model</a>.</p>\n": "<h1>RETRO \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8</h1>\n<p><a href=\"database.html\">\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304b\u3089\u6700\u3082\u8fd1\u3044\u8fd1\u508d\u3092\u4e8b\u524d\u306b\u53d6\u5f97\u3057</a><a href=\"index.html\"><a href=\"model.html\">\u3001RETRO \u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u305f\u3081\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</a></a></p>\n",
 "<h2>Build the dataset</h2>\n<ul><li><span translate=no>_^_0_^_</span> is the chunk length </li>\n<li><span translate=no>_^_1_^_</span> is the number of chunks per training sample </li>\n<li><span translate=no>_^_2_^_</span> is the maximum number of characters to skip between two samples.  We skip a few characters between samples to make sure the samples  aren&#x27;t aligned perfectly with the chunks in the <a href=\"database.html\">database</a></li></ul>\n": "<h2>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u69cb\u7bc9</h2>\n<ul><li><span translate=no>_^_0_^_</span>\u306f\u30c1\u30e3\u30f3\u30af\u306e\u9577\u3055\u3067\u3059</li>\n<li><span translate=no>_^_1_^_</span>\u306f\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b5\u30f3\u30d7\u30eb\u3042\u305f\u308a\u306e\u30c1\u30e3\u30f3\u30af\u6570\u3067\u3059</li>\n<li><span translate=no>_^_2_^_</span>2 \u3064\u306e\u30b5\u30f3\u30d7\u30eb\u9593\u3067\u30b9\u30ad\u30c3\u30d7\u3059\u308b\u6700\u5927\u6587\u5b57\u6570\u3067\u3059\u3002</li></ul><a href=\"database.html\">\u30b5\u30f3\u30d7\u30eb\u304c\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u5185\u306e\u30c1\u30e3\u30f3\u30af\u3068\u5b8c\u5168\u306b\u4e00\u81f4\u3057\u3066\u3044\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u305f\u3081\u306b\u3001\u30b5\u30f3\u30d7\u30eb\u9593\u3092\u6570\u6587\u5b57\u30b9\u30ad\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002</a>\n",
 "<h2>Dataset</h2>\n<p>This is the PyTorch dataset that loads the dataset created by <span translate=no>_^_0_^_</span>.</p>\n": "<h2>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8</h2>\n<p>\u3053\u308c\u306f\u3001\u306b\u3088\u3063\u3066\u4f5c\u6210\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30ed\u30fc\u30c9\u3059\u308b PyTorch \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u3059\u3002<span translate=no>_^_0_^_</span></p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> Get a sample</p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u3092\u5165\u624b</p>\n",
 "<p> Number of samples</p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u6570</p>\n",
 "<p>Add to list of samples </p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u30ea\u30b9\u30c8\u306b\u8ffd\u52a0</p>\n",
 "<p>Break it into chunks </p>\n": "<p>\u305d\u308c\u3092\u30c1\u30e3\u30f3\u30af\u306b\u5206\u5272\u3057\u3066\u304f\u3060\u3055\u3044</p>\n",
 "<p>Collect the offset </p>\n": "<p>\u30aa\u30d5\u30bb\u30c3\u30c8\u306e\u53ce\u96c6</p>\n",
 "<p>Cursor for the text </p>\n": "<p>\u30c6\u30ad\u30b9\u30c8\u7528\u306e\u30ab\u30fc\u30bd\u30eb</p>\n",
 "<p>For samples </p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u7528</p>\n",
 "<p>Get neighbor texts. The neighbor length is twice the <span translate=no>_^_0_^_</span> </p>\n": "<p>\u8fd1\u6240\u306e\u4eba\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u53d6\u5f97.\u8fd1\u508d\u306e\u9577\u3055\u306f 2 \u500d\u3067\u3059</p>\u3002<span translate=no>_^_0_^_</span>\n",
 "<p>Get the sample </p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u3092\u5165\u624b</p>\n",
 "<p>Get the sample including an extra character (for prediction) </p>\n": "<p>\u8ffd\u52a0\u6587\u5b57\u3092\u542b\u3080\u30b5\u30f3\u30d7\u30eb\u3092\u53d6\u5f97 (\u4e88\u6e2c\u7528)</p>\n",
 "<p>Increment the cursor </p>\n": "<p>\u30ab\u30fc\u30bd\u30eb\u3092\u30a4\u30f3\u30af\u30ea\u30e1\u30f3\u30c8\u3057\u3066\u304f\u3060\u3055\u3044</p>\n",
 "<p>Iterate through sample offsets </p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u30aa\u30d5\u30bb\u30c3\u30c8\u3092\u53cd\u5fa9\u51e6\u7406</p>\n",
 "<p>Load the index for retrieving neighbors </p>\n": "<p>\u8fd1\u508d\u691c\u7d22\u7528\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u8aad\u307f\u8fbc\u3080</p>\n",
 "<p>Load the samples </p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u3092\u8aad\u307f\u8fbc\u3080</p>\n",
 "<p>Load the text file </p>\n": "<p>\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080</p>\n",
 "<p>Retrieve nearest neighbors </p>\n": "<p>\u6700\u3082\u8fd1\u3044\u8fd1\u508d\u3092\u691c\u7d22\u3059\u308b</p>\n",
 "<p>Save the samples in JSON. We don&#x27;t need to use complex dataset storage mechanisms or pre-tokenize since our dataset is small. </p>\n": "<p>\u30b5\u30f3\u30d7\u30eb\u3092 JSON \u3067\u4fdd\u5b58\u3057\u307e\u3059\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u5c0f\u3055\u3044\u305f\u3081\u3001\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4fdd\u5b58\u30e1\u30ab\u30cb\u30ba\u30e0\u3092\u4f7f\u7528\u3057\u305f\u308a\u3001\u4e8b\u524d\u306b\u30c8\u30fc\u30af\u30f3\u5316\u3057\u305f\u308a\u3059\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093</p>\u3002\n",
 "<p>Skip a few characters to make sure it&#x27;s not aligned with the neighbors </p>\n": "<p>\u6570\u6587\u5b57\u98db\u3070\u3057\u3066\u3001\u96a3\u306e\u6587\u5b57\u3068\u63c3\u308f\u306a\u3044\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044</p>\n",
 "<p>Stop if we&#x27;ve reached the end of the text </p>\n": "<p>\u30c6\u30ad\u30b9\u30c8\u306e\u7d42\u308f\u308a\u306b\u9054\u3057\u305f\u3089\u6b62\u3081\u3066\u304f\u3060\u3055\u3044</p>\n",
 "<p>The chunk offsets </p>\n": "<p>\u30c1\u30e3\u30f3\u30af\u30aa\u30d5\u30bb\u30c3\u30c8</p>\n",
 "<p>The input </p>\n": "<p>\u30a4\u30f3\u30d7\u30c3\u30c8</p>\n",
 "<p>The input sample offsets </p>\n": "<p>\u5165\u529b\u30b5\u30f3\u30d7\u30eb\u30aa\u30d5\u30bb\u30c3\u30c8</p>\n",
 "<p>Tokenize </p>\n": "<p>\u30c8\u30fc\u30af\u30f3\u5316</p>\n",
 "<p>Training portion of it </p>\n": "<p>\u305d\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u90e8\u5206</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the path of the saved JSON file </li>\n<li><span translate=no>_^_1_^_</span> is the <span translate=no>_^_2_^_</span></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u4fdd\u5b58\u3055\u308c\u305f JSON \u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3067\u3059</li>\n</ul><li><span translate=no>_^_1_^_</span>\u306f <span translate=no>_^_2_^_</span></li>\n",
 "Create a dataset for RETRO model training": "RETRO \u30e2\u30c7\u30eb\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4f5c\u6210",
 "Training dataset for RETRO": "RETRO \u7528\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8"
}