{
 "<h1>Train a <a href=\"index.html\">Vision Transformer (ViT)</a> on CIFAR 10</h1>\n": "<h1>\u5728 CIFA <a href=\"index.html\">R 10 \u4e0a\u8bad\u7ec3\u89c6\u89c9\u53d8\u538b\u5668 (ViT)</a></h1>\n",
 "<h2>Configurations</h2>\n<p>We use <a href=\"../../experiments/cifar10.html\"><span translate=no>_^_0_^_</span></a> which defines all the dataset related configurations, optimizer, and a training loop.</p>\n": "<h2>\u914d\u7f6e</h2>\n<p>\u6211\u4eec\u4f7f\u7528<a href=\"../../experiments/cifar10.html\"><span translate=no>_^_0_^_</span></a>\u5b83\u6765\u5b9a\u4e49\u6240\u6709\u4e0e\u6570\u636e\u96c6\u76f8\u5173\u7684\u914d\u7f6e\u3001\u4f18\u5316\u5668\u548c\u8bad\u7ec3\u5faa\u73af\u3002</p>\n",
 "<h3>Create model</h3>\n": "<h3>\u521b\u5efa\u6a21\u578b</h3>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> Create transformer configs</p>\n": "<p>\u521b\u5efa\u53d8\u538b\u5668\u914d\u7f6e</p>\n",
 "<p><a href=\"../configs.html#TransformerConfigs\">Transformer configurations</a> to get <a href=\"../models.html#TransformerLayer\">transformer layer</a> </p>\n": "<p>\u83b7\u5f97<a href=\"../configs.html#TransformerConfigs\">\u53d8\u538b\u5668<a href=\"../models.html#TransformerLayer\">\u5c42\u7684\u53d8\u538b\u5668</a>\u914d\u7f6e</a></p>\n",
 "<p>Augment CIFAR 10 images for training </p>\n": "<p>\u589e\u5f3a CIFAR 10 \u56fe\u50cf\u7528\u4e8e\u8bad\u7ec3</p>\n",
 "<p>Create a vision transformer </p>\n": "<p>\u521b\u5efa\u89c6\u89c9\u53d8\u538b\u5668</p>\n",
 "<p>Create configurations </p>\n": "<p>\u521b\u5efa\u914d\u7f6e</p>\n",
 "<p>Create experiment </p>\n": "<p>\u521b\u5efa\u5b9e\u9a8c</p>\n",
 "<p>Do not augment CIFAR 10 images for validation </p>\n": "<p>\u4e0d\u8981\u6269\u5927 CIFAR 10 \u56fe\u50cf\u8fdb\u884c\u9a8c\u8bc1</p>\n",
 "<p>Load configurations </p>\n": "<p>\u88c5\u8f7d\u914d\u7f6e</p>\n",
 "<p>Number of classes in the task </p>\n": "<p>\u4efb\u52a1\u4e2d\u7684\u7c7b\u6570</p>\n",
 "<p>Optimizer </p>\n": "<p>\u4f18\u5316\u5668</p>\n",
 "<p>Set model for saving/loading </p>\n": "<p>\u8bbe\u7f6e\u4fdd\u5b58/\u52a0\u8f7d\u7684\u6a21\u578b</p>\n",
 "<p>Size of a patch </p>\n": "<p>\u8865\u4e01\u7684\u5927\u5c0f</p>\n",
 "<p>Size of the hidden layer in classification head </p>\n": "<p>\u5206\u7c7b\u5934\u4e2d\u9690\u85cf\u5c42\u7684\u5927\u5c0f</p>\n",
 "<p>Start the experiment and run the training loop </p>\n": "<p>\u5f00\u59cb\u5b9e\u9a8c\u5e76\u8fd0\u884c\u8bad\u7ec3\u5faa\u73af</p>\n",
 "<p>Training epochs and batch size </p>\n": "<p>\u8bad\u7ec3\u5468\u671f\u548c\u6279\u6b21\u5927\u5c0f</p>\n",
 "<p>Transformer embedding size </p>\n": "<p>\u53d8\u538b\u5668\u5d4c\u5165\u5c3a\u5bf8</p>\n",
 "<p>Transformer size from <a href=\"../configs.html#TransformerConfigs\">Transformer configurations</a> </p>\n": "<p>\u53d8\u538b\u5668<a href=\"../configs.html#TransformerConfigs\">\u914d\u7f6e\u4e2d\u7684\u53d8\u538b\u5668</a>\u5c3a\u5bf8</p>\n",
 "Train a Vision Transformer (ViT) on CIFAR 10": "\u5728 CIFAR 10 \u4e0a\u8bad\u7ec3\u89c6\u89c9\u53d8\u538b\u5668 (ViT)"
}