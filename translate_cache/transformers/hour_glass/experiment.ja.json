{
 "<h1><a href=\"index.html\">Hierarchical Transformers Are More Efficient Language Models</a> Experiment</h1>\n<p>This is an annotated PyTorch experiment to train a <a href=\"index.html\">hourglass</a>.</p>\n<p>This is based on <a href=\"../basic/autoregressive_experiment.html\">training loop and configurations for a simple transformer auto-regressive NLP task</a>.</p>\n": "<h1><a href=\"index.html\">\u968e\u5c64\u578b\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc\u306f\u3088\u308a\u52b9\u7387\u7684\u306a\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u5b9f\u9a13</a></h1>\n<p><a href=\"index.html\">\u3053\u308c\u306f\u3001\u7802\u6642\u8a08\u3092\u8a13\u7df4\u3059\u308b\u305f\u3081\u306e\u6ce8\u91c8\u4ed8\u304d\u306e PyTorch \u5b9f\u9a13\u3067\u3059\u3002</a></p>\n<p>\u3053\u308c\u306f\u3001<a href=\"../basic/autoregressive_experiment.html\">\u5358\u7d14\u306a\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc\u81ea\u5df1\u56de\u5e30NLP\u30bf\u30b9\u30af\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30eb\u30fc\u30d7\u3068\u69cb\u6210\u306b\u57fa\u3065\u3044\u3066\u3044\u307e\u3059</a>\u3002</p>\n",
 "<h2>Autoregressive language model</h2>\n": "<h2>\u81ea\u5df1\u56de\u5e30\u8a00\u8a9e\u30e2\u30c7\u30eb</h2>\n",
 "<h2>Configurations</h2>\n<p>This inherits from <a href=\"../basic/autoregressive_transformer.html\">training loop and configurations for a simple transformer auto-regressive NLP task</a>.</p>\n": "<h2>\u30b3\u30f3\u30d5\u30a3\u30ae\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3</h2>\n<p>\u3053\u308c\u306f\u3001<a href=\"../basic/autoregressive_transformer.html\">\u5358\u7d14\u306a\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc\u81ea\u5df1\u56de\u5e30NLP\u30bf\u30b9\u30af\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30eb\u30fc\u30d7\u3068\u69cb\u6210\u304b\u3089\u7d99\u627f\u3055\u308c\u3066\u3044\u307e\u3059</a>\u3002</p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> Create the model</p>\n": "<p>\u30e2\u30c7\u30eb\u3092\u4f5c\u6210</p>\n",
 "<p><a href=\"../positional_encoding.html\">Fixed positional embeddings</a>.</p>\n<p>\ud83d\udcdd The <a href=\"https://github.com/google/trax/blob/master/trax/models/research/hourglass.py\">official paper implementation</a> use <a href=\"../xl/relative_mha.html\">relative attention</a> </p>\n": "<p><a href=\"../positional_encoding.html\">\u4f4d\u7f6e\u57cb\u3081\u8fbc\u307f\u3092\u4fee\u6b63\u3057\u307e\u3057\u305f</a>\u3002</p>\n<p>\ud83d\udcdd <a href=\"https://github.com/google/trax/blob/master/trax/models/research/hourglass.py\"><a href=\"../xl/relative_mha.html\">\u516c\u5f0f\u8ad6\u6587\u306e\u5b9f\u88c5\u306b\u306f\u6bd4\u8f03\u7684\u6ce8\u610f\u304c\u5fc5\u8981</a></a></p>\n",
 "<p><a href=\"index.html\">hourglass model</a> </p>\n": "<p><a href=\"index.html\">\u7802\u6642\u8a08\u30e2\u30c7\u30eb</a></p>\n",
 "<p>Add <a href=\"../positional_encoding.html\">positional embeddings</a> </p>\n": "<p><a href=\"../positional_encoding.html\">\u4f4d\u7f6e\u57cb\u3081\u8fbc\u307f\u3092\u8ffd\u52a0</a></p>\n",
 "<p>Batch size <span translate=no>_^_0_^_</span> </p>\n": "<p>\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba <span translate=no>_^_0_^_</span></p>\n",
 "<p>Create configs </p>\n": "<p>\u30b3\u30f3\u30d5\u30a3\u30b0\u306e\u4f5c\u6210</p>\n",
 "<p>Create experiment </p>\n": "<p>\u5b9f\u9a13\u3092\u4f5c\u6210</p>\n",
 "<p>Create hourglass model </p>\n": "<p>\u7802\u6642\u8a08\u30e2\u30c7\u30eb\u3092\u4f5c\u6210</p>\n",
 "<p>Create the auto-regressive wrapper </p>\n": "<p>\u81ea\u52d5\u56de\u5e30\u30e9\u30c3\u30d1\u30fc\u306e\u4f5c\u6210</p>\n",
 "<p>Dropout probability </p>\n": "<p>\u8131\u843d\u78ba\u7387</p>\n",
 "<p>Embedding size </p>\n": "<p>\u57cb\u3081\u8fbc\u307f\u30b5\u30a4\u30ba</p>\n",
 "<p>Final linear layer to predict the logits </p>\n": "<p>\u30ed\u30b8\u30c3\u30c8\u3092\u4e88\u6e2c\u3059\u308b\u305f\u3081\u306e\u6700\u5f8c\u306e\u7dda\u5f62\u30ec\u30a4\u30e4\u30fc</p>\n",
 "<p>Get embeddings </p>\n": "<p>\u57cb\u3081\u8fbc\u307f\u3092\u5165\u624b</p>\n",
 "<p>Get logits </p>\n": "<p>\u30ed\u30b8\u30c3\u30c8\u3092\u53d6\u5f97</p>\n",
 "<p>Hourglass </p>\n": "<p>\u7802\u6642\u8a08</p>\n",
 "<p>Model </p>\n": "<p>\u30e2\u30c7\u30eb</p>\n",
 "<p>Number of attention heads </p>\n": "<p>\u30a2\u30c6\u30f3\u30b7\u30e7\u30f3\u30d8\u30c3\u30c9\u306e\u6570</p>\n",
 "<p>Override configurations </p>\n": "<p>\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u8a2d\u5b9a</p>\n",
 "<p>Prompt separator is blank </p>\n": "<p>\u30d7\u30ed\u30f3\u30d7\u30c8\u30bb\u30d1\u30ec\u30fc\u30bf\u304c\u7a7a\u767d</p>\n",
 "<p>Return the logits </p>\n": "<p>\u30ed\u30b8\u30c3\u30c8\u3092\u8fd4\u3059</p>\n",
 "<p>Run training </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u884c</p>\n",
 "<p>Set models for saving and loading </p>\n": "<p>\u4fdd\u5b58\u304a\u3088\u3073\u8aad\u307f\u8fbc\u307f\u7528\u306e\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\u3059\u308b</p>\n",
 "<p>Shortening factors </p>\n": "<p>\u77ed\u7e2e\u8981\u56e0</p>\n",
 "<p>Size of feed-forward hidden layer </p>\n": "<p>\u30d5\u30a3\u30fc\u30c9\u30d5\u30a9\u30ef\u30fc\u30c9\u96a0\u308c\u5c64\u306e\u30b5\u30a4\u30ba</p>\n",
 "<p>Start the experiment </p>\n": "<p>\u5b9f\u9a13\u3092\u59cb\u3081\u308b</p>\n",
 "<p>Starting prompt for sampling </p>\n": "<p>\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u306e\u958b\u59cb\u30d7\u30ed\u30f3\u30d7\u30c8</p>\n",
 "<p>Switch between training and validation for <span translate=no>_^_0_^_</span> times per epoch </p>\n": "<p>\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u691c\u8a3c\u3092\u5207\u308a\u66ff\u3048\u308b <span translate=no>_^_0_^_</span></p>\n",
 "<p>To normalize the final embeddings </p>\n": "<p>\u6700\u7d42\u7684\u306a\u57cb\u3081\u8fbc\u307f\u3092\u6b63\u898f\u5316\u3059\u308b\u306b\u306f</p>\n",
 "<p>Token embedding size </p>\n": "<p>\u30c8\u30fc\u30af\u30f3\u306e\u57cb\u3081\u8fbc\u307f\u30b5\u30a4\u30ba</p>\n",
 "<p>Token embeddings </p>\n": "<p>\u30c8\u30fc\u30af\u30f3\u306e\u57cb\u3081\u8fbc\u307f</p>\n",
 "<p>Train for <span translate=no>_^_0_^_</span> epochs </p>\n": "<p><span translate=no>_^_0_^_</span>\u6642\u4ee3\u306b\u5408\u308f\u305b\u305f\u5217\u8eca</p>\n",
 "<p>Use <a href=\"../../optimizers/noam.html\">Noam optimizer</a> </p>\n": "<p><a href=\"../../optimizers/noam.html\">Noam</a> \u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u3092\u4f7f\u3046</p>\n",
 "<p>Use Tiny Shakespeare dataset </p>\n": "<p>\u30bf\u30a4\u30cb\u30fc\u30fb\u30b7\u30a7\u30a4\u30af\u30b9\u30d4\u30a2\u30fb\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3046</p>\n",
 "<p>Use a context size of <span translate=no>_^_0_^_</span> </p>\n": "<p>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30b5\u30a4\u30ba\u3092\u6b21\u306e\u5024\u306b\u3057\u3066\u304f\u3060\u3055\u3044 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Use character level tokenizer </p>\n": "<p>\u30ad\u30e3\u30e9\u30af\u30bf\u30fc\u30ec\u30d9\u30eb\u306e\u30c8\u30fc\u30af\u30ca\u30a4\u30b6\u30fc\u3092\u4f7f\u3046</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the tensor with token indexes of shape <span translate=no>_^_1_^_</span></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u5f62\u72b6\u306e\u30c8\u30fc\u30af\u30f3\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u304c\u4ed8\u3044\u305f\u30c6\u30f3\u30bd\u30eb\u3067\u3059 <span translate=no>_^_1_^_</span></li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the vocabulary size </li>\n<li><span translate=no>_^_1_^_</span> is the size of the token embeddings </li>\n<li><span translate=no>_^_2_^_</span> is the dropout probability </li>\n<li><span translate=no>_^_3_^_</span> is the <a href=\"index.html\">hourglass model</a></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u306f\u30dc\u30ad\u30e3\u30d6\u30e9\u30ea\u30fc\u30b5\u30a4\u30ba\u3067\u3059</li>\n<li><span translate=no>_^_1_^_</span>\u30c8\u30fc\u30af\u30f3\u306e\u57cb\u3081\u8fbc\u307f\u306e\u30b5\u30a4\u30ba\u3067\u3059</li>\n<li><span translate=no>_^_2_^_</span>\u306f\u8131\u843d\u78ba\u7387\u3067\u3059</li>\n<li><span translate=no>_^_3_^_</span><a href=\"index.html\">\u7802\u6642\u8a08\u30e2\u30c7\u30eb\u3067\u3059</a></li></ul>\n",
 "Hierarchical Transformers Are More Efficient Language Models Experiment": "\u968e\u5c64\u578b\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc\u306f\u3088\u308a\u52b9\u7387\u7684\u306a\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u5b9f\u9a13",
 "This experiment trains a hourglass model on Tiny Shakespeare dataset.": "\u3053\u306e\u5b9f\u9a13\u3067\u306f\u3001Tiny Shakespeare\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u7802\u6642\u8a08\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3059\u3002"
}