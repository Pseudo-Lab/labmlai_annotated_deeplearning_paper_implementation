{
 "<h1>Gated Linear Units and Variants</h1>\n<p>This trains a simple <a href=\"../../\">transformer</a> model for auto-regression. We try different variants for the <a href=\"../feed_forward\">position-wise feedforward network</a>.</p>\n<p><em>This is a simpler implementation that doesn&#x27;t use <a href=\"experiment.html\"><span translate=no>_^_0_^_</span></a> module. We decided to write a simpler implementation to make it easier for readers who are not familiar.</em></p>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/transformers/glu_variants/simple.ipynb\"><span translate=no>_^_1_^_</span></a></p>\n": "<h1>\u95e8\u63a7\u7ebf\u6027\u5355\u5143\u548c\u53d8\u4f53</h1>\n</a><p>\u8fd9\u53ef\u4ee5\u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684<a href=\"../../\">\u53d8\u538b\u5668\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u56de\u5f52\u3002\u6211\u4eec\u4e3a<a href=\"../feed_forward\">\u4f4d\u7f6e\u524d\u9988\u7f51\u7edc</a>\u5c1d\u8bd5\u4e0d\u540c\u7684\u53d8\u4f53\u3002</p>\n<p><em>\u8fd9\u662f\u4e00\u4e2a\u4e0d\u4f7f\u7528<a href=\"experiment.html\"><span translate=no>_^_0_^_</span></a>\u6a21\u5757\u7684\u66f4\u7b80\u5355\u7684\u5b9e\u73b0\u3002\u6211\u4eec\u51b3\u5b9a\u7f16\u5199\u4e00\u4e2a\u66f4\u7b80\u5355\u7684\u5b9e\u73b0\uff0c\u8ba9\u4e0d\u719f\u6089\u7684\u8bfb\u8005\u66f4\u5bb9\u6613\u4f7f\u7528\u3002</em></p>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/transformers/glu_variants/simple.ipynb\"><span translate=no>_^_1_^_</span></a></p>\n",
 "<h2>Auto regressive model</h2>\n": "<h2>\u81ea\u52a8\u56de\u5f52\u6a21\u578b</h2>\n",
 "<h2>Trainer</h2>\n": "<h2>\u8bad\u7ec3\u5e08</h2>\n",
 "<h3>Configurations</h3>\n": "<h3>\u914d\u7f6e</h3>\n",
 "<h3>Sampling function to generate samples periodically while training</h3>\n": "<h3>\u91c7\u6837\u529f\u80fd\u53ef\u5728\u8bad\u7ec3\u65f6\u5b9a\u671f\u751f\u6210\u6837\u672c</h3>\n",
 "<h3>Tiny Shakespeare Dataset</h3>\n": "<h3>\u5c0f\u838e\u58eb\u6bd4\u4e9a\u6570\u636e\u96c6</h3>\n",
 "<h3>Train the model</h3>\n": "<h3>\u8bad\u7ec3\u6a21\u578b</h3>\n",
 "<p> Number of samples in the dataset.</p>\n<p><em>This will read the dataset <span translate=no>_^_0_^_</span> times in a single epoch.</em></p>\n": "<p>\u6570\u636e\u96c6\u4e2d\u7684\u6837\u672c\u6570\u3002</p>\n<p><em>\u8fd9\u5c06\u8bfb\u53d6\u5355\u4e2a\u7eaa\u5143\u4e2d\u7684\u6570\u636e\u96c6<span translate=no>_^_0_^_</span>\u65f6\u95f4\u3002</em></p>\n",
 "<p> Return a sample</p>\n": "<p>\u8fd4\u56de\u6837\u54c1</p>\n",
 "<p> Transform the text into a tensor of ids</p>\n": "<p>\u5c06\u6587\u672c\u8f6c\u6362\u4e3a id \u5f20\u91cf</p>\n",
 "<p>Add the prediction for logging </p>\n": "<p>\u6dfb\u52a0\u65e5\u5fd7\u8bb0\u5f55\u7684\u9884\u6d4b</p>\n",
 "<p>Add the prediction to prompt </p>\n": "<p>\u5c06\u9884\u6d4b\u6dfb\u52a0\u5230\u63d0\u793a\u7b26\u4e2d</p>\n",
 "<p>Calculate gradients </p>\n": "<p>\u8ba1\u7b97\u68af\u5ea6</p>\n",
 "<p>Calculate loss </p>\n": "<p>\u8ba1\u7b97\u635f\u5931</p>\n",
 "<p>Character to id (integer) map </p>\n": "<p>\u5b57\u7b26\u5230 id\uff08\u6574\u6570\uff09\u6620\u5c04</p>\n",
 "<p>Clear the gradients </p>\n": "<p>\u6e05\u9664\u6e10\u53d8</p>\n",
 "<p>Clip gradients </p>\n": "<p>\u526a\u8f91\u6e10\u53d8</p>\n",
 "<p>Collect output for printing </p>\n": "<p>\u6536\u96c6\u8f93\u51fa\u4ee5\u8fdb\u884c\u6253\u5370</p>\n",
 "<p>Create configs </p>\n": "<p>\u521b\u5efa\u914d\u7f6e</p>\n",
 "<p>Create experiment </p>\n": "<p>\u521b\u5efa\u5b9e\u9a8c</p>\n",
 "<p>Create subsequent mask, so that the transformer can only pay attention to past tokens. </p>\n": "<p>\u521b\u5efa\u540e\u7eed\u63a9\u7801\uff0c\u4ee5\u4fbf\u53d8\u538b\u5668\u53ea\u80fd\u5173\u6ce8\u8fc7\u53bb\u7684\u4ee4\u724c\u3002</p>\n",
 "<p>Create trainer </p>\n": "<p>\u521b\u5efa\u8bad\u7ec3\u5668</p>\n",
 "<p>Cross-entropy loss </p>\n": "<p>\u4ea4\u53c9\u71b5\u635f\u5931</p>\n",
 "<p>Data in the form of a tensor of ids </p>\n": "<p>\u4ee5 id \u5f20\u91cf\u5f62\u5f0f\u663e\u793a\u7684\u6570\u636e</p>\n",
 "<p>Download the file </p>\n": "<p>\u4e0b\u8f7d\u8be5\u6587\u4ef6</p>\n",
 "<p>Embed the tokens (<span translate=no>_^_0_^_</span>) and run it through the the transformer </p>\n": "<p>\u5d4c\u5165\u4ee4\u724c (<span translate=no>_^_0_^_</span>) \u5e76\u901a\u8fc7\u53d8\u538b\u5668\u8fd0\u884c\u5b83</p>\n",
 "<p>Evaluate the model </p>\n": "<p>\u8bc4\u4f30\u6a21\u578b</p>\n",
 "<p>Extract the characters </p>\n": "<p>\u63d0\u53d6\u5b57\u7b26</p>\n",
 "<p>FFN with Bilinear hidden layer <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5e26\u53cc\u7ebf\u6027\u9690\u85cf\u5c42\u7684 FFN<span translate=no>_^_0_^_</span></p>\n",
 "<p>FFN with GELU gate <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5e26\u6709 GELU \u95e8\u7684 FFN<span translate=no>_^_0_^_</span></p>\n",
 "<p>FFN with Gated Linear Unit <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5e26\u95e8\u63a7\u7ebf\u6027\u5355\u5143\u7684 FFN<span translate=no>_^_0_^_</span></p>\n",
 "<p>FFN with ReLU activation <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6fc0\u6d3b ReLU \u7684 FFN<span translate=no>_^_0_^_</span></p>\n",
 "<p>FFN with ReLU gate <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5e26\u6709 ReLU \u95e8\u7684 FFN<span translate=no>_^_0_^_</span></p>\n",
 "<p>FFN with Swish gate <span translate=no>_^_0_^_</span> where <span translate=no>_^_1_^_</span> </p>\n": "<p>FFN \u6709 Swish gate<span translate=no>_^_0_^_</span> \u5728\u54ea\u91cc<span translate=no>_^_1_^_</span></p>\n",
 "<p>Generate a sample </p>\n": "<p>\u751f\u6210\u6837\u672c</p>\n",
 "<p>Generate logits of the next token </p>\n": "<p>\u751f\u6210\u4e0b\u4e00\u4e2a\u4ee4\u724c\u7684\u65e5\u5fd7</p>\n",
 "<p>Get the device </p>\n": "<p>\u62ff\u5230\u8bbe\u5907</p>\n",
 "<p>Get the model output </p>\n": "<p>\u83b7\u53d6\u6a21\u578b\u8f93\u51fa</p>\n",
 "<p>Get the model prediction (greedy) </p>\n": "<p>\u83b7\u53d6\u6a21\u578b\u9884\u6d4b\uff08\u8d2a\u5a6a\uff09</p>\n",
 "<p>Gradient clipping norm </p>\n": "<p>\u6e10\u53d8\u526a\u5207\u89c4\u8303</p>\n",
 "<p>Id to character map </p>\n": "<p>\u89d2\u8272\u6620\u5c04\u7684 ID</p>\n",
 "<p>Initialize <a href=\"../../optimizers/noam.html\">Noam optimizer</a> </p>\n": "<p>\u521d\u59cb\u5316 <a href=\"../../optimizers/noam.html\">Noam \u4f18\u5316\u5668</a></p>\n",
 "<p>Initialize <a href=\"../mha.html\">Multi-Head Attention module</a> </p>\n": "<p>\u521d\u59cb\u5316<a href=\"../mha.html\">\u591a\u5934\u6ce8\u610f\u6a21\u5757</a></p>\n",
 "<p>Initialize the <a href=\"../models.html#TransformerLayer\">Transformer Block</a> </p>\n": "<p>\u521d\u59cb\u5316\u53d8<a href=\"../models.html#TransformerLayer\">\u538b\u5668\u6a21\u5757</a></p>\n",
 "<p>Initialize the dataloader </p>\n": "<p>\u521d\u59cb\u5316\u6570\u636e\u52a0\u8f7d\u5668</p>\n",
 "<p>Initialize the dataset </p>\n": "<p>\u521d\u59cb\u5316\u6570\u636e\u96c6</p>\n",
 "<p>Initialize the model with an <a href=\"../models.html#EmbeddingsWithPositionalEncoding\">embedding layer</a> (with fixed positional encoding) <a href=\"../models.html#Encoder\">transformer encoder</a> and a linear layer to generate logits. </p>\n": "\u4f7f\u7528@@ <p><a href=\"../models.html#EmbeddingsWithPositionalEncoding\">\u5d4c\u5165\u5c42</a>\uff08\u5177\u6709\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801\uff09<a href=\"../models.html#Encoder\">\u53d8\u538b\u5668\u7f16\u7801\u5668\u548c</a>\u7ebf\u6027\u5c42\u6765\u521d\u59cb\u5316\u6a21\u578b\u4ee5\u751f\u6210\u5bf9\u6570\u3002</p>\n",
 "<p>Iterate over the minibatches </p>\n": "<p>\u904d\u5386\u8ff7\u4f60\u6279\u6b21</p>\n",
 "<p>Length of a training sample </p>\n": "<p>\u8bad\u7ec3\u6837\u672c\u7684\u957f\u5ea6</p>\n",
 "<p>Load configurations </p>\n": "<p>\u88c5\u8f7d\u914d\u7f6e</p>\n",
 "<p>Location of the text file </p>\n": "<p>\u6587\u672c\u6587\u4ef6\u7684\u4f4d\u7f6e</p>\n",
 "<p>Log the loss </p>\n": "<p>\u8bb0\u5f55\u635f\u5931</p>\n",
 "<p>Log the model parameters and gradients </p>\n": "<p>\u8bb0\u5f55\u6a21\u578b\u53c2\u6570\u548c\u68af\u5ea6</p>\n",
 "<p>Loop for the given number of epochs </p>\n": "<p>\u5faa\u73af\u4f7f\u7528\u7ed9\u5b9a\u6570\u91cf\u7684\u5468\u671f</p>\n",
 "<p>Move data to the device </p>\n": "<p>\u5c06\u6570\u636e\u79fb\u52a8\u5230\u8bbe\u5907</p>\n",
 "<p>Move the model to the current device </p>\n": "<p>\u5c06\u6a21\u578b\u79fb\u81f3\u5f53\u524d\u8bbe\u5907</p>\n",
 "<p>Next token generation layer; this gives logits of the the next token </p>\n": "<p>\u4e0b\u4e00\u4ee3\u5e01\u751f\u6210\u5c42\uff1b\u8fd9\u7ed9\u51fa\u4e86\u4e0b\u4e00\u4e2a\u4ee4\u724c\u7684\u65e5\u5fd7</p>\n",
 "<p>Number of different characters </p>\n": "<p>\u4e0d\u540c\u5b57\u7b26\u7684\u6570\u91cf</p>\n",
 "<p>Number of training epochs; <em>note that our dataset definition repeats the data <span translate=no>_^_0_^_</span> times in a single epoch</em> </p>\n": "<p>\u8bad\u7ec3\u5468\u671f\u7684\u6570\u91cf\uff1b<em>\u8bf7\u6ce8\u610f\uff0c\u6211\u4eec\u7684\u6570\u636e\u96c6\u5b9a\u4e49\u5728\u5355\u4e2a\u7eaa\u5143\u4e2d\u91cd\u590d\u6570\u636e<span translate=no>_^_0_^_</span>\u65f6\u95f4</em></p>\n",
 "<p>Print the sampled output </p>\n": "<p>\u6253\u5370\u91c7\u6837\u8f93\u51fa</p>\n",
 "<p>Read the downloaded file </p>\n": "<p>\u8bfb\u53d6\u4e0b\u8f7d\u7684\u6587\u4ef6</p>\n",
 "<p>Sample 25 tokens </p>\n": "<p>\u6837\u672c 25 \u4e2a\u4ee3\u5e01</p>\n",
 "<p>Save the model </p>\n": "<p>\u4fdd\u5b58\u6a21\u578b</p>\n",
 "<p>Save the tracked metrics </p>\n": "<p>\u4fdd\u5b58\u8ddf\u8e2a\u7684\u6307\u6807</p>\n",
 "<p>Set model state to training </p>\n": "<p>\u5c06\u6a21\u578b\u72b6\u6001\u8bbe\u7f6e\u4e3a\u8bad\u7ec3</p>\n",
 "<p>Set models for training and loading </p>\n": "<p>\u8bbe\u7f6e\u7528\u4e8e\u8bad\u7ec3\u548c\u52a0\u8f7d\u7684\u6a21\u578b</p>\n",
 "<p>Set tracker configurations </p>\n": "<p>\u8bbe\u7f6e\u8ddf\u8e2a\u5668\u914d\u7f6e</p>\n",
 "<p>Set tracker step, as the number of characters trained on </p>\n": "<p>\u5c06\u8ddf\u8e2a\u5668\u6b65\u957f\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u7684\u5b57\u7b26\u6570</p>\n",
 "<p>Start the experiment </p>\n": "<p>\u5f00\u59cb\u5b9e\u9a8c</p>\n",
 "<p>Starting prompt </p>\n": "<p>\u542f\u52a8\u63d0\u793a</p>\n",
 "<p>Take optimizer step </p>\n": "<p>\u91c7\u53d6\u4f18\u5316\u5668\u6b65\u9aa4</p>\n",
 "<p>This will be initialized on the first call </p>\n": "<p>\u8fd9\u5c06\u5728\u7b2c\u4e00\u6b21\u8c03\u7528\u65f6\u521d\u59cb\u5316</p>\n",
 "<p>Token embedding module </p>\n": "<p>\u4ee4\u724c\u5d4c\u5165\u6a21\u5757</p>\n",
 "<p>Tokenize the prompt </p>\n": "<p>\u5c06\u63d0\u793a\u7b26\u53f7\u5316</p>\n",
 "<p>Train the model </p>\n": "<p>\u8bad\u7ec3\u6a21\u578b</p>\n",
 "<p>Transformer based encoder </p>\n": "<p>\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u7f16\u7801\u5668</p>\n",
 "Gated Linear Units and Variants": "\u95e8\u63a7\u7ebf\u6027\u5355\u4f4d\u548c\u53d8\u4f53",
 "Train an auto-regressive transformer with Gated Linear Units and variants for the position-wise feedforward network (FFN).": "\u4f7f\u7528\u95e8\u63a7\u7ebf\u6027\u5355\u5143\u548c\u4f4d\u7f6e\u524d\u9988\u7f51\u7edc (FFN) \u53d8\u4f53\u8bad\u7ec3\u81ea\u56de\u5f52\u53d8\u538b\u5668\u3002"
}