{
 "<h1>MLP-Mixer: An all-MLP Architecture for Vision</h1>\n<p>This is a <a href=\"https://pytorch.org\">PyTorch</a> implementation of the paper <a href=\"https://papers.labml.ai/paper/2105.01601\">MLP-Mixer: An all-MLP Architecture for Vision</a>.</p>\n<p>This paper applies the model on vision tasks. The model is similar to a transformer with attention layer being replaced by a MLP that is applied across the patches (or tokens in case of a NLP task).</p>\n<p>Our implementation of MLP Mixer is a drop in replacement for the <a href=\"../mha.html\">self-attention layer</a> in <a href=\"../models.html\">our transformer implementation</a>. So it&#x27;s just a couple of lines of code, transposing the tensor to apply the MLP across the sequence dimension.</p>\n<p>Although the paper applied MLP Mixer on vision tasks, we tried it on a <a href=\"../mlm/index.html\">masked language model</a>. <a href=\"experiment.html\">Here is the experiment code</a>.</p>\n": "<h1>MLP-Mixer\uff1a\u9002\u7528\u4e8e\u89c6\u89c9\u7684\u5168 MLP \u67b6\u6784</h1>\n<p>\u8fd9\u662f <a href=\"https://pytorch.org\">PyTorch</a> \u5bf9\u8bba\u6587 <a href=\"https://papers.labml.ai/paper/2105.01601\">MLP-Mixer\uff1a\u9002\u7528\u4e8e\u89c6\u89c9\u7684\u5168 MLP \u67b6\u6784\u7684</a>\u5b9e\u73b0\u3002</p>\n<p>\u672c\u6587\u5c06\u8be5\u6a21\u578b\u5e94\u7528\u4e8e\u89c6\u89c9\u4efb\u52a1\u3002\u8be5\u6a21\u578b\u7c7b\u4f3c\u4e8e\u53d8\u538b\u5668\uff0c\u6ce8\u610f\u529b\u5c42\u88ab\u5e94\u7528\u4e8e\u8865\u4e01\u7684 MLP\uff08\u5982\u679c\u662f NLP \u4efb\u52a1\uff0c\u5219\u4e3a\u4ee3\u5e01\uff09\u3002</p>\n<p>\u6211\u4eec\u5b9e\u73b0\u7684 MLP Mixer \u5b8c\u5168\u53d6\u4ee3\u4e86<a href=\"../models.html\">\u53d8\u538b\u5668\u5b9e\u73b0</a>\u4e2d\u7684<a href=\"../mha.html\">\u81ea\u6ce8\u610f\u529b\u5c42</a>\u3002\u56e0\u6b64\uff0c\u8fd9\u53ea\u662f\u51e0\u884c\u4ee3\u7801\uff0c\u5bf9\u5f20\u91cf\u8fdb\u884c\u8f6c\u7f6e\u4ee5\u5728\u5e8f\u5217\u7ef4\u5ea6\u4e0a\u5e94\u7528 MLP\u3002</p>\n<p>\u5c3d\u7ba1\u8be5\u8bba\u6587\u5c06 MLP Mixer \u5e94\u7528\u4e8e\u89c6\u89c9\u4efb\u52a1\uff0c\u4f46\u6211\u4eec\u5728<a href=\"../mlm/index.html\">\u63a9\u7801\u8bed\u8a00\u6a21\u578b</a>\u4e0a\u8fdb\u884c\u4e86\u5c1d\u8bd5\u3002<a href=\"experiment.html\">\u8fd9\u662f\u5b9e\u9a8c\u4ee3\u7801</a>\u3002</p>\n",
 "<h2>MLP Mixer</h2>\n<p>This module is a drop-in replacement for <a href=\"../mha.html\">self-attention layer</a>. It transposes the input tensor before feeding it to the MLP and transposes back, so that the MLP is applied across the sequence dimension (across tokens or image patches) instead of the feature dimension.</p>\n": "<h2>MLP \u6df7\u97f3\u5668</h2>\n<p>\u8be5\u6a21\u5757\u662f<a href=\"../mha.html\">\u81ea\u6211\u6ce8\u610f\u529b\u5c42</a>\u7684\u76f4\u63a5\u66ff\u4ee3\u54c1\u3002\u5b83\u5728\u5c06\u8f93\u5165\u5f20\u91cf\u9988\u9001\u5230 MLP \u4e4b\u524d\u5bf9\u5176\u8fdb\u884c\u8f6c\u7f6e\u5e76\u5411\u540e\u79fb\u8c03\uff0c\u8fd9\u6837 MLP \u5c06\u5e94\u7528\u4e8e\u6574\u4e2a\u5e8f\u5217\u7ef4\u5ea6\uff08\u8de8\u6807\u8bb0\u6216\u56fe\u50cf\u8865\u4e01\uff09\uff0c\u800c\u4e0d\u662f\u7279\u5f81\u7ef4\u5ea6\u3002</p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> The <a href=\"../mha.html\">normal attention module</a> can be fed with different token embeddings for <span translate=no>_^_0_^_</span>,<span translate=no>_^_1_^_</span>, and <span translate=no>_^_2_^_</span> and a mask.</p>\n<p>We follow the same function signature so that we can replace it directly.</p>\n<p>For MLP mixing, <span translate=no>_^_3_^_</span> and masking is not possible. Shape of <span translate=no>_^_4_^_</span> (and <span translate=no>_^_5_^_</span> and <span translate=no>_^_6_^_</span>) is <span translate=no>_^_7_^_</span>.</p>\n": "<p><a href=\"../mha.html\">\u666e\u901a\u6ce8\u610f\u529b\u6a21\u5757</a>\u53ef\u4ee5\u4f7f\u7528<span translate=no>_^_0_^_</span>\u3001<span translate=no>_^_1_^_</span>\u548c\u7684\u4e0d\u540c\u4ee4\u724c\u5d4c\u5165<span translate=no>_^_2_^_</span>\u4ee5\u53ca\u63a9\u7801\u8fdb\u884c\u9988\u9001\u3002</p>\n<p>\u6211\u4eec\u9075\u5faa\u76f8\u540c\u7684\u51fd\u6570\u7b7e\u540d\uff0c\u4ee5\u4fbf\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u66ff\u6362\u5b83\u3002</p>\n<p>\u5bf9\u4e8e MLP \u6df7\u5408<span translate=no>_^_3_^_</span>\uff0c\u5c4f\u853d\u662f\u4e0d\u53ef\u80fd\u7684\u3002<span translate=no>_^_4_^_</span>\uff08\u548c<span translate=no>_^_5_^_</span>\u548c<span translate=no>_^_6_^_</span>\uff09\u7684\u5f62\u72b6\u4e3a<span translate=no>_^_7_^_</span>\u3002</p>\n",
 "<p><span translate=no>_^_0_^_</span>,<span translate=no>_^_1_^_</span>, and <span translate=no>_^_2_^_</span> all should be the same </p>\n": "<p><span translate=no>_^_0_^_</span>\u3001<span translate=no>_^_1_^_</span>\uff0c\u5e76\u4e14<span translate=no>_^_2_^_</span>\u90fd\u5e94\u8be5\u662f\u4e00\u6837\u7684</p>\n",
 "<p>Apply the MLP across tokens </p>\n": "<p>\u8de8\u4ee3\u5e01\u5e94\u7528 MLP</p>\n",
 "<p>Assign to <span translate=no>_^_0_^_</span> for clarity </p>\n": "<p>\u4e3a\u4e86\u6e05\u695a\u8d77\u89c1\uff0c<span translate=no>_^_0_^_</span>\u8bf7\u5206\u914d\u7ed9</p>\n",
 "<p>MLP mixer doesn&#x27;t support masking. i.e. all tokens will see all other token embeddings. </p>\n": "<p>MLP \u6df7\u97f3\u5668\u4e0d\u652f\u6301\u5c4f\u853d\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u6240\u6709\u4ee4\u724c\u90fd\u4f1a\u770b\u5230\u6240\u6709\u5176\u4ed6\u4ee4\u724c\u5d4c\u5165\u3002</p>\n",
 "<p>Transpose back into original form </p>\n": "<p>\u79fb\u8c03\u56de\u539f\u59cb\u5f62\u5f0f</p>\n",
 "<p>Transpose so that the last dimension is the sequence dimension. New shape is <span translate=no>_^_0_^_</span> </p>\n": "\u8fdb\u884c@@ <p>\u8f6c\u7f6e\uff0c\u4f7f\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u6210\u4e3a\u5e8f\u5217\u7ef4\u5ea6\u3002\u65b0\u5f62\u72b6\u662f<span translate=no>_^_0_^_</span></p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the MLP module.</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f MLP \u6a21\u5757\u3002</li></ul>\n",
 "MLP-Mixer: An all-MLP Architecture for Vision": "MLP \u6df7\u97f3\u5668\uff1a\u9762\u5411\u89c6\u89c9\u7684\u5168 MLP \u67b6\u6784",
 "This is an annotated implementation/tutorial of MLP-Mixer: An all-MLP Architecture for Vision in PyTorch.": "\u8fd9\u662f MLP-Mixer \u7684\u5e26\u6ce8\u91ca\u7684\u5b9e\u73b0/\u6559\u7a0b\uff1aPyTorch \u4e2d\u89c6\u89c9\u7684\u5168 MLP \u67b6\u6784\u3002"
}