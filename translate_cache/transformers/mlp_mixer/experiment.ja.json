{
 "<h1><a href=\"index.html\">MLP Mixer</a> Experiment</h1>\n<p>This is an annotated PyTorch experiment to train a <a href=\"index.html\">MLP Mixer Model</a>.</p>\n": "<h1><a href=\"index.html\">MLP \u30df\u30ad\u30b5\u30fc\u5b9f\u9a13</a></h1>\n<p><a href=\"index.html\">\u3053\u308c\u306f MLP \u30df\u30ad\u30b5\u30fc\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u305f\u3081\u306e\u6ce8\u91c8\u4ed8\u304d PyTorch \u5b9f\u9a13\u3067\u3059\u3002</a></p>\n",
 "<h2>Configurations</h2>\n<p>This inherits from <a href=\"../mlm/experiment.html\"><span translate=no>_^_0_^_</span></a> where we define an experiment for <a href=\"../mlm.index.html\">Masked Language Models</a>.</p>\n": "<h2>\u30b3\u30f3\u30d5\u30a3\u30ae\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3</h2>\n<p>\u3053\u308c\u306f\u3001<a href=\"../mlm/experiment.html\"><span translate=no>_^_0_^_</span></a><a href=\"../mlm.index.html\">\u30de\u30b9\u30af\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u5b9f\u9a13\u3092\u5b9a\u7fa9\u3059\u308b\u3068\u3053\u308d\u304b\u3089\u53d7\u3051\u7d99\u304c\u308c\u3066\u3044\u307e\u3059</a>\u3002</p>\n",
 "<h3>Transformer configurations</h3>\n": "<h3>\u5909\u5727\u5668\u69cb\u6210</h3>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> The mixing MLP configurations</p>\n": "<p>MLP \u69cb\u6210\u306e\u30df\u30ad\u30b7\u30f3\u30b0</p>\n",
 "<p>Batch size </p>\n": "<p>\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba</p>\n",
 "<p>Change attention module to <a href=\"index.html\">MLPMixer</a> </p>\n": "<p><a href=\"index.html\">\u30a2\u30c6\u30f3\u30b7\u30e7\u30f3\u30e2\u30b8\u30e5\u30fc\u30eb\u3092MLPMixer\u306b\u5909\u66f4</a></p>\n",
 "<p>Configurable <a href=\"../feed_forward.html\">Feed-Forward Network</a> for the MLP </p>\n": "<p>MLP <a href=\"../feed_forward.html\">\u7528\u306e\u8a2d\u5b9a\u53ef\u80fd\u306a\u30d5\u30a3\u30fc\u30c9\u30d5\u30a9\u30ef\u30fc\u30c9\u30cd\u30c3\u30c8\u30ef\u30fc\u30af</a></p>\n",
 "<p>Create configs </p>\n": "<p>\u30b3\u30f3\u30d5\u30a3\u30b0\u306e\u4f5c\u6210</p>\n",
 "<p>Create experiment </p>\n": "<p>\u5b9f\u9a13\u3092\u4f5c\u6210</p>\n",
 "<p>Embedding size </p>\n": "<p>\u57cb\u3081\u8fbc\u307f\u30b5\u30a4\u30ba</p>\n",
 "<p>Mixer MLP hidden layer size </p>\n": "<p>\u30df\u30ad\u30b5\u30fc MLP \u96a0\u308c\u30ec\u30a4\u30e4\u30fc\u30b5\u30a4\u30ba</p>\n",
 "<p>Override configurations </p>\n": "<p>\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u8a2d\u5b9a</p>\n",
 "<p>Run training </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u884c</p>\n",
 "<p>Sequence length of <span translate=no>_^_0_^_</span>. We use a short sequence length to train faster. Otherwise MLM models take forever to train. </p>\n": "<p>\u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u9577\u3055\u306f <span translate=no>_^_0_^_</span>\u77ed\u3044\u30b7\u30fc\u30b1\u30f3\u30b9\u9577\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u9ad8\u901f\u5316\u3057\u307e\u3059\u3002\u305d\u3046\u3057\u306a\u3044\u3068\u3001MLM\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306b\u306f\u6c38\u9060\u306b\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059</p>\u3002\n",
 "<p>Set models for saving and loading </p>\n": "<p>\u4fdd\u5b58\u304a\u3088\u3073\u8aad\u307f\u8fbc\u307f\u7528\u306e\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\u3059\u308b</p>\n",
 "<p>Set the vocabulary sizes for embeddings and generating logits </p>\n": "<p>\u57cb\u3081\u8fbc\u307f\u3084\u30ed\u30b8\u30c3\u30c8\u306e\u751f\u6210\u306b\u4f7f\u7528\u3059\u308b\u30dc\u30ad\u30e3\u30d6\u30e9\u30ea\u30fc\u30b5\u30a4\u30ba\u3092\u8a2d\u5b9a</p>\n",
 "<p>Size of the MLP is the sequence length, because it is applied across tokens </p>\n": "<p>MLP\u306e\u30b5\u30a4\u30ba\u306f\u30c8\u30fc\u30af\u30f3\u5168\u4f53\u306b\u9069\u7528\u3055\u308c\u308b\u305f\u3081\u3001\u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u9577\u3055\u306b\u306a\u308a\u307e\u3059</p>\n",
 "<p>Start the experiment </p>\n": "<p>\u5b9f\u9a13\u3092\u59cb\u3081\u308b</p>\n",
 "<p>Switch between training and validation for <span translate=no>_^_0_^_</span> times per epoch </p>\n": "<p>\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u691c\u8a3c\u3092\u5207\u308a\u66ff\u3048\u308b <span translate=no>_^_0_^_</span></p>\n",
 "<p>The paper suggests <span translate=no>_^_0_^_</span> activation </p>\n": "<p><span translate=no>_^_0_^_</span>\u8ad6\u6587\u306f\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30b7\u30e7\u30f3\u3092\u793a\u5506\u3057\u3066\u3044\u307e\u3059</p>\n",
 "<p>Train for 1024 epochs. </p>\n": "<p>1024 \u30a8\u30dd\u30c3\u30af\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u884c\u3044\u307e\u3059\u3002</p>\n",
 "<p>Transformer configurations </p>\n": "<p>\u5909\u5727\u5668\u69cb\u6210</p>\n",
 "<p>Use <a href=\"../../optimizers/noam.html\">Noam optimizer</a> </p>\n": "<p><a href=\"../../optimizers/noam.html\">Noam</a> \u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u3092\u4f7f\u3046</p>\n",
 "<p>We use our <a href=\"../configs.html#TransformerConfigs\">configurable transformer implementation</a> </p>\n": "<p><a href=\"../configs.html#TransformerConfigs\">\u8a2d\u5b9a\u53ef\u80fd\u306a\u30c8\u30e9\u30f3\u30b9\u5b9f\u88c5\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059</a></p>\n",
 "MLP Mixer experiment": "MLP \u30df\u30ad\u30b5\u30fc\u5b9f\u9a13",
 "This experiment trains MLP Mixer on Tiny Shakespeare dataset.": "\u3053\u306e\u5b9f\u9a13\u3067\u306f\u3001\u30bf\u30a4\u30cb\u30fc\u30b7\u30a7\u30a4\u30af\u30b9\u30d4\u30a2\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067 MLP Mixer \u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3059\u3002"
}