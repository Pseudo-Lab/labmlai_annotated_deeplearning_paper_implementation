{
 "<h1>Fixed Positional Encodings</h1>\n<p>The positional encoding encodes the position along the sequence into  a vector of size <span translate=no>_^_0_^_</span>.</p>\n<span translate=no>_^_1_^_</span><p>Where <span translate=no>_^_2_^_</span>  are the feature indexes in the encoding, and <span translate=no>_^_3_^_</span> is the position.</p>\n": "<h1>\u56fa\u5b9a\u4f4d\u7f6e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0</h1>\n<p>\u4f4d\u7f6e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306f\u3001\u30b7\u30fc\u30b1\u30f3\u30b9\u4e0a\u306e\u4f4d\u7f6e\u3092\u30b5\u30a4\u30ba\u306e\u30d9\u30af\u30c8\u30eb\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\u3057\u307e\u3059\u3002<span translate=no>_^_0_^_</span></p>\n<span translate=no>_^_1_^_</span><p>\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306b\u304a\u3051\u308b\u7279\u5fb4\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u4f4d\u7f6e\u3001<span translate=no>_^_3_^_</span>\u306f\u4f4d\u7f6e\u3067\u3059\u3002<span translate=no>_^_2_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p>Add batch dimension </p>\n": "<p>\u30d0\u30c3\u30c1\u30c7\u30a3\u30e1\u30f3\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0</p>\n",
 "<p>Empty encodings vectors </p>\n": "<p>\u7a7a\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30d9\u30af\u30c8\u30eb</p>\n",
 "<p>Position indexes </p>\n": "<p>\u30dd\u30b8\u30b7\u30e7\u30f3\u30a4\u30f3\u30c7\u30c3\u30af\u30b9</p>\n",
 "Fixed Positional Encodings": "\u56fa\u5b9a\u4f4d\u7f6e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0",
 "Implementation with explanation of fixed positional encodings as described in paper Attention is All You Need.": "\u8ad6\u6587\u300c\u6ce8\u610f\u3059\u308c\u3070\u3044\u3044\u3060\u3051\u300d\u3067\u8aac\u660e\u3055\u308c\u3066\u3044\u308b\u56fa\u5b9a\u4f4d\u7f6e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306e\u8aac\u660e\u4ed8\u304d\u306e\u5b9f\u88c5\u3002"
}