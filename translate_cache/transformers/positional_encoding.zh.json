{
 "<h1>Fixed Positional Encodings</h1>\n<p>The positional encoding encodes the position along the sequence into  a vector of size <span translate=no>_^_0_^_</span>.</p>\n<span translate=no>_^_1_^_</span><p>Where <span translate=no>_^_2_^_</span>  are the feature indexes in the encoding, and <span translate=no>_^_3_^_</span> is the position.</p>\n": "<h1>\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801</h1>\n<p>\u4f4d\u7f6e\u7f16\u7801\u5c06\u6cbf\u5e8f\u5217\u7684\u4f4d\u7f6e\u7f16\u7801\u4e3a\u5927\u5c0f\u5411\u91cf<span translate=no>_^_0_^_</span>\u3002</p>\n<span translate=no>_^_1_^_</span><p>\u7f16\u7801<span translate=no>_^_2_^_</span>\u4e2d\u7684\u7279\u5f81\u7d22\u5f15\u5728\u54ea\u91cc\uff0c<span translate=no>_^_3_^_</span>\u662f\u4f4d\u7f6e\u3002</p>\n",
 "<p><span translate=no>_^_0_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p>Add batch dimension </p>\n": "<p>\u6dfb\u52a0\u6279\u91cf\u7ef4\u5ea6</p>\n",
 "<p>Empty encodings vectors </p>\n": "<p>\u7a7a\u7f16\u7801\u5411\u91cf</p>\n",
 "<p>Position indexes </p>\n": "<p>\u5934\u5bf8\u6307\u6570</p>\n",
 "Fixed Positional Encodings": "\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801",
 "Implementation with explanation of fixed positional encodings as described in paper Attention is All You Need.": "\u5b9e\u73b0\u65f6\u5bf9\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801\u7684\u89e3\u91ca\uff0c\u5982\u8bba\u6587 \u201c\u6ce8\u610f\u5c31\u662f\u4f60\u6240\u9700\u8981\u7684\u201d\u3002"
}