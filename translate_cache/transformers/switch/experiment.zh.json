{
 "<h1>Switch Transformer Experiment</h1>\n<p>This is an annotated PyTorch experiment to train a switch transformer.</p>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/transformers/switch/experiment.ipynb\"><span translate=no>_^_0_^_</span></a></p>\n": "<h1>\u5f00\u5173\u53d8\u538b\u5668\u5b9e\u9a8c</h1>\n<p>\u8fd9\u662f\u4e00\u9879\u5e26\u6ce8\u91ca\u7684 PyTorch \u5b9e\u9a8c\uff0c\u7528\u4e8e\u8bad\u7ec3\u5f00\u5173\u53d8\u538b\u5668\u3002</p>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/transformers/switch/experiment.ipynb\"><span translate=no>_^_0_^_</span></a></p>\n",
 "<h2>Auto regressive model</h2>\n": "<h2>\u81ea\u52a8\u56de\u5f52\u6a21\u578b</h2>\n",
 "<h2>Configurations</h2>\n<p>This extends <a href=\"../../experiments/nlp_autoregression.html\"><span translate=no>_^_0_^_</span></a>.</p>\n<p>The default configs can and will be over-ridden when we start the experiment</p>\n": "<h2>\u914d\u7f6e</h2>\n<p>\u8fd9\u5ef6\u4f38<a href=\"../../experiments/nlp_autoregression.html\"><span translate=no>_^_0_^_</span></a>\u4e86\u3002</p>\n<p>\u5f53\u6211\u4eec\u5f00\u59cb\u5b9e\u9a8c\u65f6\uff0c\u9ed8\u8ba4\u914d\u7f6e\u53ef\u4ee5\u800c\u4e14\u5c06\u4f1a\u88ab\u8986\u76d6</p>\n",
 "<h3>Initialize the auto-regressive model</h3>\n": "<h3>\u521d\u59cb\u5316\u81ea\u56de\u5f52\u6a21\u578b</h3>\n",
 "<h3>Initialize the switch transformer</h3>\n": "<h3>\u521d\u59cb\u5316\u5f00\u5173\u53d8\u538b\u5668</h3>\n",
 "<h3>Run the experiment</h3>\n": "<h3>\u8fd0\u884c\u5b9e\u9a8c</h3>\n",
 "<h3>Training or validation step</h3>\n": "<h3>\u57f9\u8bad\u6216\u9a8c\u8bc1\u6b65\u9aa4</h3>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p><span translate=no>_^_0_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p>A dictionary of configurations to override </p>\n": "<p>\u8981\u8986\u76d6\u7684\u914d\u7f6e\u5b57\u5178</p>\n",
 "<p>Calculate and cross entropy loss </p>\n": "<p>\u8ba1\u7b97\u548c\u4ea4\u53c9\u71b5\u635f\u5931</p>\n",
 "<p>Calculate and log accuracy </p>\n": "<p>\u8ba1\u7b97\u548c\u8bb0\u5f55\u7cbe\u5ea6</p>\n",
 "<p>Calculate gradients </p>\n": "<p>\u8ba1\u7b97\u68af\u5ea6</p>\n",
 "<p>Capacity factor to determine capacity of each model </p>\n": "<p>\u786e\u5b9a\u6bcf\u79cd\u578b\u53f7\u5bb9\u91cf\u7684\u5bb9\u91cf\u7cfb\u6570</p>\n",
 "<p>Clear the gradients </p>\n": "<p>\u6e05\u9664\u6e10\u53d8</p>\n",
 "<p>Clip gradients </p>\n": "<p>\u526a\u8f91\u6e10\u53d8</p>\n",
 "<p>Combined loss. The load balancing loss is multiplied by a coefficient <span translate=no>_^_0_^_</span> which is set to something small like <span translate=no>_^_1_^_</span>. </p>\n": "<p>\u5408\u5e76\u4e8f\u635f\u3002\u8d1f\u8f7d\u5747\u8861\u635f\u5931\u4e58\u4ee5\u7cfb\u6570\uff0c<span translate=no>_^_0_^_</span>\u8be5\u7cfb\u6570\u8bbe\u7f6e\u4e3a\u7c7b\u4f3c\u7684\u5c0f\u503c<span translate=no>_^_1_^_</span>\u3002</p>\n",
 "<p>Create configs </p>\n": "<p>\u521b\u5efa\u914d\u7f6e</p>\n",
 "<p>Create experiment </p>\n": "<p>\u521b\u5efa\u5b9e\u9a8c</p>\n",
 "<p>Dropout probability </p>\n": "<p>\u8f8d\u5b66\u6982\u7387</p>\n",
 "<p>Final layer </p>\n": "<p>\u6700\u540e\u4e00\u5c42</p>\n",
 "<p>Fraction of tokens routed to each expert <span translate=no>_^_0_^_</span> <span translate=no>_^_1_^_</span> is the count of tokens where the argmax of <span translate=no>_^_2_^_</span> is equal to <span translate=no>_^_3_^_</span>. </p>\n": "<p>\u53d1\u9001\u7ed9\u6bcf\u4e2a EA \u7684\u4ee3\u5e01\u7684\u5206\u6570<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u662f\u5176\u4e2d\u7684argmax\u7b49\u4e8e\u7684<span translate=no>_^_2_^_</span>\u4ee3\u5e01\u8ba1\u6570<span translate=no>_^_3_^_</span>\u3002</p>\n",
 "<p>Generate logits of the next token </p>\n": "<p>\u751f\u6210\u4e0b\u4e00\u4e2a\u4ee4\u724c\u7684\u65e5\u5fd7</p>\n",
 "<p>Get model outputs. </p>\n": "<p>\u83b7\u53d6\u6a21\u578b\u8f93\u51fa\u3002</p>\n",
 "<p>Initialize the subsequent mask </p>\n": "<p>\u521d\u59cb\u5316\u540e\u7eed\u63a9\u7801</p>\n",
 "<p>Initialize tracking indicators </p>\n": "<p>\u521d\u59cb\u5316\u8ddf\u8e2a\u6307\u793a\u5668</p>\n",
 "<p>Load balancing coefficient </p>\n": "<p>\u8d1f\u8f7d\u5e73\u8861\u7cfb\u6570</p>\n",
 "<p>Load balancing loss <span translate=no>_^_0_^_</span> <span translate=no>_^_1_^_</span> is the loss for a single layer and here we are taking the sum of losses across all layers. </p>\n": "<p>\u8d1f\u8f7d\u5747\u8861\u635f\u5931<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u662f\u5355\u5c42\u7684\u635f\u5931\uff0c\u8fd9\u91cc\u6211\u4eec\u53d6\u7684\u662f\u6240\u6709\u5c42\u7684\u635f\u5931\u603b\u548c\u3002</p>\n",
 "<p>Load configurations </p>\n": "<p>\u88c5\u8f7d\u914d\u7f6e</p>\n",
 "<p>Log the model parameters and gradients on last batch of every epoch </p>\n": "<p>\u8bb0\u5f55\u6bcf\u4e2a\u7eaa\u5143\u6700\u540e\u4e00\u6279\u7684\u6a21\u578b\u53c2\u6570\u548c\u68af\u5ea6</p>\n",
 "<p>Mean routing probability <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5e73\u5747\u8def\u7531\u6982\u7387<span translate=no>_^_0_^_</span></p>\n",
 "<p>Move data to the device </p>\n": "<p>\u5c06\u6570\u636e\u79fb\u52a8\u5230\u8bbe\u5907</p>\n",
 "<p>Number of attention heads </p>\n": "<p>\u6ce8\u610f\u5934\u6570\u91cf</p>\n",
 "<p>Number of experts </p>\n": "<p>\u4e13\u5bb6\u4eba\u6570</p>\n",
 "<p>Number of features in FFN hidden layer </p>\n": "<p>FFN \u9690\u85cf\u5c42\u4e2d\u7684\u8981\u7d20\u6570\u91cf</p>\n",
 "<p>Number of transformer layers </p>\n": "<p>\u53d8\u538b\u5668\u5c42\u6570</p>\n",
 "<p>Run it through the transformer </p>\n": "<p>\u7528\u5b83\u7a7f\u8fc7\u53d8\u538b\u5668</p>\n",
 "<p>Save the tracked metrics </p>\n": "<p>\u4fdd\u5b58\u8ddf\u8e2a\u7684\u6307\u6807</p>\n",
 "<p>Set models for saving and loading </p>\n": "<p>\u8bbe\u7f6e\u7528\u4e8e\u4fdd\u5b58\u548c\u52a0\u8f7d\u7684\u6a21\u578b</p>\n",
 "<p>Start the experiment </p>\n": "<p>\u5f00\u59cb\u5b9e\u9a8c</p>\n",
 "<p>Take optimizer step </p>\n": "<p>\u91c7\u53d6\u4f18\u5316\u5668\u6b65\u9aa4</p>\n",
 "<p>Token embedding module </p>\n": "<p>\u4ee4\u724c\u5d4c\u5165\u6a21\u5757</p>\n",
 "<p>Token embedding size </p>\n": "<p>\u4ee4\u724c\u5d4c\u5165\u5927\u5c0f</p>\n",
 "<p>Token embeddings </p>\n": "<p>\u4ee4\u724c\u5d4c\u5165</p>\n",
 "<p>Total number of tokens processed, <span translate=no>_^_0_^_</span>, in the current batch <span translate=no>_^_1_^_</span> </p>\n": "<p>\u5f53\u524d\u6279\u6b21\u4e2d\u5df2\u5904\u7406\u7684\u4ee4\u724c\u603b\u6570<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span></p>\n",
 "<p>Track stats </p>\n": "<p>\u8ffd\u8e2a\u7edf\u8ba1\u6570\u636e</p>\n",
 "<p>Train the model </p>\n": "<p>\u8bad\u7ec3\u6a21\u578b</p>\n",
 "<p>Transformer </p>\n": "<p>\u53d8\u538b\u5668</p>\n",
 "<p>Update global step (number of tokens processed) when in training mode </p>\n": "<p>\u5728\u8bad\u7ec3\u6a21\u5f0f\u4e0b\u66f4\u65b0\u5168\u5c40\u6b65\u957f\uff08\u5904\u7406\u7684\u4ee4\u724c\u6570\uff09</p>\n",
 "<p>Whether to capture model outputs </p>\n": "<p>\u662f\u5426\u6355\u83b7\u6a21\u578b\u8f93\u51fa</p>\n",
 "<p>Whether to drop tokens </p>\n": "<p>\u662f\u5426\u4e22\u5f03\u4ee3\u5e01</p>\n",
 "<p>Whether to scale the chosen expert outputs by the routing probability </p>\n": "<p>\u662f\u5426\u6309\u8def\u7531\u6982\u7387\u7f29\u653e\u6240\u9009\u667a\u80fd\u4ea4\u6613\u8f93\u51fa</p>\n",
 "Switch Transformer Experiment": "\u5f00\u5173\u53d8\u538b\u5668\u5b9e\u9a8c",
 "This experiment trains a small switch transformer on tiny Shakespeare dataset.": "\u8fd9\u4e2a\u5b9e\u9a8c\u5728\u5fae\u5c0f\u7684\u838e\u58eb\u6bd4\u4e9a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u578b\u5f00\u5173\u53d8\u538b\u5668\u3002"
}