{
 "<h1><a href=\"index.html\">Primer EZ</a> Variations</h1>\n<p>We tried some variations to see which changes in Primer EZ has most benefits.</p>\n": "<h1><a href=\"index.html\">\u0db4\u0dca\u0dbb\u0dba\u0dd2\u0db8\u0dbb\u0dca EZ</a> \u0dc0\u0dd2\u0da0\u0dbd\u0db1\u0dba\u0db1\u0dca</h1>\n<p>\u0db4\u0dca\u0dbb\u0dba\u0dd2\u0db8\u0dbb\u0dcaEZ \u0dc4\u0dd2 \u0dc0\u0dd9\u0db1\u0dc3\u0dca\u0d9a\u0db8\u0dca \u0db8\u0ddc\u0db1\u0dc0\u0dcf\u0daf \u0dba\u0db1\u0dca\u0db1 \u0db6\u0dd0\u0dbd\u0dd3\u0db8\u0da7 \u0d85\u0db4\u0dd2 \u0dba\u0db8\u0dca \u0dc0\u0dd9\u0db1\u0dc3\u0dca\u0d9a\u0db8\u0dca \u0d9a\u0dd2\u0dc4\u0dd2\u0db4\u0dba\u0d9a\u0dca \u0d8b\u0dad\u0dca\u0dc3\u0dcf\u0dc4 \u0d9a\u0dc5\u0dd9\u0db8\u0dd4. </p>\n",
 "<h2>Multi-Depth-wise-Shared-Conv-Head Attention</h2>\n<p>We extend our original implementation of <a href=\"../mha.html#MHA\">Multi-Head Attention</a> and add the spatial depth-wise shared convolution to query, key and value projections.</p>\n": "<h2>\u0db6\u0dc4\u0dd4-\u0d9c\u0dd0\u0db9\u0dd4\u0dbb\u0dd4-\u0db4\u0dca\u0dbb\u0da5\u0dcf\u0dc0-\u0db6\u0dd9\u0daf\u0dcf-COV-\u0dc4\u0dd2\u0dc3\u0d85\u0dc0\u0db0\u0dcf\u0db1\u0dba</h2>\n<p>\u0d85\u0db4\u0dd2 <a href=\"../mha.html#MHA\">\u0db6\u0dc4\u0dd4-\u0db4\u0dca\u0dbb\u0db0\u0dcf\u0db1 \u0d85\u0dc0\u0db0\u0dcf\u0db1\u0dba</a> \u0d85\u0db4\u0d9c\u0dda \u0db8\u0dd4\u0dbd\u0dca \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0daf\u0dd3\u0dbb\u0dca extend \u0d9a\u0dbb\u0db1 \u0d85\u0dad\u0dbb \u0dc0\u0dd2\u0db8\u0dc3\u0dd4\u0db8, \u0dba\u0dad\u0dd4\u0dbb \u0dc3\u0dc4 \u0dc0\u0da7\u0dd2\u0db1\u0dcf\u0d9a\u0db8\u0dca \u0db4\u0dca\u0dbb\u0d9a\u0dca\u0dc2\u0dda\u0db4\u0dab \u0dc3\u0db3\u0dc4\u0dcf \u0d85\u0dc0\u0d9a\u0dcf\u0dc1\u0dd3\u0dba \u0d9c\u0dd0\u0db9\u0dd4\u0dbb\u0da7 \u0dc4\u0dc0\u0dd4\u0dbd\u0dca \u0dc4\u0dc0\u0dd4\u0dbd\u0dca \u0dc3\u0db8\u0dca\u0db8\u0dd4\u0dad\u0dd2\u0dba\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0d9a\u0dbb\u0db8\u0dd4. </p>\n",
 "<h2>Multi-per-Head-Depth-wise-Conv-Head Attention</h2>\n<p>We extend our original implementation of <a href=\"../mha.html#MHA\">Multi-Head Attention</a> and add the spatial depth-wise convolution to query, key and value projections.</p>\n": "<h2>\u0db6\u0dc4\u0dd4-per-\u0dc4\u0dd2\u0dc3\u0d9c\u0dd0\u0db9\u0dd4\u0dbb\u0dd4-\u0db4\u0dca\u0dbb\u0da5\u0dcf\u0dc0-\u0d9a\u0dda\u0dad\u0dd4-\u0dc4\u0dd2\u0dc3 \u0d85\u0dc0\u0db0\u0dcf\u0db1\u0dba</h2>\n<p>\u0d85\u0db4\u0dd2 <a href=\"../mha.html#MHA\">\u0db6\u0dc4\u0dd4-\u0db4\u0dca\u0dbb\u0db0\u0dcf\u0db1 \u0d85\u0dc0\u0db0\u0dcf\u0db1\u0dba</a> \u0d85\u0db4\u0d9c\u0dda \u0db8\u0dd4\u0dbd\u0dca \u0d9a\u0dca\u0dbb\u0dd2\u0dba\u0dcf\u0dad\u0dca\u0db8\u0d9a \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 \u0daf\u0dd3\u0dbb\u0dca and \u0d9a\u0dbb\u0db1 \u0d85\u0dad\u0dbb \u0dc0\u0dd2\u0db8\u0dc3\u0dd4\u0db8, \u0dba\u0dad\u0dd4\u0dbb \u0dc3\u0dc4 \u0dc0\u0da7\u0dd2\u0db1\u0dcf\u0d9a\u0db8\u0dca \u0db4\u0dca\u0dbb\u0d9a\u0dca\u0dc2\u0dda\u0db4\u0dab \u0dc3\u0db3\u0dc4\u0dcf \u0d85\u0dc0\u0d9a\u0dcf\u0dc1\u0dd3\u0dba \u0d9c\u0dd0\u0db9\u0dd4\u0dbb-\u0db1\u0dd0\u0dab\u0dc0\u0dad\u0dca \u0dc3\u0db8\u0dca\u0db8\u0dd4\u0dad\u0dd2\u0dba \u0d91\u0d9a\u0dca \u0d9a\u0dbb\u0db8\u0dd4. </p>\n",
 "<h2>Spatial Depth Wise Per Head Convolution</h2>\n": "<h2>\u0dc4\u0dd2\u0dc3\u0dc3\u0d82\u0d9a\u0ddd\u0da0\u0db1\u0dba \u0dc3\u0db3\u0dc4\u0dcf \u0d85\u0dc0\u0d9a\u0dcf\u0dc1\u0dd3\u0dba \u0d9c\u0dd0\u0db9\u0dd4\u0dbb \u0db1\u0dd0\u0dab\u0dc0\u0dad\u0dca</h2>\n",
 "<h2>Spatial Depth Wise Shared Convolution</h2>\n<p>We share the same kernel across all channels.</p>\n": "<h2>\u0d85\u0dc0\u0d9a\u0dcf\u0dc1\u0dd3\u0dba\u0d9c\u0dd0\u0db9\u0dd4\u0dbb \u0db1\u0dd0\u0dab\u0dc0\u0dad\u0dca \u0dc4\u0dc0\u0dd4\u0dbd\u0dca \u0dc3\u0db8\u0dca\u0db8\u0dd4\u0dad\u0dd2\u0dba</h2>\n<p>\u0d85\u0db4\u0dd2\u0d91\u0d9a\u0db8 \u0d9a\u0dbb\u0dca\u0db1\u0dbd\u0dba \u0dc3\u0dd2\u0dba\u0dbd\u0dd4\u0db8 \u0db1\u0dcf\u0dbd\u0dd2\u0d9a\u0dcf \u0dc4\u0dbb\u0dc4\u0dcf \u0db6\u0dd9\u0daf\u0dcf \u0d9c\u0db1\u0dd2\u0db8\u0dd4. </p>\n",
 "<p> </p>\n": "<p> </p>\n",
 "<p> <span translate=no>_^_0_^_</span> has shape <span translate=no>_^_1_^_</span></p>\n": "<p> <span translate=no>_^_0_^_</span> \u0dc4\u0dd0\u0da9\u0dba \u0d87\u0dad <span translate=no>_^_1_^_</span></p>\n",
 "<p>1D convolution accepts input of the form <span translate=no>_^_0_^_</span> </p>\n": "<p>1D\u0d9a\u0dd0\u0da7\u0dd2 \u0d9c\u0dd0\u0dc3\u0dd4\u0db8\u0dda \u0d86\u0d9a\u0dd8\u0dad\u0dd2\u0dba\u0dda \u0d86\u0daf\u0dcf\u0db1\u0dba \u0db4\u0dd2\u0dc5\u0dd2\u0d9c\u0db1\u0dd3 <span translate=no>_^_0_^_</span> </p>\n",
 "<p><a href=\"../mha.html#MHA\">Multi-Head Attention</a> will create query, key and value projection modules <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>, and <span translate=no>_^_2_^_</span>.</p>\n<p>We combine a spatial depth-wise shared convolution layer to each of them and replace <span translate=no>_^_3_^_</span>, <span translate=no>_^_4_^_</span>, and <span translate=no>_^_5_^_</span>. </p>\n": "<p><a href=\"../mha.html#MHA\">\u0db6\u0dc4\u0dd4-\u0db4\u0dca\u0dbb\u0db0\u0dcf\u0db1 \u0d85\u0dc0\u0db0\u0dcf\u0db1\u0dba</a> \u0dc0\u0dd2\u0db8\u0dc3\u0dd4\u0db8 \u0db1\u0dd2\u0dbb\u0dca\u0db8\u0dcf\u0dab\u0dba \u0d9a\u0dbb\u0db1\u0dd4 \u0d87\u0dad, \u0db4\u0dca\u0dbb\u0db0\u0dcf\u0db1 \u0dc3\u0dc4 \u0d85\u0d9c\u0dba \u0db4\u0dca\u0dbb\u0d9a\u0dca\u0dc2\u0dda\u0db4\u0db1\u0dba \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd <span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>, \u0dc3\u0dc4 <span translate=no>_^_2_^_</span>. </p>\n<p>\u0d85\u0db4\u0dd2\u0d94\u0dc0\u0dd4\u0db1\u0dca \u0d91\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0d85\u0dc0\u0d9a\u0dcf\u0dc1\u0dd3\u0dba \u0d9c\u0dd0\u0db9\u0dd4\u0dbb-\u0db1\u0dd0\u0dab\u0dc0\u0dad\u0dca \u0dc4\u0dc0\u0dd4\u0dbd\u0dca convolution \u0dc3\u0dca\u0dae\u0dbb\u0dba \u0d92\u0d9a\u0dcf\u0db6\u0daf\u0dca\u0db0 \u0dc4\u0dcf \u0dc0\u0dd9\u0db1\u0dd4\u0dc0\u0da7 <span translate=no>_^_3_^_</span><span translate=no>_^_4_^_</span>, \u0dc3\u0dc4 <span translate=no>_^_5_^_</span>. </p>\n",
 "<p><a href=\"../mha.html#MHA\">Multi-Head Attention</a> will create query, key and value projection modules <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>, and <span translate=no>_^_2_^_</span>.</p>\n<p>We combine a spatial per-head depth-wise convolution layer to each of them and replace <span translate=no>_^_3_^_</span>, <span translate=no>_^_4_^_</span>, and <span translate=no>_^_5_^_</span>. </p>\n": "<p><a href=\"../mha.html#MHA\">\u0db6\u0dc4\u0dd4-\u0db4\u0dca\u0dbb\u0db0\u0dcf\u0db1 \u0d85\u0dc0\u0db0\u0dcf\u0db1\u0dba</a> \u0dc0\u0dd2\u0db8\u0dc3\u0dd4\u0db8 \u0db1\u0dd2\u0dbb\u0dca\u0db8\u0dcf\u0dab\u0dba \u0d9a\u0dbb\u0db1\u0dd4 \u0d87\u0dad, \u0db4\u0dca\u0dbb\u0db0\u0dcf\u0db1 \u0dc3\u0dc4 \u0d85\u0d9c\u0dba \u0db4\u0dca\u0dbb\u0d9a\u0dca\u0dc2\u0dda\u0db4\u0db1\u0dba \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd <span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>, \u0dc3\u0dc4 <span translate=no>_^_2_^_</span>. </p>\n<p>\u0d85\u0db4\u0dd2\u0d91\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0d92\u0dc0\u0dcf\u0da7 \u0d85\u0dc0\u0d9a\u0dcf\u0dc1\u0dd3\u0dba \u0d91\u0d9a\u0dca-\u0dc4\u0dd2\u0dc3 \u0d9c\u0dd0\u0db9\u0dd4\u0dbb-\u0db1\u0dd0\u0dab\u0dc0\u0dad\u0dca \u0d9a\u0dd0\u0da7\u0dd2 \u0d9c\u0dd0\u0dc3\u0dd4\u0dab\u0dd4 \u0dc3\u0dca\u0dae\u0dbb\u0dba\u0d9a\u0dca \u0d92\u0d9a\u0dcf\u0db6\u0daf\u0dca\u0db0 \u0d9a\u0dbb \u0db4\u0dca\u0dbb\u0dad\u0dd2\u0dc3\u0dca\u0dae\u0dcf\u0db4\u0db1\u0dba \u0d9a\u0dbb\u0db8\u0dd4 <span translate=no>_^_3_^_</span><span translate=no>_^_4_^_</span>, \u0dc3\u0dc4 <span translate=no>_^_5_^_</span>. </p>\n",
 "<p>Change the shape to <span translate=no>_^_0_^_</span> </p>\n": "<p>\u0dc4\u0dd0\u0da9\u0dba\u0dc0\u0dd9\u0db1\u0dc3\u0dca \u0d9a\u0dbb\u0db1\u0dca\u0db1 <span translate=no>_^_0_^_</span> </p>\n",
 "<p>Crop the right most <span translate=no>_^_0_^_</span> results since we padded both sides </p>\n": "<p>\u0d85\u0db4\u0dd2\u0daf\u0dd9\u0db4\u0dd0\u0dad\u0dca\u0dad\u0dd9\u0db1\u0dca\u0db8 \u0d86\u0dc0\u0dbb\u0dab\u0dba\u0d9a\u0dd2\u0db1\u0dca \u0dc3\u0db8\u0db1\u0dca\u0dc0\u0dd2\u0dad \u0db6\u0dd0\u0dc0\u0dd2\u0db1\u0dca \u0db1\u0dd2\u0dc0\u0dd0\u0dbb\u0daf\u0dd2 \u0dc0\u0da9\u0dcf\u0dad\u0dca\u0db8 <span translate=no>_^_0_^_</span> \u0db4\u0dca\u0dbb\u0dad\u0dd2 results \u0dbd \u0db6\u0ddd\u0d9c \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Get the shape </p>\n": "<p>\u0dc4\u0dd0\u0da9\u0dba\u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dca\u0db1 </p>\n",
 "<p>Permute to <span translate=no>_^_0_^_</span> </p>\n": "<p>\u0d9a\u0dd2\u0dbb\u0dd3\u0db8\u0da7\u0d85\u0dc0\u0dc3\u0dbb <span translate=no>_^_0_^_</span> </p>\n",
 "<p>Reshape to <span translate=no>_^_0_^_</span> </p>\n": "<p>\u0db1\u0dd0\u0dc0\u0dad\u0dc4\u0dd0\u0da9\u0d9c\u0dc3\u0dca\u0dc0\u0db1\u0dca\u0db1 <span translate=no>_^_0_^_</span> </p>\n",
 "<p>We use PyTorch&#x27;s <span translate=no>_^_0_^_</span> module. We add padding to both sides and later crop the right most <span translate=no>_^_1_^_</span> results </p>\n": "<p>\u0d85\u0db4\u0dd2\u0db4\u0dba\u0dd2\u0da7\u0ddd\u0dbb\u0dca\u0da0\u0dca <span translate=no>_^_0_^_</span> \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db8\u0dd4. \u0d85\u0db4\u0dd2 \u0daf\u0dd9\u0db4\u0dd0\u0dad\u0dca\u0dad\u0da7\u0db8 \u0db4\u0dd4\u0dbb\u0dc0\u0db1 \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb \u0db4\u0dc3\u0dd4\u0dc0 \u0db1\u0dd2\u0dc0\u0dd0\u0dbb\u0daf\u0dd2 \u0dc0\u0da9\u0dcf\u0dad\u0dca\u0db8 <span translate=no>_^_1_^_</span> \u0db4\u0dca\u0dbb\u0dad\u0dd2 </p>. \u0dbd \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dd2\u0db8\u0dd4\n",
 "<p>We use PyTorch&#x27;s <span translate=no>_^_0_^_</span> module. We set the number of groups to be equal to the number of channels from each head so that it does a separate convolution (with different kernels) for each channel and head. We add padding to both sides and later crop the right most <span translate=no>_^_1_^_</span> results </p>\n": "<p>\u0d85\u0db4\u0dd2\u0db4\u0dba\u0dd2\u0da7\u0ddd\u0dbb\u0dca\u0da0\u0dca <span translate=no>_^_0_^_</span> \u0db8\u0ddc\u0da9\u0dd2\u0dba\u0dd4\u0dbd\u0dba \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db8\u0dd4. \u0d91\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0db1\u0dcf\u0dbd\u0dd2\u0d9a\u0dcf\u0dc0 \u0dc3\u0dc4 \u0dc4\u0dd2\u0dc3 \u0dc3\u0db3\u0dc4\u0dcf \u0dc0\u0dd9\u0db1\u0db8 \u0dc3\u0d82\u0dc0\u0dc4\u0db1\u0dba\u0d9a\u0dca (\u0dc0\u0dd2\u0dc0\u0dd2\u0db0 \u0d9a\u0dbb\u0dca\u0db1\u0dbd\u0dca \u0dc3\u0db8\u0d9f) \u0dc3\u0dd2\u0daf\u0dd4 \u0dc0\u0db1 \u0db4\u0dbb\u0dd2\u0daf\u0dd2 \u0d91\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0dc4\u0dd2\u0dc3\u0dd9\u0db1\u0dca \u0db1\u0dcf\u0dbd\u0dd2\u0d9a\u0dcf \u0d9c\u0dab\u0db1\u0da7 \u0dc3\u0db8\u0dcf\u0db1 \u0dc0\u0db1 \u0db4\u0dbb\u0dd2\u0daf\u0dd2 \u0d85\u0db4\u0dd2 \u0d9a\u0dab\u0dca\u0da9\u0dcf\u0dba\u0db8\u0dca \u0d9c\u0dab\u0db1 \u0dc3\u0d9a\u0dc3\u0dca \u0d9a\u0dbb\u0db8\u0dd4. \u0d85\u0db4\u0dd2 \u0daf\u0dd9\u0db4\u0dd0\u0dad\u0dca\u0dad\u0da7\u0db8 \u0db4\u0dd4\u0dbb\u0dc0\u0db1 \u0d91\u0d9a\u0dad\u0dd4 \u0d9a\u0dbb \u0db4\u0dc3\u0dd4\u0dc0 \u0db1\u0dd2\u0dc0\u0dd0\u0dbb\u0daf\u0dd2 \u0dc0\u0da9\u0dcf\u0dad\u0dca\u0db8 <span translate=no>_^_1_^_</span> \u0db4\u0dca\u0dbb\u0dad\u0dd2 </p>. \u0dbd \u0dbd\u0db6\u0dcf \u0d9c\u0db1\u0dd2\u0db8\u0dd4\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the number of heads </li>\n<li><span translate=no>_^_1_^_</span> is the number of channels in each head</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span> \u0dc4\u0dd2\u0dc3\u0dca \u0dc3\u0d82\u0d9b\u0dca\u0dba\u0dcf\u0dc0 \u0dc0\u0dda </li>\n<li><span translate=no>_^_1_^_</span> \u0d91\u0d9a\u0dca \u0d91\u0d9a\u0dca \u0dc4\u0dd2\u0dc3\u0dd9\u0dc4\u0dd2 \u0db1\u0dcf\u0dbd\u0dd2\u0d9a\u0dcf \u0d9c\u0dab\u0db1 \u0dc0\u0dda</li></ul>\n",
 "Primer EZ variations": "\u0db4\u0dca\u0dbb\u0dba\u0dd2\u0db8\u0dbb\u0dca EZ \u0dc0\u0dd9\u0db1\u0dc3\u0dca\u0d9a\u0db8\u0dca",
 "We tried some variations to Primer EZ.": "\u0d85\u0db4\u0dd2 \u0db4\u0dca\u0dbb\u0dba\u0dd2\u0db8\u0dbb\u0dca EZ \u0dc0\u0dd9\u0dad \u0dc0\u0dd9\u0db1\u0dc3\u0dca\u0d9a\u0db8\u0dca \u0d9a\u0dd2\u0dc4\u0dd2\u0db4\u0dba\u0d9a\u0dca \u0d8b\u0dad\u0dca\u0dc3\u0dcf\u0dc4 \u0d9a\u0dc5\u0dd9\u0db8\u0dd4."
}