{
 "<h1>Denoising Diffusion Probabilistic Models (DDPM)</h1>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/diffusion/ddpm/experiment.ipynb\"><span translate=no>_^_0_^_</span></a></p>\n<p>This is a <a href=\"https://pytorch.org\">PyTorch</a> implementation/tutorial of the paper <a href=\"https://papers.labml.ai/paper/2006.11239\">Denoising Diffusion Probabilistic Models</a>.</p>\n<p>In simple terms, we get an image from data and add noise step by step. Then We train a model to predict that noise at each step and use the model to generate images.</p>\n<p>The following definitions and derivations show how this works. For details please refer to <a href=\"https://papers.labml.ai/paper/2006.11239\">the paper</a>.</p>\n<h2>Forward Process</h2>\n<p>The forward process adds noise to the data <span translate=no>_^_1_^_</span>, for <span translate=no>_^_2_^_</span> timesteps.</p>\n<span translate=no>_^_3_^_</span><p>where <span translate=no>_^_4_^_</span> is the variance schedule.</p>\n<p>We can sample <span translate=no>_^_5_^_</span> at any timestep <span translate=no>_^_6_^_</span> with,</p>\n<span translate=no>_^_7_^_</span><p>where <span translate=no>_^_8_^_</span> and <span translate=no>_^_9_^_</span></p>\n<h2>Reverse Process</h2>\n<p>The reverse process removes noise starting at <span translate=no>_^_10_^_</span> for <span translate=no>_^_11_^_</span> time steps.</p>\n<span translate=no>_^_12_^_</span><p><span translate=no>_^_13_^_</span> are the parameters we train.</p>\n<h2>Loss</h2>\n<p>We optimize the ELBO (from Jenson&#x27;s inequality) on the negative log likelihood.</p>\n<span translate=no>_^_14_^_</span><p>The loss can be rewritten as follows.</p>\n<span translate=no>_^_15_^_</span><p><span translate=no>_^_16_^_</span> is constant since we keep <span translate=no>_^_17_^_</span> constant.</p>\n<h3>Computing <span translate=no>_^_18_^_</span></h3>\n<p>The forward process posterior conditioned by <span translate=no>_^_19_^_</span> is,</p>\n<span translate=no>_^_20_^_</span><p>The paper sets <span translate=no>_^_21_^_</span> where <span translate=no>_^_22_^_</span> is set to constants <span translate=no>_^_23_^_</span> or <span translate=no>_^_24_^_</span>.</p>\n<p>Then, <span translate=no>_^_25_^_</span></p>\n<p>For given noise <span translate=no>_^_26_^_</span> using <span translate=no>_^_27_^_</span></p>\n<span translate=no>_^_28_^_</span><p>This gives,</p>\n<span translate=no>_^_29_^_</span><p>Re-parameterizing with a model to predict noise</p>\n<span translate=no>_^_30_^_</span><p>where <span translate=no>_^_31_^_</span> is a learned function that predicts <span translate=no>_^_32_^_</span> given <span translate=no>_^_33_^_</span>.</p>\n<p>This gives,</p>\n<span translate=no>_^_34_^_</span><p>That is, we are training to predict the noise.</p>\n<h3>Simplified loss</h3>\n<p><span translate=no>_^_35_^_</span></p>\n<p>This minimizes <span translate=no>_^_36_^_</span> when <span translate=no>_^_37_^_</span> and <span translate=no>_^_38_^_</span> for <span translate=no>_^_39_^_</span> discarding the weighting in <span translate=no>_^_40_^_</span>. Discarding the weights <span translate=no>_^_41_^_</span> increase the weight given to higher <span translate=no>_^_42_^_</span> (which have higher noise levels), therefore increasing the sample quality.</p>\n<p>This file implements the loss calculation and a basic sampling method that we use to generate images during training.</p>\n<p>Here is the <a href=\"unet.html\">UNet model</a> that gives <span translate=no>_^_43_^_</span> and <a href=\"experiment.html\">training code</a>. <a href=\"evaluate.html\">This file</a> can generate samples and interpolations from a trained model.</p>\n": "<h1>\u30ce\u30a4\u30ba\u9664\u53bb\u62e1\u6563\u78ba\u7387\u30e2\u30c7\u30eb (DDPM)</h1>\n<p><a href=\"https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/diffusion/ddpm/experiment.ipynb\"><span translate=no>_^_0_^_</span></a></p>\n<p><a href=\"https://papers.labml.ai/paper/2006.11239\">\u3053\u308c\u306f\u3001\u8ad6\u6587\u300c\u30ce\u30a4\u30ba\u9664\u53bb\u62e1\u6563\u78ba\u7387\u30e2\u30c7\u30eb\u300d<a href=\"https://pytorch.org\">\u306ePyTorch\u5b9f\u88c5/\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u3059</a>\u3002</a></p>\n<p>\u7c21\u5358\u306b\u8a00\u3046\u3068\u3001\u30c7\u30fc\u30bf\u304b\u3089\u753b\u50cf\u3092\u53d6\u5f97\u3057\u3001\u6bb5\u968e\u7684\u306b\u30ce\u30a4\u30ba\u3092\u8ffd\u52a0\u3057\u307e\u3059\u3002\u6b21\u306b\u3001\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u3066\u5404\u30b9\u30c6\u30c3\u30d7\u3067\u305d\u306e\u30ce\u30a4\u30ba\u3092\u4e88\u6e2c\u3057\u3001\u305d\u306e\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3066\u753b\u50cf\u3092\u751f\u6210\u3057\u307e\u3059\u3002</p>\n<p>\u4ee5\u4e0b\u306e\u5b9a\u7fa9\u3068\u6d3e\u751f\u306f\u3001\u3053\u308c\u304c\u3069\u306e\u3088\u3046\u306b\u6a5f\u80fd\u3059\u308b\u304b\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002<a href=\"https://papers.labml.ai/paper/2006.11239\">\u8a73\u3057\u304f\u306f\u8ad6\u6587\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044</a>\u3002</p>\n<h2>\u8ee2\u9001\u30d7\u30ed\u30bb\u30b9</h2>\n<p>\u30d5\u30a9\u30ef\u30fc\u30c9\u51e6\u7406\u3067\u306f<span translate=no>_^_1_^_</span>\u3001<span translate=no>_^_2_^_</span>\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u306e\u30ce\u30a4\u30ba\u304c\u30c7\u30fc\u30bf\u306b\u8ffd\u52a0\u3055\u308c\u307e\u3059\u3002</p>\n<span translate=no>_^_3_^_</span><p><span translate=no>_^_4_^_</span>\u5dee\u7570\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u306f\u3069\u3053\u3067\u3059\u304b\u3002</p>\n<p>\u4ee5\u4e0b\u3092\u4f7f\u7528\u3059\u308b\u3068\u3001<span translate=no>_^_5_^_</span><span translate=no>_^_6_^_</span>\u4efb\u610f\u306e\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u3067\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u307e\u3059\u3002</p>\n<span translate=no>_^_7_^_</span><p><span translate=no>_^_8_^_</span>\u3069\u3053\u3068 <span translate=no>_^_9_^_</span></p>\n<h2>\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30bb\u30b9</h2>\n<p>\u9006\u306e\u51e6\u7406\u3067\u306f<span translate=no>_^_10_^_</span>\u30014 <span translate=no>_^_11_^_</span> \u3064\u306e\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u304b\u3089\u30ce\u30a4\u30ba\u3092\u9664\u53bb\u3057\u307e\u3059\u3002</p>\n<span translate=no>_^_12_^_</span><p><span translate=no>_^_13_^_</span>\u79c1\u305f\u3061\u304c\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u3059\u3002</p>\n<h2>\u640d\u5931</h2>\n<p>\uff08\u30b8\u30a7\u30f3\u30bd\u30f3\u306e\u4e0d\u7b49\u5f0f\u304b\u3089\uff09ELBO\u3092\u8ca0\u306e\u5bfe\u6570\u78ba\u7387\u3067\u6700\u9069\u5316\u3057\u307e\u3059\u3002</p>\n<span translate=no>_^_14_^_</span><p>\u640d\u5931\u306f\u6b21\u306e\u3088\u3046\u306b\u66f8\u304d\u76f4\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p>\n<span translate=no>_^_15_^_</span><p><span translate=no>_^_16_^_</span><span translate=no>_^_17_^_</span>\u79c1\u305f\u3061\u306f\u4e00\u5b9a\u306a\u306e\u3067\u4e00\u5b9a\u3067\u3059\u3002</p>\n<h3>\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0 <span translate=no>_^_18_^_</span></h3>\n<p><span translate=no>_^_19_^_</span>\u6b21\u306e\u6761\u4ef6\u3067\u6761\u4ef6\u4ed8\u3051\u3055\u308c\u305f\u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30bb\u30b9\u306e\u4e8b\u5f8c\u51e6\u7406\u306f</p>\n<span translate=no>_^_20_^_</span><p><span translate=no>_^_21_^_</span><span translate=no>_^_22_^_</span><span translate=no>_^_23_^_</span>\u7528\u7d19\u30bb\u30c3\u30c8\u306f\u5b9a\u6570\u307e\u305f\u306f\u306b\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\u3002<span translate=no>_^_24_^_</span></p>\n<p>\u6b21\u306b\u3001<span translate=no>_^_25_^_</span></p>\n<p><span translate=no>_^_26_^_</span>\u4e0e\u3048\u3089\u308c\u305f\u30ce\u30a4\u30ba\u306b\u5bfe\u3057\u3066 <span translate=no>_^_27_^_</span></p>\n<span translate=no>_^_28_^_</span><p>\u3053\u308c\u306b\u3088\u308a\u3001</p>\n<span translate=no>_^_29_^_</span><p>\u30ce\u30a4\u30ba\u3092\u4e88\u6e2c\u3059\u308b\u305f\u3081\u306e\u30e2\u30c7\u30eb\u306b\u3088\u308b\u518d\u30d1\u30e9\u30e1\u30fc\u30bf\u5316</p>\n<span translate=no>_^_30_^_</span><p><span translate=no>_^_31_^_</span><span translate=no>_^_32_^_</span><span translate=no>_^_33_^_</span>\u4e0e\u3048\u3089\u308c\u305f\u3082\u306e\u3092\u4e88\u6e2c\u3059\u308b\u5b66\u7fd2\u6e08\u307f\u95a2\u6570\u306f\u3069\u3053\u304b</p>\n<p>\u3053\u308c\u306b\u3088\u308a\u3001</p>\n<span translate=no>_^_34_^_</span><p>\u3064\u307e\u308a\u3001\u30ce\u30a4\u30ba\u3092\u4e88\u6e2c\u3059\u308b\u305f\u3081\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002</p>\n<h3>\u7c21\u6613\u640d\u5931</h3>\n<p><span translate=no>_^_35_^_</span></p>\n<p>\u3053\u308c\u306b\u3088\u308a\u3001<span translate=no>_^_36_^_</span><span translate=no>_^_37_^_</span><span translate=no>_^_38_^_</span><span translate=no>_^_39_^_</span>\u30a6\u30a7\u30a4\u30c8\u3092\u5ec3\u68c4\u3059\u308b\u30bf\u30a4\u30df\u30f3\u30b0\u3068\u5ec3\u68c4\u3059\u308b\u30bf\u30a4\u30df\u30f3\u30b0\u3092\u6700\u5c0f\u9650\u306b\u6291\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002<span translate=no>_^_40_^_</span><span translate=no>_^_41_^_</span>\u91cd\u307f\u3092\u6368\u3066\u308b\u3068\u3001<span translate=no>_^_42_^_</span>\uff08\u30ce\u30a4\u30ba\u30ec\u30d9\u30eb\u304c\u9ad8\u3044\uff09\u9ad8\u3044\u307b\u3046\u306b\u4e0e\u3048\u3089\u308c\u308b\u91cd\u307f\u304c\u5897\u3048\u3001\u30b5\u30f3\u30d7\u30eb\u306e\u54c1\u8cea\u304c\u5411\u4e0a\u3057\u307e\u3059</p>\u3002\n<p>\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u4e2d\u306b\u753b\u50cf\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3059\u308b\u640d\u5931\u8a08\u7b97\u3068\u57fa\u672c\u7684\u306a\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u65b9\u6cd5\u304c\u5b9f\u88c5\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>\n<p><a href=\"unet.html\"><span translate=no>_^_43_^_</span><a href=\"experiment.html\">\u3053\u308c\u304c\u30b3\u30fc\u30c9\u3092\u63d0\u4f9b\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308bUNet\u30e2\u30c7\u30eb\u3067\u3059</a></a>\u3002<a href=\"evaluate.html\">\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3067\u306f</a>\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u6e08\u307f\u306e\u30e2\u30c7\u30eb\u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3068\u88dc\u9593\u3092\u751f\u6210\u3067\u304d\u307e\u3059</p>\u3002\n",
 "<h2>Denoise Diffusion</h2>\n": "<h2>\u30ce\u30a4\u30ba\u9664\u53bb</h2>\n",
 "<h4>Get <span translate=no>_^_0_^_</span> distribution</h4>\n<span translate=no>_^_1_^_</span>": "<h4><span translate=no>_^_0_^_</span>\u30c7\u30a3\u30b9\u30c8\u30ea\u30d3\u30e5\u30fc\u30b7\u30e7\u30f3\u3092\u53d6\u5f97</h4>\n<span translate=no>_^_1_^_</span>",
 "<h4>Sample from <span translate=no>_^_0_^_</span></h4>\n<span translate=no>_^_1_^_</span>": "<h4>\u304b\u3089\u306e\u30b5\u30f3\u30d7\u30eb <span translate=no>_^_0_^_</span></h4>\n<span translate=no>_^_1_^_</span>",
 "<h4>Simplified Loss</h4>\n<p><span translate=no>_^_0_^_</span></p>\n": "<h4>\u7c21\u6613\u640d\u5931</h4>\n<p><span translate=no>_^_0_^_</span></p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p><a href=\"utils.html\">gather</a> <span translate=no>_^_0_^_</span> </p>\n": "<p><a href=\"utils.html\">\u96c6\u307e\u308b</a> <span translate=no>_^_0_^_</span></p>\n",
 "<p><a href=\"utils.html\">gather</a> <span translate=no>_^_0_^_</span> and compute <span translate=no>_^_1_^_</span> </p>\n": "<p><a href=\"utils.html\"><span translate=no>_^_0_^_</span>\u53ce\u96c6\u3057\u3066\u8a08\u7b97\u3059\u308b</a> <span translate=no>_^_1_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p>Create <span translate=no>_^_0_^_</span> linearly increasing variance schedule </p>\n": "<p><span translate=no>_^_0_^_</span>\u76f4\u7dda\u7684\u306b\u5897\u52a0\u3059\u308b\u5dee\u7570\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u306e\u4f5c\u6210</p>\n",
 "<p>Get <span translate=no>_^_0_^_</span> </p>\n": "<p>\u53d6\u5f97 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Get batch size </p>\n": "<p>\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u53d6\u5f97</p>\n",
 "<p>Get random <span translate=no>_^_0_^_</span> for each sample in the batch </p>\n": "<p><span translate=no>_^_0_^_</span>\u30d0\u30c3\u30c1\u5185\u306e\u5404\u30b5\u30f3\u30d7\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u53d6\u5f97</p>\n",
 "<p>MSE loss </p>\n": "<p>MSE \u30ed\u30b9</p>\n",
 "<p>Sample </p>\n": "<p>[\u30b5\u30f3\u30d7\u30eb]</p>\n",
 "<p>Sample <span translate=no>_^_0_^_</span> for <span translate=no>_^_1_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span>\u306e\u30b5\u30f3\u30d7\u30eb <span translate=no>_^_1_^_</span></p>\n",
 "<p>Sample from <span translate=no>_^_0_^_</span> </p>\n": "<p>\u304b\u3089\u306e\u30b5\u30f3\u30d7\u30eb <span translate=no>_^_0_^_</span></p>\n",
 "<p>get <span translate=no>_^_0_^_</span> </p>\n": "<p>\u53d6\u5f97 <span translate=no>_^_0_^_</span></p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is <span translate=no>_^_1_^_</span> model </li>\n<li><span translate=no>_^_2_^_</span> is <span translate=no>_^_3_^_</span> </li>\n<li><span translate=no>_^_4_^_</span> is the device to place constants on</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u30e2\u30c7\u30eb\u3067\u3059</li>\n<li><span translate=no>_^_2_^_</span>\u306f <span translate=no>_^_3_^_</span></li>\n<li><span translate=no>_^_4_^_</span>\u5b9a\u6570\u3092\u914d\u7f6e\u3059\u308b\u30c7\u30d0\u30a4\u30b9\u3067\u3059</li></ul>\n",
 "Denoising Diffusion Probabilistic Models (DDPM)": "\u30ce\u30a4\u30ba\u9664\u53bb\u62e1\u6563\u78ba\u7387\u30e2\u30c7\u30eb (DDPM)",
 "PyTorch implementation and tutorial of the paper Denoising Diffusion Probabilistic Models (DDPM).": "PyTorch\u306e\u5b9f\u88c5\u3068\u8ad6\u6587\u300c\u30ce\u30a4\u30ba\u9664\u53bb\u62e1\u6563\u78ba\u7387\u30e2\u30c7\u30eb\uff08DDPM\uff09\u300d\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3002"
}