{
 "<h1>Finetune <a href=\"../../neox/index.html\">GPT-NeoX</a> with <a href=\"index.html\">Zero3 memory optimizer</a></h1>\n<p>This script trains the bias parameters of the <a href=\"../../neox/model.html\">GPT-NeoX model</a>  on multiple devices with Zero-DP Memory Optimization.</p>\n": "<h1><a href=\"index.html\">Zero3 \u30e1\u30e2\u30ea\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u306b\u3088\u308b <a href=\"../../neox/index.html\">GPT-NeOx</a> \u306e\u5fae\u8abf\u6574</a></h1>\n<p>\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u3001<a href=\"../../neox/model.html\">\u30bc\u30edDP\u30e1\u30e2\u30ea\u6700\u9069\u5316\u6a5f\u80fd\u3092\u5099\u3048\u305f\u8907\u6570\u306e\u30c7\u30d0\u30a4\u30b9\u4e0a\u3067GPT-Neox\u30e2\u30c7\u30eb\u306e\u30d0\u30a4\u30a2\u30b9\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3059</a>\u3002</p>\n",
 "<h4>Create the model with Zero3 memory optimizer</h4>\n": "<h4>Zero3 \u30e1\u30e2\u30ea\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u3067\u30e2\u30c7\u30eb\u3092\u4f5c\u6210</h4>\n",
 "<h4>Run the training on the node with rank <span translate=no>_^_0_^_</span>.</h4>\n": "<h4>\u30e9\u30f3\u30af\u306e\u3042\u308b\u30ce\u30fc\u30c9\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u884c\u3057\u307e\u3059<span translate=no>_^_0_^_</span>\u3002</h4>\n",
 "<h4>Set the optimizers for the model</h4>\n<p>Note that we pass the sharded parameters from <span translate=no>_^_0_^_</span>.</p>\n": "<h4>\u30e2\u30c7\u30eb\u306e\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002</h4>\n<p><span translate=no>_^_0_^_</span>\u30b7\u30e3\u30fc\u30c9\u3055\u308c\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u304b\u3089\u6e21\u3059\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p>Create a sequential model </p>\n": "<p>\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30e2\u30c7\u30eb\u306e\u4f5c\u6210</p>\n",
 "<p>Create configurations </p>\n": "<p>\u69cb\u6210\u306e\u4f5c\u6210</p>\n",
 "<p>Create the experiment </p>\n": "<p>\u5b9f\u9a13\u3092\u4f5c\u6210</p>\n",
 "<p>Initialize PyTorch distributed process group </p>\n": "<p>PyTorch \u5206\u6563\u30d7\u30ed\u30bb\u30b9\u30b0\u30eb\u30fc\u30d7\u3092\u521d\u671f\u5316</p>\n",
 "<p>Initialize the model. Do this before the loop for cleaner logs. </p>\n": "<p>\u30e2\u30c7\u30eb\u3092\u521d\u671f\u5316\u3057\u307e\u3059\u3002\u3053\u308c\u3092\u30eb\u30fc\u30d7\u306e\u524d\u306b\u884c\u3063\u3066\u3001\u30ed\u30b0\u3092\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>\n",
 "<p>Load configurations </p>\n": "<p>\u69cb\u6210\u3092\u30ed\u30fc\u30c9</p>\n",
 "<p>Log the machine configurations </p>\n": "<p>\u30de\u30b7\u30f3\u69cb\u6210\u3092\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b</p>\n",
 "<p>Set current device </p>\n": "<p>\u73fe\u5728\u306e\u30c7\u30d0\u30a4\u30b9\u3092\u8a2d\u5b9a</p>\n",
 "<p>Start a process for each GPU. You will need a separate launcher if you are using multiple computers. </p>\n": "<p>GPU \u3054\u3068\u306b\u30d7\u30ed\u30bb\u30b9\u3092\u958b\u59cb\u3057\u307e\u3059\u3002\u8907\u6570\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fc\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u5225\u306e\u30e9\u30f3\u30c1\u30e3\u30fc\u304c\u5fc5\u8981\u306b\u306a\u308a\u307e\u3059</p>\u3002\n",
 "<p>Start the experiment </p>\n": "<p>\u5b9f\u9a13\u3092\u59cb\u3081\u308b</p>\n",
 "<p>To make sure the fine tuner sets the trainable parameters </p>\n": "<p>\u5fae\u8abf\u6574\u5668\u304c\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u53ef\u80fd\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u306b\u306f</p>\n",
 "<p>Train the model </p>\n": "<p>\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0</p>\n",
 "<p>Use the <a href=\"../../neox/samples/finetune.html\">Pipeline Parallel Trainer configurations</a> and adapt it for Zero3 memory optimizer. </p>\n": "<p><a href=\"../../neox/samples/finetune.html\">\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u30d1\u30e9\u30ec\u30eb\u30c8\u30ec\u30fc\u30ca\u30fc\u306e\u8a2d\u5b9a\u3092\u4f7f\u7528\u3057\u3066</a>\u3001Zero3 \u30e1\u30e2\u30ea\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306b\u9069\u5fdc\u3055\u305b\u3066\u304f\u3060\u3055\u3044\u3002</p>\n",
 "<p>Wrap the layers with <span translate=no>_^_0_^_</span> </p>\n": "<p>\u30ec\u30a4\u30e4\u30fc\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30e9\u30c3\u30d4\u30f3\u30b0\u3057\u307e\u3059\u3002<span translate=no>_^_0_^_</span></p>\n",
 "Finetune GPT-NeoX with Zero3 memory optimizer": "Zero3 \u30e1\u30e2\u30ea\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u306b\u3088\u308b GPT-NeOx \u306e\u5fae\u8abf\u6574",
 "This script trains the bias parameters of the GPT-NeoX on multiple devices with Zero-DP Memory Optimization.": "\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u3001\u30bc\u30edDP\u30e1\u30e2\u30ea\u6700\u9069\u5316\u3092\u4f7f\u7528\u3057\u3066\u8907\u6570\u306e\u30c7\u30d0\u30a4\u30b9\u3067GPT-Neox\u306e\u30d0\u30a4\u30a2\u30b9\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3059\u3002"
}