{
 "<h1>Text Dataset for GPT-NeoX</h1>\n": "<h1>GPT-NEOX \u7684\u6587\u672c\u6570\u636e\u96c6</h1>\n",
 "<h2>Dataset for fine-tuning GPT-NeoX</h2>\n<p>This is not optimized to very large datasets.</p>\n": "<h2>\u7528\u4e8e\u5fae\u8c03 GPT-NEOX \u7684\u6570\u636e\u96c6</h2>\n<p>\u8fd9\u5e76\u672a\u9488\u5bf9\u975e\u5e38\u5927\u7684\u6570\u636e\u96c6\u8fdb\u884c\u4f18\u5316\u3002</p>\n",
 "<h3>Get a sample</h3>\n<ul><li><span translate=no>_^_0_^_</span>  is the index of the sample </li>\n<p><em>Returns</em>  the input and the target</p></ul>\n": "<h3>\u83b7\u53d6\u6837\u54c1</h3>\n<ul><li><span translate=no>_^_0_^_</span>\u662f\u6837\u672c\u7684\u7d22\u5f15</li>\n<p><em>\u8fd4\u56de</em>\u8f93\u5165\u548c\u76ee\u6807</p></ul>\n",
 "<h3>Load Dataset</h3>\n<ul><li><span translate=no>_^_0_^_</span>  is the sequence length of a single training sample </li>\n<li><span translate=no>_^_1_^_</span>  is the name of the dataset </li>\n<p><em>Returns</em>  the dataset</p></ul>\n": "<h3>\u52a0\u8f7d\u6570\u636e\u96c6</h3>\n<ul><li><span translate=no>_^_0_^_</span>\u662f\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u5e8f\u5217\u957f\u5ea6</li>\n<li><span translate=no>_^_1_^_</span>\u662f\u6570\u636e\u96c6\u7684\u540d\u79f0</li>\n<p><em>\u8fd4\u56de</em>\u6570\u636e\u96c6</p></ul>\n",
 "<h3>Load text file</h3>\n<ul><li><span translate=no>_^_0_^_</span>  is the location of the text file </li>\n<li><span translate=no>_^_1_^_</span>  is the URL to download the file from </li>\n<li><span translate=no>_^_2_^_</span>  is the number of characters to filter.  Use this during testing when trying large datasets </li>\n<p><em>Returns</em>  the text content</p></ul>\n": "<h3>\u52a0\u8f7d\u6587\u672c\u6587\u4ef6</h3>\n<ul><li><span translate=no>_^_0_^_</span>\u662f\u6587\u672c\u6587\u4ef6\u7684\u4f4d\u7f6e</li>\n<li><span translate=no>_^_1_^_</span>\u662f\u4ece\u4e2d\u4e0b\u8f7d\u6587\u4ef6\u7684 URL</li>\n<li><span translate=no>_^_2_^_</span>\u662f\u8981\u7b5b\u9009\u7684\u5b57\u7b26\u6570\u3002\u5728\u6d4b\u8bd5\u671f\u95f4\u5c1d\u8bd5\u5927\u578b\u6570\u636e\u96c6\u65f6\u4f7f\u7528\u6b64</li>\u9009\u9879\n<p><em>\u8fd4\u56de</em>\u6587\u672c\u5185\u5bb9</p></ul>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p>Create a PyTorch tensor </p>\n": "<p>\u521b\u5efa\u4e00\u4e2a pyTorch \u5f20\u91cf</p>\n",
 "<p>Download if it doesn&#x27;t exist </p>\n": "<p>\u5982\u679c\u4e0d\u5b58\u5728\uff0c\u8bf7\u4e0b\u8f7d</p>\n",
 "<p>Filter </p>\n": "<p>\u7b5b\u9009</p>\n",
 "<p>Load data </p>\n": "<p>\u52a0\u8f7d\u6570\u636e</p>\n",
 "<p>Load the content </p>\n": "<p>\u52a0\u8f7d\u5185\u5bb9</p>\n",
 "<p>Number of samples </p>\n": "<p>\u6837\u672c\u6570\u91cf</p>\n",
 "<p>Tokenize </p>\n": "<p>Tokenize</p>\n",
 "<p>Truncate </p>\n": "<p>\u622a\u65ad</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  is the list of token ids </li>\n<li><span translate=no>_^_1_^_</span>  is the sequence length of a single training sample</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u4ee4\u724c ID \u7684\u5217\u8868</li>\n<li><span translate=no>_^_1_^_</span>\u662f\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u5e8f\u5217\u957f\u5ea6</li></ul>\n",
 "Loads text datasets to fine-tune GPT-NeoX": "\u52a0\u8f7d\u6587\u672c\u6570\u636e\u96c6\u4ee5\u5fae\u8c03 GPT-NEOX",
 "Text Dataset for GPT-NeoX": "GPT-NEOX \u7684\u6587\u672c\u6570\u636e\u96c6"
}