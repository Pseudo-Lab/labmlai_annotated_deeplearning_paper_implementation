{
 "<h1>GPT-NeoX</h1>\n<p>This is a simple implementation of <a href=\"https://papers.labml.ai/paper/2204.06745\">Eleuther GPT-NeoX</a> for inference and fine-tuning.</p>\n<ul><li><a href=\"model.html\">Model definition</a> </li>\n<li><a href=\"tokenizer.html\">Tokenizer</a> </li>\n<li><a href=\"checkpoint.html\">Checkpoint downloading and loading helpers</a> </li>\n<li><a href=\"utils/index.html\">Utilities</a> </li>\n<li><a href=\"utils/llm_int8.html\">LLM.int8() quantization</a></li></ul>\n<h3><a href=\"samples/__init__.py\">Samples</a></h3>\n<ul><li><a href=\"samples/generate.html\">Generating text</a> </li>\n<li><a href=\"samples/finetune.html\">Fine-tuning the biases with pipeline-parallel</a> </li>\n<li><a href=\"samples/llm_int8.html\">Generating text with LLM.int8()</a></li></ul>\n<h3><a href=\"evaluation/__init__.py\">Evaluation</a></h3>\n<ul><li><a href=\"evaluation/half_precision.html\">Evaluating half precision model on a single GPU</a> </li>\n<li><a href=\"evaluation/llm_int8.html\">Evaluating LLM.int8() model</a></li></ul>\n<p><strong>Official <a href=\"https://www.eleuther.ai\">Eleuther</a> GPT-NoeX is source code is available at <a href=\"https://github.com/eleutherai/gpt-neox\">eleutherai/gpt-neox</a>.</strong></p>\n": "<h1>GPT \u30cd\u30aa\u30c3\u30af\u30b9</h1>\n<p>\u3053\u308c\u306f\u3001<a href=\"https://papers.labml.ai/paper/2204.06745\">\u63a8\u8ad6\u3068\u5fae\u8abf\u6574\u306e\u305f\u3081\u306eEleuther GPT-Neox\u306e\u7c21\u5358\u306a\u5b9f\u88c5\u3067\u3059</a>\u3002</p>\n<ul><li><a href=\"model.html\">\u30e2\u30c7\u30eb\u5b9a\u7fa9</a></li>\n<li><a href=\"tokenizer.html\">\u30c8\u30fc\u30af\u30ca\u30a4\u30b6\u30fc</a></li>\n<li><a href=\"checkpoint.html\">\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3068\u8aad\u307f\u8fbc\u307f\u30d8\u30eb\u30d1\u30fc</a></li>\n<li><a href=\"utils/index.html\">\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3</a></li>\n<li><a href=\"utils/llm_int8.html\">llm.int8 () \u91cf\u5b50\u5316</a></li></ul>\n<h3><a href=\"samples/__init__.py\">[\u30b5\u30f3\u30d7\u30eb]</a></h3>\n<ul><li><a href=\"samples/generate.html\">\u30c6\u30ad\u30b9\u30c8\u306e\u751f\u6210</a></li>\n<li><a href=\"samples/finetune.html\">\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u30d1\u30e9\u30ec\u30eb\u306b\u3088\u308b\u30d0\u30a4\u30a2\u30b9\u306e\u5fae\u8abf\u6574</a></li>\n<li><a href=\"samples/llm_int8.html\">LLM.int8 () \u3092\u4f7f\u7528\u3057\u3066\u30c6\u30ad\u30b9\u30c8\u3092\u751f\u6210\u3059\u308b</a></li></ul>\n<h3><a href=\"evaluation/__init__.py\">\u8a55\u4fa1</a></h3>\n<ul><li><a href=\"evaluation/half_precision.html\">\u5358\u4e00\u306e GPU \u3067\u306e\u534a\u7cbe\u5ea6\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1</a></li>\n<li><a href=\"evaluation/llm_int8.html\">LLM.int8 () \u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\u4e2d</a></li></ul>\n<p><strong><a href=\"https://www.eleuther.ai\">Eleuther GPT-noex\u306e\u516c\u5f0f\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306feleutherai/gpt-neox\u3067\u5165\u624b\u3067\u304d\u307e\u3059</a><a href=\"https://github.com/eleutherai/gpt-neox\">\u3002</a></strong></p>\n",
 "GPT-NeoX": "GPT \u30cd\u30aa\u30c3\u30af\u30b9",
 "Simple GPT-NeoX implementation": "\u30b7\u30f3\u30d7\u30eb\u306a GPT \u30cd\u30aa\u30c3\u30af\u30b9\u306e\u5b9f\u88c5"
}