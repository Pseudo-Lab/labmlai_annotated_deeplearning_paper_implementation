{
 "<h1>Evaluate GPT-NeoX using LLM.int8() quantization on test suite</h1>\n<p>This code evaluate <a href=\"../index.html\">GPT-NeoX</a> using <a href=\"../utils/llm_int8.html\">LLM.int8() quantization</a>, on a suite of tasks.</p>\n": "<h1>LLM.INT8\u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db8\u0dd2\u0db1\u0dca \u0da2\u0dd3\u0db4\u0dd3\u0da7\u0dd3-\u0db1\u0dd2\u0dba\u0ddd\u0d9a\u0dca\u0dc3\u0dca \u0dad\u0d9a\u0dca\u0dc3\u0dda\u0dbb\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1 () \u0db4\u0dbb\u0dd3\u0d9a\u0dca\u0dc2\u0dab \u0d9a\u0da7\u0dca\u0da7\u0dbd\u0dba \u0db8\u0dad \u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0d9a\u0dbb\u0dab\u0dba</h1>\n<p>\u0db8\u0dd9\u0db8\u0d9a\u0dda\u0dad\u0dba <a href=\"../utils/llm_int8.html\">LLM.INT8 () \u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0d9a\u0dbb\u0dab\u0dba</a> \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db8\u0dd2\u0db1\u0dca <a href=\"../index.html\">\u0da2\u0dd3\u0db4\u0dd3\u0da7\u0dd3-\u0db1\u0dd2\u0dba\u0ddd\u0d9a\u0dca\u0dc3\u0dca</a> \u0d87\u0d9c\u0dba\u0dd3\u0db8\u0da7 \u0dbd\u0d9a\u0dca \u0d9a\u0dbb\u0dba\u0dd2, \u0d9a\u0dcf\u0dbb\u0dca\u0dba\u0dba\u0db1\u0dca \u0d9a\u0da7\u0dca\u0da7\u0dbd\u0dba\u0d9a\u0dca \u0db8\u0dad. </p>\n",
 "<p> </p>\n": "<p> </p>\n",
 "<p>Create <span translate=no>_^_0_^_</span> model </p>\n": "<p><span translate=no>_^_0_^_</span> \u0d86\u0d9a\u0dd8\u0dad\u0dd2\u0dba \u0dc3\u0dcf\u0daf\u0db1\u0dca\u0db1 </p>\n",
 "<p>Device </p>\n": "<p>\u0d8b\u0db4\u0dcf\u0d82\u0d9c\u0dba </p>\n",
 "<p>Load layers </p>\n": "<p>\u0dc3\u0dca\u0dae\u0dbb\u0db4\u0dd6\u0dbb\u0dab\u0dba \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>Load layers in float16 into CPU. We convert the layers to int8 later, because doing that on the fly after loading layers to GPU causes CUDA memory fragmentation (about 3GB memory can get lost due to fragmentation). </p>\n": "<p>\u0db4\u0dcf\u0dc0\u0dd9\u0db116 \u0dc4\u0dd2 \u0dc3\u0dca\u0dae\u0dbb CPU \u0dad\u0dd4\u0dc5\u0da7 \u0db4\u0da7\u0dc0\u0db1\u0dca\u0db1. \u0d85\u0db4\u0dd2 \u0dc3\u0dca\u0dae\u0dbb \u0db4\u0dc3\u0dd4\u0dc0 int8 \u0db6\u0dc0\u0da7 \u0db4\u0dbb\u0dd2\u0dc0\u0dbb\u0dca\u0dad\u0db1\u0dba \u0d9a\u0dbb\u0db8\u0dd4, \u0db8\u0db1\u0dca\u0daf \u0dc3\u0dca\u0dae\u0dbb GPU \u0dc0\u0dd9\u0dad \u0db4\u0dd0\u0da7\u0dc0\u0dd3\u0db8\u0dd9\u0db1\u0dca \u0db4\u0dc3\u0dd4 \u0db4\u0dd2\u0dba\u0dcf\u0dc3\u0dbb \u0d9a\u0dd2\u0dbb\u0dd3\u0db8 CUDA \u0db8\u0dad\u0d9a \u0d9b\u0dab\u0dca\u0da9\u0db1\u0dba \u0dc0\u0dd3\u0db8\u0da7 \u0dc4\u0dda\u0dad\u0dd4 \u0dc0\u0dda (3GB \u0db4\u0db8\u0dab \u0db8\u0dad\u0d9a\u0dba \u0d9a\u0dd0\u0db6\u0dbd\u0dd2 \u0dc0\u0dd3\u0db8 \u0db1\u0dd2\u0dc3\u0dcf \u0d85\u0dc4\u0dd2\u0db8\u0dd2 \u0dc0\u0dd2\u0dba \u0dc4\u0dd0\u0d9a). </p>\n",
 "<p>Run <a href=\"index.html\">evaluation harness</a> </p>\n": "<p><a href=\"index.html\">\u0d87\u0d9c\u0dba\u0dd3\u0db8\u0dca \u0db4\u0da7\u0dd2</a> \u0db0\u0dcf\u0dc0\u0db1\u0dba \u0d9a\u0dbb\u0db1\u0dca\u0db1 </p>\n",
 "<p>This reduces CUDA memory fragmentation </p>\n": "<p>\u0db8\u0dd9\u0dbaCUDA \u0db8\u0dad\u0d9a \u0d9b\u0dab\u0dca\u0da9\u0db1\u0dba \u0d85\u0da9\u0dd4 \u0d9a\u0dbb\u0dba\u0dd2 </p>\n",
 "Evaluate GPT-NeoX using LLM.int8() quantization on test suite": "LLM.INT8 \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dcf \u0d9a\u0dbb\u0db8\u0dd2\u0db1\u0dca \u0da2\u0dd3\u0db4\u0dd3\u0da7\u0dd3-\u0db1\u0dd2\u0dba\u0ddd\u0d9a\u0dca\u0dc3\u0dca \u0dad\u0d9a\u0dca\u0dc3\u0dda\u0dbb\u0dd4 \u0d9a\u0dbb\u0db1\u0dca\u0db1 () \u0db4\u0dbb\u0dd3\u0d9a\u0dca\u0dc2\u0dab \u0d9a\u0da7\u0dca\u0da7\u0dbd\u0dba \u0db8\u0dad \u0db4\u0dca\u0dbb\u0db8\u0dcf\u0dab\u0d9a\u0dbb\u0dab\u0dba"
}