{
 "<h1>Recurrent Highway Networks</h1>\n<p>This is a <a href=\"https://pytorch.org\">PyTorch</a> implementation of <a href=\"https://papers.labml.ai/paper/1607.03474\">Recurrent Highway Networks</a>.</p>\n": "<h1>\u30ea\u30ab\u30ec\u30f3\u30c8\u30cf\u30a4\u30a6\u30a7\u30a4\u30cd\u30c3\u30c8\u30ef\u30fc\u30af</h1>\n<p>\u3053\u308c\u306f\u3001<a href=\"https://pytorch.org\"><a href=\"https://papers.labml.ai/paper/1607.03474\">\u30ea\u30ab\u30ec\u30f3\u30c8\u30cf\u30a4\u30a6\u30a7\u30a4\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306ePyTorch\u5b9f\u88c5\u3067\u3059</a></a>\u3002</p>\n",
 "<h2>Multilayer Recurrent Highway Network</h2>\n": "<h2>\u591a\u5c64\u30ea\u30ab\u30ec\u30f3\u30c8\u30cf\u30a4\u30a6\u30a7\u30a4\u30cd\u30c3\u30c8\u30ef\u30fc\u30af</h2>\n",
 "<h2>Recurrent Highway Network Cell</h2>\n<p>This implements equations <span translate=no>_^_0_^_</span>.</p>\n<p><span translate=no>_^_1_^_</span></p>\n<p>where</p>\n<span translate=no>_^_2_^_</span><p>and for <span translate=no>_^_3_^_</span></p>\n<span translate=no>_^_4_^_</span><p><span translate=no>_^_5_^_</span> stands for element-wise multiplication.</p>\n<p>Here we have made a couple of changes to notations from the paper. To avoid confusion with time, gate is represented with <span translate=no>_^_6_^_</span>, which was <span translate=no>_^_7_^_</span> in the paper. To avoid confusion with multiple layers we use <span translate=no>_^_8_^_</span> for depth and <span translate=no>_^_9_^_</span> for total depth instead of <span translate=no>_^_10_^_</span> and <span translate=no>_^_11_^_</span> from the paper.</p>\n<p>We have also replaced the weight matrices and bias vectors from the equations with linear transforms, because that&#x27;s how the implementation is going to look like.</p>\n<p>We implement weight tying, as described in paper, <span translate=no>_^_12_^_</span>.</p>\n": "<h2>\u30ea\u30ab\u30ec\u30f3\u30c8\u30cf\u30a4\u30a6\u30a7\u30a4\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30bb\u30eb</h2>\n<p><span translate=no>_^_0_^_</span>\u3053\u308c\u306f\u65b9\u7a0b\u5f0f\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002</p>\n<p><span translate=no>_^_1_^_</span></p>\n<p>\u3069\u3053</p>\n<span translate=no>_^_2_^_</span><p>\u305d\u3057\u3066\u306b\u3068\u3063\u3066 <span translate=no>_^_3_^_</span></p>\n<span translate=no>_^_4_^_</span><p><span translate=no>_^_5_^_</span>\u8981\u7d20\u3054\u3068\u306e\u4e57\u7b97\u306e\u7565\u3067\u3059\u3002</p>\n<p>\u3053\u3053\u3067\u306f\u3001\u8ad6\u6587\u306e\u8868\u8a18\u306b\u3044\u304f\u3064\u304b\u5909\u66f4\u3092\u52a0\u3048\u307e\u3057\u305f\u3002\u6642\u9593\u3068\u306e\u6df7\u540c\u3092\u907f\u3051\u308b\u305f\u3081\u3001<span translate=no>_^_6_^_</span>\u30b2\u30fc\u30c8\u306f\u7d19\u306b\u8f09\u3063\u3066\u3044\u305f\u300c\u300d<span translate=no>_^_7_^_</span> \u3067\u8868\u3057\u3066\u3044\u308b\u3002\u8907\u6570\u306e\u30ec\u30a4\u30e4\u30fc\u3068\u6df7\u540c\u3057\u306a\u3044\u3088\u3046\u306b\u3001<span translate=no>_^_8_^_</span><span translate=no>_^_9_^_</span><span translate=no>_^_10_^_</span><span translate=no>_^_11_^_</span>\u7d19\u306e\u5965\u884c\u304d\u3068\u5168\u4f53\u306e\u5965\u884c\u304d\u3092\u7d19\u306e\u4ee3\u308f\u308a\u306b\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059</p>\u3002\n<p>\u307e\u305f\u3001\u65b9\u7a0b\u5f0f\u306b\u542b\u307e\u308c\u308b\u91cd\u307f\u884c\u5217\u3068\u30d0\u30a4\u30a2\u30b9\u30d9\u30af\u30c8\u30eb\u3092\u7dda\u5f62\u5909\u63db\u306b\u7f6e\u304d\u63db\u3048\u307e\u3057\u305f\u3002\u3053\u308c\u304c\u5b9f\u88c5\u306e\u3088\u3046\u306b\u306a\u308b\u305f\u3081\u3067\u3059\u3002</p>\n<p>\u8ad6\u6587\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u3088\u3046\u306b\u3001\u30a6\u30a8\u30a4\u30c8\u30bf\u30a4\u30a4\u30f3\u30b0\u3092\u5b9f\u65bd\u3057\u3066\u3044\u307e\u3059\u3002<span translate=no>_^_12_^_</span></p>\n",
 "<p> <span translate=no>_^_0_^_</span> has shape <span translate=no>_^_1_^_</span> and <span translate=no>_^_2_^_</span> has shape <span translate=no>_^_3_^_</span>.</p>\n": "<p><span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span><span translate=no>_^_2_^_</span><span translate=no>_^_3_^_</span>\u5f62\u304c\u3042\u3063\u3066\u5f62\u304c\u3042\u308b</p>\n",
 "<p> <span translate=no>_^_0_^_</span> is the feature length of the input and <span translate=no>_^_1_^_</span> is the feature length of the cell. <span translate=no>_^_2_^_</span> is <span translate=no>_^_3_^_</span>.</p>\n": "<p><span translate=no>_^_0_^_</span>\u306f\u5165\u529b\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u9577\u3001<span translate=no>_^_1_^_</span>\u306f\u30bb\u30eb\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u9577\u3067\u3059\u3002<span translate=no>_^_2_^_</span>\u3067\u3059<span translate=no>_^_3_^_</span>\u3002</p>\n",
 "<p> Create a network of <span translate=no>_^_0_^_</span> of recurrent highway network layers, each with depth <span translate=no>_^_1_^_</span>, <span translate=no>_^_2_^_</span>.</p>\n": "<p><span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u305d\u308c\u305e\u308c\u5965\u884c\u304d\u306e\u3042\u308b\u9ad8\u901f\u9053\u8def\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u6210\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002<span translate=no>_^_2_^_</span></p>\n",
 "<p>Array to collect the outputs of the final layer at each time step. </p>\n": "<p>\u5404\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u3067\u6700\u7d42\u30ec\u30a4\u30e4\u30fc\u306e\u51fa\u529b\u3092\u53ce\u96c6\u3059\u308b\u914d\u5217\u3002</p>\n",
 "<p>Collect the output of the final layer </p>\n": "<p>\u6700\u7d42\u30ec\u30a4\u30e4\u30fc\u306e\u51fa\u529b\u3092\u96c6\u3081\u308b</p>\n",
 "<p>Create cells for each layer. Note that only the first layer gets the input directly. Rest of the layers get the input from the layer below </p>\n": "<p>\u30ec\u30a4\u30e4\u30fc\u3054\u3068\u306b\u30bb\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u6700\u521d\u306e\u30ec\u30a4\u30e4\u30fc\u3060\u3051\u304c\u76f4\u63a5\u5165\u529b\u3092\u53d6\u5f97\u3059\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u6b8b\u308a\u306e\u30ec\u30a4\u30e4\u30fc\u306f\u3001\u4e0b\u306e\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u5165\u529b\u3092\u53d6\u5f97\u3057\u307e\u3059</p>\u3002\n",
 "<p>Get the state of the layer </p>\n": "<p>\u30ec\u30a4\u30e4\u30fc\u306e\u72b6\u614b\u3092\u53d6\u5f97</p>\n",
 "<p>Initialize the state if <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6b21\u306e\u5834\u5408\u306b\u30b9\u30c6\u30fc\u30c8\u3092\u521d\u671f\u5316\u3057\u307e\u3059 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Input to the first layer is the input itself </p>\n": "<p>\u6700\u521d\u306e\u30ec\u30a4\u30e4\u30fc\u3078\u306e\u5165\u529b\u306f\u5165\u529b\u305d\u306e\u3082\u306e\u3067\u3059</p>\n",
 "<p>Input to the next layer is the state of this layer </p>\n": "<p>\u6b21\u306e\u30ec\u30a4\u30e4\u30fc\u3078\u306e\u5165\u529b\u306f\u3001\u3053\u306e\u30ec\u30a4\u30e4\u30fc\u306e\u72b6\u614b\u3067\u3059</p>\n",
 "<p>Iterate <span translate=no>_^_0_^_</span> </p>\n": "<p>\u7e70\u308a\u8fd4\u3057 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Loop through the layers </p>\n": "<p>\u30ec\u30a4\u30e4\u30fc\u3092\u30eb\u30fc\u30d7\u3059\u308b</p>\n",
 "<p>Reverse stack the state to get the state of each layer</p>\n<p>\ud83d\udcdd You can just work with the tensor itself but this is easier to debug </p>\n": "<p>\u30b9\u30c6\u30fc\u30c8\u3092\u9006\u306b\u30b9\u30bf\u30c3\u30af\u3057\u3066\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u72b6\u614b\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002</p>\n<p>\ud83d\udcdd \u30c6\u30f3\u30bd\u30eb\u81ea\u4f53\u3067\u4f5c\u696d\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u304c\u3001\u30c7\u30d0\u30c3\u30b0\u306f\u7c21\u5358\u3067\u3059</p>\n",
 "<p>Run through the network for each time step </p>\n": "<p>\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u3054\u3068\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u7d4c\u7531\u3067\u5b9f\u884c</p>\n",
 "<p>Similarly we combine <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span>. </p>\n": "<p>\u540c\u69d8\u306b\u3001<span translate=no>_^_0_^_</span>\u3068\u3092\u7d44\u307f\u5408\u308f\u305b\u307e\u3059<span translate=no>_^_1_^_</span>\u3002</p>\n",
 "<p>Stack the outputs and states </p>\n": "<p>\u51fa\u529b\u3068\u30b9\u30c6\u30fc\u30c8\u3092\u7a4d\u307f\u91cd\u306d\u308b</p>\n",
 "<p>The input is used only when <span translate=no>_^_0_^_</span> is <span translate=no>_^_1_^_</span>. </p>\n": "<p>\u5165\u529b\u306f\u3001<span translate=no>_^_0_^_</span>\u306e\u5834\u5408\u306b\u306e\u307f\u4f7f\u7528\u3055\u308c\u307e\u3059<span translate=no>_^_1_^_</span>\u3002</p>\n",
 "<p>Use the first half of <span translate=no>_^_0_^_</span> to get <span translate=no>_^_1_^_</span></p>\n<span translate=no>_^_2_^_</span><p> </p>\n": "<p><span translate=no>_^_0_^_</span>\u524d\u534a\u3092\u4f7f\u3046\u3068 <span translate=no>_^_1_^_</span></p>\n<span translate=no>_^_2_^_</span><p></p>\n",
 "<p>Use the second half of <span translate=no>_^_0_^_</span> to get <span translate=no>_^_1_^_</span></p>\n<span translate=no>_^_2_^_</span><p> </p>\n": "<p><span translate=no>_^_0_^_</span>\u306e\u5f8c\u534a\u3092\u4f7f\u3046\u3068 <span translate=no>_^_1_^_</span></p>\n<span translate=no>_^_2_^_</span><p></p>\n",
 "<p>We calculate the concatenation of linear transforms for <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> </p>\n": "<p>\u3068\u306e\u7dda\u5f62\u5909\u63db\u306e\u9023\u7d50\u3092\u8a08\u7b97\u3057\u307e\u3059 <span translate=no>_^_0_^_</span> <span translate=no>_^_1_^_</span></p>\n",
 "<p>We combine <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span>, with a single linear layer. We can then split the results to get the <span translate=no>_^_2_^_</span> and <span translate=no>_^_3_^_</span> components. This is the <span translate=no>_^_4_^_</span> and <span translate=no>_^_5_^_</span> for <span translate=no>_^_6_^_</span>. </p>\n": "<p><span translate=no>_^_0_^_</span>\u3068<span translate=no>_^_1_^_</span>\u3001\u3092\u5358\u4e00\u306e\u7dda\u5f62\u30ec\u30a4\u30e4\u30fc\u3068\u7d44\u307f\u5408\u308f\u305b\u307e\u3059\u3002\u305d\u306e\u5f8c\u3001<span translate=no>_^_2_^_</span><span translate=no>_^_3_^_</span>\u7d50\u679c\u3092\u5206\u5272\u3057\u3066\u304a\u3088\u3073\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u53d6\u5f97\u3067\u304d\u307e\u3059\u3002<span translate=no>_^_4_^_</span><span translate=no>_^_5_^_</span><span translate=no>_^_6_^_</span>\u3053\u308c\u304c\u304a\u3088\u3073\u7528\u3067\u3059\u3002</p>\n",
 "A simple PyTorch implementation/tutorial of Recurrent Highway Networks.": "\u30ea\u30ab\u30ec\u30f3\u30c8\u30cf\u30a4\u30a6\u30a7\u30a4\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u7c21\u5358\u306a PyTorch \u5b9f\u88c5/\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3002",
 "Recurrent Highway Networks": "\u30ea\u30ab\u30ec\u30f3\u30c8\u30cf\u30a4\u30a6\u30a7\u30a4\u30cd\u30c3\u30c8\u30ef\u30fc\u30af"
}