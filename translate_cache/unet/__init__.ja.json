{
 "<h1>U-Net</h1>\n<p>This is an implementation of the U-Net model from the paper, <a href=\"https://papers.labml.ai/paper/1505.04597\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>.</p>\n<p>U-Net consists of a contracting path and an expansive path. The contracting path is a series of convolutional layers and pooling layers, where the resolution of the feature map gets progressively reduced. Expansive path is a series of up-sampling layers and convolutional layers where the resolution of the feature map gets progressively increased.</p>\n<p>At every step in the expansive path the corresponding feature map from the contracting path concatenated with the current feature map.</p>\n<p><span translate=no>_^_0_^_</span></p>\n<p>Here is the <a href=\"experiment.html\">training code</a> for an experiment that trains a U-Net on <a href=\"carvana.html\">Carvana dataset</a>.</p>\n": "<h1>\u30e6\u30fc\u30cd\u30c3\u30c8</h1>\n<p>\u3053\u308c\u306f\u3001\u8ad6\u6587\u300cU-Net<a href=\"https://papers.labml.ai/paper/1505.04597\">: \u751f\u7269\u533b\u5b66\u753b\u50cf\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u306e\u305f\u3081\u306e\u7573\u307f\u8fbc\u307f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u300d\u306eU-Net\u30e2\u30c7\u30eb\u306e\u5b9f\u88c5\u3067\u3059</a>\u3002</p>\n<p>U-Net\u306f\u53ce\u7e2e\u7d4c\u8def\u3068\u62e1\u5f35\u7d4c\u8def\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u53ce\u7e2e\u7d4c\u8def\u306f\u4e00\u9023\u306e\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3067\u3042\u308a\u3001\u7279\u5fb4\u30de\u30c3\u30d7\u306e\u89e3\u50cf\u5ea6\u306f\u5f90\u3005\u306b\u4f4e\u4e0b\u3057\u307e\u3059\u3002\u30a8\u30af\u30b9\u30d1\u30f3\u30b7\u30d6\u30d1\u30b9\u3068\u306f\u3001\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u306e\u89e3\u50cf\u5ea6\u304c\u5f90\u3005\u306b\u4e0a\u304c\u3063\u3066\u3044\u304f\u4e00\u9023\u306e\u30a2\u30c3\u30d7\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30a4\u30e4\u30fc\u3068\u7573\u307f\u8fbc\u307f\u30ec\u30a4\u30e4\u30fc\u306e\u3053\u3068\u3067\u3059</p>\u3002\n<p>\u62e1\u5f35\u30d1\u30b9\u306e\u5404\u30b9\u30c6\u30c3\u30d7\u3067\u3001\u7e2e\u5c0f\u30d1\u30b9\u304b\u3089\u306e\u5bfe\u5fdc\u3059\u308b\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u304c\u73fe\u5728\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u3068\u9023\u7d50\u3055\u308c\u307e\u3059\u3002</p>\n<p><span translate=no>_^_0_^_</span></p>\n<p>\u3053\u308c\u306f\u3001<a href=\"experiment.html\"><a href=\"carvana.html\">Carvana\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067U-Net\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u5b9f\u9a13\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b3\u30fc\u30c9\u3067\u3059</a></a>\u3002</p>\n",
 "<h2>U-Net</h2>\n": "<h2>\u30e6\u30fc\u30cd\u30c3\u30c8</h2>\n",
 "<h3>Crop and Concatenate the feature map</h3>\n<p>At every step in the expansive path the corresponding feature map from the contracting path concatenated with the current feature map.</p>\n": "<h3>\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u306e\u30c8\u30ea\u30df\u30f3\u30b0\u3068\u9023\u7d50</h3>\n<p>\u62e1\u5f35\u30d1\u30b9\u306e\u5404\u30b9\u30c6\u30c3\u30d7\u3067\u3001\u7e2e\u5c0f\u30d1\u30b9\u304b\u3089\u306e\u5bfe\u5fdc\u3059\u308b\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u304c\u73fe\u5728\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u3068\u9023\u7d50\u3055\u308c\u307e\u3059\u3002</p>\n",
 "<h3>Down-sample</h3>\n<p>Each step in the contracting path down-samples the feature map with a <span translate=no>_^_0_^_</span> max pooling layer.</p>\n": "<h3>\u30c0\u30a6\u30f3\u30b5\u30f3\u30d7\u30eb</h3>\n<p>\u53ce\u7e2e\u30d1\u30b9\u306e\u5404\u30b9\u30c6\u30c3\u30d7\u306f\u3001<span translate=no>_^_0_^_</span>\u6700\u5927\u30d7\u30fc\u30ea\u30f3\u30b0\u30ec\u30a4\u30e4\u30fc\u3092\u4f7f\u7528\u3057\u3066\u7279\u5fb4\u30de\u30c3\u30d7\u3092\u30c0\u30a6\u30f3\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u307e\u3059\u3002</p>\n",
 "<h3>Two <span translate=no>_^_0_^_</span> Convolution Layers</h3>\n<p>Each step in the contraction path and expansive path have two <span translate=no>_^_1_^_</span> convolutional layers followed by ReLU activations.</p>\n<p>In the U-Net paper they used <span translate=no>_^_2_^_</span> padding, but we use <span translate=no>_^_3_^_</span> padding so that final feature map is not cropped.</p>\n": "<h3>2 <span translate=no>_^_0_^_</span> \u3064\u306e\u30b3\u30f3\u30dc\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u30ec\u30a4\u30e4\u30fc</h3>\n<p>\u53ce\u7e2e\u7d4c\u8def\u3068\u81a8\u5f35\u7d4c\u8def\u306e\u5404\u30b9\u30c6\u30c3\u30d7\u306b\u306f\u3001<span translate=no>_^_1_^_</span> 2\u3064\u306e\u7573\u307f\u8fbc\u307f\u5c64\u304c\u3042\u308a\u3001\u305d\u306e\u5f8c\u306bReLU\u6d3b\u6027\u5316\u304c\u7d9a\u304d\u307e\u3059\u3002</p>\n<p><span translate=no>_^_2_^_</span>U-Net\u306e\u8ad6\u6587\u3067\u306f\u30d1\u30c7\u30a3\u30f3\u30b0\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3057\u305f\u304c\u3001<span translate=no>_^_3_^_</span>\u6700\u7d42\u7684\u306a\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u304c\u30c8\u30ea\u30df\u30f3\u30b0\u3055\u308c\u306a\u3044\u3088\u3046\u306b\u30d1\u30c7\u30a3\u30f3\u30b0\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002</p>\n",
 "<h3>Up-sample</h3>\n<p>Each step in the expansive path up-samples the feature map with a <span translate=no>_^_0_^_</span> up-convolution.</p>\n": "<h3>\u30a2\u30c3\u30d7\u30b5\u30f3\u30d7\u30eb</h3>\n<p>\u5e83\u5927\u306a\u7d4c\u8def\u306e\u5404\u30b9\u30c6\u30c3\u30d7\u306f\u3001\u30a2\u30c3\u30d7\u30b3\u30f3\u30dc\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u3067\u7279\u5fb4\u30de\u30c3\u30d7\u3092\u30a2\u30c3\u30d7\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u307e\u3059\u3002<span translate=no>_^_0_^_</span></p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p>Apply the two convolution layers and activations </p>\n": "<p>2 \u3064\u306e\u30b3\u30f3\u30dc\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u30ec\u30a4\u30e4\u30fc\u3068\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30b7\u30e7\u30f3\u3092\u9069\u7528\u3057\u307e\u3059\u3002</p>\n",
 "<p>Collect the output </p>\n": "<p>\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u3092\u53ce\u96c6</p>\n",
 "<p>Concatenate the feature maps </p>\n": "<p>\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u3092\u9023\u7d50\u3059\u308b</p>\n",
 "<p>Concatenate the output of the contracting path </p>\n": "<p>\u30b3\u30f3\u30c8\u30e9\u30af\u30c8\u30d1\u30b9\u306e\u51fa\u529b\u3092\u9023\u7d50\u3059\u308b</p>\n",
 "<p>Contracting path </p>\n": "<p>\u5951\u7d04\u7d4c\u8def</p>\n",
 "<p>Crop and concatenate layers for the expansive path. </p>\n": "<p>\u30ec\u30a4\u30e4\u30fc\u3092\u30c8\u30ea\u30df\u30f3\u30b0\u3057\u3066\u9023\u7d50\u3059\u308b\u3068\u3001\u5e83\u5927\u306a\u30d1\u30b9\u304c\u4f5c\u308c\u307e\u3059\u3002</p>\n",
 "<p>Crop the feature map from the contracting path to the size of the current feature map </p>\n": "<p>\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u3092\u7e2e\u5c0f\u30d1\u30b9\u304b\u3089\u73fe\u5728\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u306e\u30b5\u30a4\u30ba\u306b\u30c8\u30ea\u30df\u30f3\u30b0\u3057\u307e\u3059</p>\n",
 "<p>Double convolution layers for the contracting path. The number of features gets doubled at each step starting from <span translate=no>_^_0_^_</span>. </p>\n": "<p>\u53ce\u7e2e\u7d4c\u8def\u7528\u306e\u4e8c\u91cd\u7573\u307f\u8fbc\u307f\u5c64\u3002<span translate=no>_^_0_^_</span>\u304b\u3089\u59cb\u307e\u308b\u5404\u30b9\u30c6\u30c3\u30d7\u3067\u6a5f\u80fd\u306e\u6570\u304c 2 \u500d\u306b\u306a\u308a\u307e\u3059</p>\u3002\n",
 "<p>Double convolution layers for the expansive path. Their input is the concatenation of the current feature map and the feature map from the contracting path. Therefore, the number of input features is double the number of features from up-sampling. </p>\n": "<p>\u81a8\u5f35\u7d4c\u8def\u7528\u306e\u4e8c\u91cd\u7573\u307f\u8fbc\u307f\u5c64\u3002\u305d\u308c\u3089\u306e\u5165\u529b\u306f\u3001\u73fe\u5728\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u3068\u7e2e\u5c0f\u30d1\u30b9\u304b\u3089\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u3092\u9023\u7d50\u3057\u305f\u3082\u306e\u3067\u3059\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u306e\u6570\u306f\u3001\u30a2\u30c3\u30d7\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u306b\u3088\u308b\u30d5\u30a3\u30fc\u30c1\u30e3\u6570\u306e2\u500d\u306b\u306a\u308a\u307e\u3059</p>\u3002\n",
 "<p>Down sampling layers for the contracting path </p>\n": "<p>\u53ce\u7e2e\u7d4c\u8def\u7528\u306e\u30c0\u30a6\u30f3\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u5c64</p>\n",
 "<p>Down-sample </p>\n": "<p>\u30c0\u30a6\u30f3\u30b5\u30f3\u30d7\u30eb</p>\n",
 "<p>Expansive path </p>\n": "<p>\u5e83\u5927\u306a\u9053</p>\n",
 "<p>Final <span translate=no>_^_0_^_</span> convolution layer </p>\n": "<p><span translate=no>_^_0_^_</span>\u6700\u7d42\u7573\u307f\u8fbc\u307f\u5c64</p>\n",
 "<p>Final <span translate=no>_^_0_^_</span> convolution layer to produce the output </p>\n": "<p><span translate=no>_^_0_^_</span>\u51fa\u529b\u3092\u751f\u6210\u3059\u308b\u6700\u5f8c\u306e\u7573\u307f\u8fbc\u307f\u5c64</p>\n",
 "<p>First <span translate=no>_^_0_^_</span> convolutional layer </p>\n": "<p><span translate=no>_^_0_^_</span>\u6700\u521d\u306e\u7573\u307f\u8fbc\u307f\u5c64</p>\n",
 "<p>Max pooling layer </p>\n": "<p>\u6700\u5927\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64</p>\n",
 "<p>Second <span translate=no>_^_0_^_</span> convolutional layer </p>\n": "<p>2 <span translate=no>_^_0_^_</span> \u756a\u76ee\u306e\u7573\u307f\u8fbc\u307f\u5c64</p>\n",
 "<p>The two convolution layers at the lowest resolution (the bottom of the U). </p>\n": "<p>\u6700\u3082\u4f4e\u3044\u89e3\u50cf\u5ea6\u306e 2 \u3064\u306e\u7573\u307f\u8fbc\u307f\u5c64 (U \u306e\u4e0b\u90e8)\u3002</p>\n",
 "<p>To collect the outputs of contracting path for later concatenation with the expansive path. </p>\n": "<p>\u7e2e\u5c0f\u30d1\u30b9\u306e\u51fa\u529b\u3092\u53ce\u96c6\u3057\u3066\u3001\u5f8c\u3067\u62e1\u5f35\u30d1\u30b9\u3068\u9023\u7d50\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002</p>\n",
 "<p>Two <span translate=no>_^_0_^_</span> convolutional layers </p>\n": "<p>2 <span translate=no>_^_0_^_</span> \u3064\u306e\u7573\u307f\u8fbc\u307f\u5c64</p>\n",
 "<p>Two <span translate=no>_^_0_^_</span> convolutional layers at the bottom of the U-Net </p>\n": "<p><span translate=no>_^_0_^_</span>U-Net\u306e\u4e0b\u90e8\u306b\u3042\u308b2\u3064\u306e\u7573\u307f\u8fbc\u307f\u5c64</p>\n",
 "<p>Up sampling layers for the expansive path. The number of features is halved with up-sampling. </p>\n": "<p>\u5e83\u5927\u306a\u7d4c\u8def\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30a4\u30e4\u30fc\u3092\u30a2\u30c3\u30d7\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3002\u30a2\u30c3\u30d7\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3092\u884c\u3046\u3068\u3001\u6a5f\u80fd\u306e\u6570\u306f\u534a\u5206\u306b\u306a\u308a\u307e\u3059</p>\u3002\n",
 "<p>Up-convolution </p>\n": "<p>\u30a2\u30c3\u30d7\u30b3\u30f3\u30dc\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3</p>\n",
 "<p>Up-sample </p>\n": "<p>\u30a2\u30c3\u30d7\u30b5\u30f3\u30d7\u30eb</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  current feature map in the expansive path </li>\n<li><span translate=no>_^_1_^_</span>  corresponding feature map from the contracting path</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u30a8\u30af\u30b9\u30d1\u30f3\u30b7\u30d6\u30d1\u30b9\u5185\u306e\u73fe\u5728\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7</li>\n<li><span translate=no>_^_1_^_</span>\u5951\u7d04\u7d4c\u8def\u304b\u3089\u306e\u5bfe\u5fdc\u3059\u308b\u6a5f\u80fd\u30de\u30c3\u30d7</li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  input image</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u5165\u529b\u753b\u50cf</li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  is the number of input channels </li>\n<li><span translate=no>_^_1_^_</span>  is the number of output channels</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u306f\u5165\u529b\u30c1\u30e3\u30f3\u30cd\u30eb\u6570</li>\n<li><span translate=no>_^_1_^_</span>\u306f\u51fa\u529b\u30c1\u30e3\u30f3\u30cd\u30eb\u6570</li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  number of channels in the input image </li>\n<li><span translate=no>_^_1_^_</span>  number of channels in the result feature map</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u5165\u529b\u753b\u50cf\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u6570</li>\n<li><span translate=no>_^_1_^_</span>\u7d50\u679c\u30d5\u30a3\u30fc\u30c1\u30e3\u30de\u30c3\u30d7\u306e\u30c1\u30e3\u30cd\u30eb\u6570</li></ul>\n",
 "PyTorch implementation and tutorial of U-Net model.": "PyTorch\u306e\u5b9f\u88c5\u3068U-Net\u30e2\u30c7\u30eb\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3002",
 "U-Net": "\u30e6\u30fc\u30cd\u30c3\u30c8"
}