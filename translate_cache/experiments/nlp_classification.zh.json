{
 "<h1>NLP model trainer for classification</h1>\n": "<h1>\u7528\u4e8e\u5206\u7c7b\u7684 NLP \u6a21\u578b\u8bad\u7ec3\u5668</h1>\n",
 "<h2>Function to load data into batches</h2>\n": "<h2>\u5c06\u6570\u636e\u52a0\u8f7d\u5230\u6279\u5904\u7406\u4e2d\u7684\u51fd\u6570</h2>\n",
 "<h3>AG News dataset</h3>\n<p>This loads the AG News dataset and the set the values for  <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>, <span translate=no>_^_2_^_</span>, and <span translate=no>_^_3_^_</span>.</p>\n": "<h3>AG \u65b0\u95fb\u6570\u636e\u96c6</h3>\n<p>\u8fd9\u5c06\u52a0\u8f7d AG News \u6570\u636e\u96c6\u5e76\u8bbe\u7f6e<span translate=no>_^_0_^_</span>\u3001<span translate=no>_^_1_^_</span><span translate=no>_^_2_^_</span>\u3001\u548c\u7684\u503c<span translate=no>_^_3_^_</span>\u3002</p>\n",
 "<h3>Basic english tokenizer</h3>\n<p>We use character level tokenizer in this experiment. You can switch by setting,</p>\n<span translate=no>_^_0_^_</span><p>in the configurations dictionary when starting the experiment.</p>\n": "<h3>\u57fa\u7840\u82f1\u8bed\u5206\u8bcd\u5668</h3>\n<p>\u6211\u4eec\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u89d2\u8272\u7b49\u7ea7\u5206\u8bcd\u5668\u3002\u4f60\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u8fdb\u884c\u5207\u6362\uff0c</p>\n<span translate=no>_^_0_^_</span><p>\u5f00\u59cb\u5b9e\u9a8c\u65f6\u5728\u914d\u7f6e\u5b57\u5178\u4e2d\u3002</p>\n",
 "<h3>Character level tokenizer</h3>\n": "<h3>\u89d2\u8272\u7b49\u7ea7\u5206\u8bcd\u5668</h3>\n",
 "<h3>Default <a href=\"../optimizers/configs.html\">optimizer configurations</a></h3>\n": "<h3>\u9ed8\u8ba4<a href=\"../optimizers/configs.html\">\u4f18\u5316\u5668\u914d\u7f6e</a></h3>\n",
 "<h3>Initialization</h3>\n": "<h3>\u521d\u59cb\u5316</h3>\n",
 "<h3>Training or validation step</h3>\n": "<h3>\u57f9\u8bad\u6216\u9a8c\u8bc1\u6b65\u9aa4</h3>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> <a id=\"NLPClassificationConfigs\"></a></p>\n<h2>Trainer configurations</h2>\n<p>This has the basic configurations for NLP classification task training. All the properties are configurable.</p>\n": "<p><a id=\"NLPClassificationConfigs\"></a></p>\n<h2>\u8bad\u7ec3\u5668\u914d\u7f6e</h2>\n<p>\u5b83\u5177\u6709 NLP \u5206\u7c7b\u4efb\u52a1\u57f9\u8bad\u7684\u57fa\u672c\u914d\u7f6e\u3002\u6240\u6709\u5c5e\u6027\u90fd\u662f\u53ef\u914d\u7f6e\u7684\u3002</p>\n",
 "<p> Character level tokenizer configuration</p>\n": "<p>\u89d2\u8272\u7ea7\u522b\u5206\u8bcd\u5668\u914d\u7f6e</p>\n",
 "<p> Get number of tokens</p>\n": "<p>\u83b7\u53d6\u4ee3\u5e01\u6570\u91cf</p>\n",
 "<p>Accuracy function </p>\n": "<p>\u7cbe\u5ea6\u51fd\u6570</p>\n",
 "<p>Add a hook to log module outputs </p>\n": "<p>\u5411\u65e5\u5fd7\u6a21\u5757\u8f93\u51fa\u6dfb\u52a0\u94a9\u5b50</p>\n",
 "<p>Add accuracy as a state module. The name is probably confusing, since it&#x27;s meant to store states between training and validation for RNNs. This will keep the accuracy metric stats separate for training and validation. </p>\n": "<p>\u589e\u52a0\u4f5c\u4e3a\u72b6\u6001\u6a21\u5757\u7684\u7cbe\u5ea6\u3002\u8fd9\u4e2a\u540d\u5b57\u53ef\u80fd\u4ee4\u4eba\u56f0\u60d1\uff0c\u56e0\u4e3a\u5b83\u65e8\u5728\u5b58\u50a8 RNN \u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u4e4b\u95f4\u7684\u72b6\u6001\u3002\u8fd9\u5c06\u4f7f\u7cbe\u5ea6\u6307\u6807\u7edf\u8ba1\u6570\u636e\u5206\u5f00\uff0c\u4ee5\u4fbf\u8fdb\u884c\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002</p>\n",
 "<p>Autoregressive model </p>\n": "<p>\u81ea\u56de\u5f52\u6a21\u578b</p>\n",
 "<p>Batch size </p>\n": "<p>\u6279\u91cf\u5927\u5c0f</p>\n",
 "<p>Calculate and log accuracy </p>\n": "<p>\u8ba1\u7b97\u548c\u8bb0\u5f55\u7cbe\u5ea6</p>\n",
 "<p>Calculate and log loss </p>\n": "<p>\u8ba1\u7b97\u5e76\u8bb0\u5f55\u635f\u5931</p>\n",
 "<p>Calculate gradients </p>\n": "<p>\u8ba1\u7b97\u68af\u5ea6</p>\n",
 "<p>Clear the gradients </p>\n": "<p>\u6e05\u9664\u6e10\u53d8</p>\n",
 "<p>Clip gradients </p>\n": "<p>\u526a\u8f91\u6e10\u53d8</p>\n",
 "<p>Collect tokens from training dataset </p>\n": "<p>\u4ece\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u6536\u96c6\u4ee4\u724c</p>\n",
 "<p>Collect tokens from validation dataset </p>\n": "<p>\u4ece\u9a8c\u8bc1\u6570\u636e\u96c6\u4e2d\u6536\u96c6\u4ee4\u724c</p>\n",
 "<p>Create <a href=\"../utils.html#map_style_dataset\">map-style datasets</a> </p>\n": "<p>\u521b\u5efa<a href=\"../utils.html#map_style_dataset\">\u5730\u56fe\u6837\u5f0f\u6570\u636e\u96c6</a></p>\n",
 "<p>Create a counter </p>\n": "<p>\u521b\u5efa\u8ba1\u6570\u5668</p>\n",
 "<p>Create training data loader </p>\n": "<p>\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u52a0\u8f7d\u5668</p>\n",
 "<p>Create validation data loader </p>\n": "<p>\u521b\u5efa\u9a8c\u8bc1\u6570\u636e\u52a0\u8f7d\u5668</p>\n",
 "<p>Create vocabulary </p>\n": "<p>\u521b\u5efa\u8bcd\u6c47</p>\n",
 "<p>Empty labels tensor </p>\n": "<p>\u7a7a\u6807\u7b7e\u5f20\u91cf</p>\n",
 "<p>Get model outputs. It&#x27;s returning a tuple for states when using RNNs. This is not implemented yet. \ud83d\ude1c </p>\n": "<p>\u83b7\u53d6\u6a21\u578b\u8f93\u51fa\u3002\u5b83\u5728\u4f7f\u7528 RNN \u65f6\u8fd4\u56de\u72b6\u6001\u7684\u5143\u7ec4\u3002\u8fd9\u8fd8\u6ca1\u6709\u5b9e\u73b0\u3002\ud83d\ude1c</p>\n",
 "<p>Get tokenizer </p>\n": "<p>\u83b7\u53d6\u5206\u8bcd\u5668</p>\n",
 "<p>Get training and validation datasets </p>\n": "<p>\u83b7\u53d6\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u96c6</p>\n",
 "<p>Gradient clipping </p>\n": "<p>\u6e10\u53d8\u526a\u5207</p>\n",
 "<p>Input data tensor, initialized with <span translate=no>_^_0_^_</span> </p>\n": "<p>\u8f93\u5165\u6570\u636e\u5f20\u91cf\uff0c\u521d\u59cb\u5316\u4e3a<span translate=no>_^_0_^_</span></p>\n",
 "<p>Length of the sequence, or context size </p>\n": "<p>\u5e8f\u5217\u7684\u957f\u5ea6\u6216\u4e0a\u4e0b\u6587\u5927\u5c0f</p>\n",
 "<p>Load data to memory </p>\n": "<p>\u5c06\u6570\u636e\u52a0\u8f7d\u5230\u5185\u5b58</p>\n",
 "<p>Log the model parameters and gradients on last batch of every epoch </p>\n": "<p>\u8bb0\u5f55\u6bcf\u4e2a\u7eaa\u5143\u6700\u540e\u4e00\u6279\u7684\u6a21\u578b\u53c2\u6570\u548c\u68af\u5ea6</p>\n",
 "<p>Loop through the samples </p>\n": "<p>\u5faa\u73af\u6d4f\u89c8\u6837\u672c</p>\n",
 "<p>Loss function </p>\n": "<p>\u4e8f\u635f\u51fd\u6570</p>\n",
 "<p>Model embedding size </p>\n": "<p>\u6a21\u578b\u5d4c\u5165\u5927\u5c0f</p>\n",
 "<p>Move data to the device </p>\n": "<p>\u5c06\u6570\u636e\u79fb\u52a8\u5230\u8bbe\u5907</p>\n",
 "<p>Number of classes </p>\n": "<p>\u73ed\u7ea7\u6570</p>\n",
 "<p>Number of token in vocabulary </p>\n": "<p>\u8bcd\u6c47\u4e2d\u7684\u4ee3\u5e01\u6570\u91cf</p>\n",
 "<p>Optimizer </p>\n": "<p>\u4f18\u5316\u5668</p>\n",
 "<p>Return <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>, <span translate=no>_^_2_^_</span>, and <span translate=no>_^_3_^_</span> </p>\n": "<p>\u8fd4\u56de<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u3001<span translate=no>_^_2_^_</span>\u3001\u548c<span translate=no>_^_3_^_</span></p>\n",
 "<p>Save the tracked metrics </p>\n": "<p>\u4fdd\u5b58\u8ddf\u8e2a\u7684\u6307\u6807</p>\n",
 "<p>Set the final token in the sequence to <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5c06\u5e8f\u5217\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u4ee4\u724c\u8bbe\u7f6e\u4e3a<span translate=no>_^_0_^_</span></p>\n",
 "<p>Set the label </p>\n": "<p>\u8bbe\u7f6e\u6807\u7b7e</p>\n",
 "<p>Set tracker configurations </p>\n": "<p>\u8bbe\u7f6e\u8ddf\u8e2a\u5668\u914d\u7f6e</p>\n",
 "<p>Take optimizer step </p>\n": "<p>\u91c7\u53d6\u4f18\u5316\u5668\u6b65\u9aa4</p>\n",
 "<p>Tokenize the input text </p>\n": "<p>\u6807\u8bb0\u8f93\u5165\u6587\u672c</p>\n",
 "<p>Tokenizer </p>\n": "<p>\u5206\u8bcd\u5668</p>\n",
 "<p>Train the model </p>\n": "<p>\u8bad\u7ec3\u6a21\u578b</p>\n",
 "<p>Training data loader </p>\n": "<p>\u8bad\u7ec3\u6570\u636e\u52a0\u8f7d\u5668</p>\n",
 "<p>Training device </p>\n": "<p>\u8bad\u7ec3\u8bbe\u5907</p>\n",
 "<p>Transpose and add to data </p>\n": "<p>\u8f6c\u7f6e\u5e76\u6dfb\u52a0\u5230\u6570\u636e</p>\n",
 "<p>Truncate upto <span translate=no>_^_0_^_</span> </p>\n": "<p>\u622a\u65ad\u6700\u591a<span translate=no>_^_0_^_</span></p>\n",
 "<p>Update global step (number of tokens processed) when in training mode </p>\n": "<p>\u5728\u8bad\u7ec3\u6a21\u5f0f\u4e0b\u66f4\u65b0\u5168\u5c40\u6b65\u957f\uff08\u5904\u7406\u7684\u4ee4\u724c\u6570\uff09</p>\n",
 "<p>Validation data loader </p>\n": "<p>\u9a8c\u8bc1\u6570\u636e\u52a0\u8f7d\u5668</p>\n",
 "<p>Vocabulary </p>\n": "<p>\u8bcd\u6c47</p>\n",
 "<p>Whether to capture model outputs </p>\n": "<p>\u662f\u5426\u6355\u83b7\u6a21\u578b\u8f93\u51fa</p>\n",
 "<p>Whether to log model activations (once per epoch). These are summarized stats per layer, but it could still lead to many indicators for very deep networks. </p>\n": "<p>\u662f\u5426\u8bb0\u5f55\u6a21\u578b\u6fc0\u6d3b\uff08\u6bcf\u4e2a\u7eaa\u5143\u4e00\u6b21\uff09\u3002\u8fd9\u4e9b\u662f\u6bcf\u5c42\u7684\u6c47\u603b\u7edf\u8ba1\u6570\u636e\uff0c\u4f46\u5b83\u4ecd\u7136\u53ef\u80fd\u5bfc\u81f4\u975e\u5e38\u6df1\u7684\u7f51\u7edc\u7684\u8bb8\u591a\u6307\u6807\u3002</p>\n",
 "<p>Whether to log model parameters and gradients (once per epoch). These are summarized stats per layer, but it could still lead to many indicators for very deep networks. </p>\n": "<p>\u662f\u5426\u8bb0\u5f55\u6a21\u578b\u53c2\u6570\u548c\u68af\u5ea6\uff08\u6bcf\u4e2a\u7eaa\u5143\u4e00\u6b21\uff09\u3002\u8fd9\u4e9b\u662f\u6bcf\u5c42\u7684\u6c47\u603b\u7edf\u8ba1\u6570\u636e\uff0c\u4f46\u5b83\u4ecd\u7136\u53ef\u80fd\u5bfc\u81f4\u975e\u5e38\u6df1\u7684\u7f51\u7edc\u7684\u8bb8\u591a\u6307\u6807\u3002</p>\n",
 "<p>Whether to periodically save models </p>\n": "<p>\u662f\u5426\u5b9a\u671f\u4fdd\u5b58\u6a21\u578b</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the batch of data collected by the <span translate=no>_^_1_^_</span></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u7531<span translate=no>_^_1_^_</span></li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the tokenizer function </li>\n<li><span translate=no>_^_1_^_</span> is the vocabulary </li>\n<li><span translate=no>_^_2_^_</span> is the length of the sequence </li>\n<li><span translate=no>_^_3_^_</span> is the token used for padding when the <span translate=no>_^_4_^_</span> is larger than the text length </li>\n<li><span translate=no>_^_5_^_</span> is the <span translate=no>_^_6_^_</span> token which we set at end of the input</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u5206\u8bcd\u5668\u51fd\u6570</li>\n<li><span translate=no>_^_1_^_</span>\u662f\u8bcd\u6c47</li>\n<li><span translate=no>_^_2_^_</span>\u662f\u5e8f\u5217\u7684\u957f\u5ea6</li>\n<li><span translate=no>_^_3_^_</span>\u662f\u5927\u4e8e\u6587\u672c\u957f\u5ea6\u65f6<span translate=no>_^_4_^_</span>\u7528\u4e8e\u586b\u5145\u7684\u6807\u8bb0</li>\n<li><span translate=no>_^_5_^_</span>\u662f\u6211\u4eec\u5728\u8f93\u5165\u672b\u5c3e\u8bbe\u7f6e\u7684<span translate=no>_^_6_^_</span>\u4ee4\u724c</li></ul>\n",
 "NLP classification trainer": "NLP \u5206\u7c7b\u57f9\u8bad\u5e08",
 "This is a reusable trainer for classification tasks": "\u8fd9\u662f\u4e00\u6b3e\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u5206\u7c7b\u4efb\u52a1\u8bad\u7ec3\u5668"
}