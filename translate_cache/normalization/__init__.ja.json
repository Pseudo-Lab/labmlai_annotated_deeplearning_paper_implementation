{
 "<h1>Normalization Layers</h1>\n<ul><li><a href=\"batch_norm/index.html\">Batch Normalization</a> </li>\n<li><a href=\"layer_norm/index.html\">Layer Normalization</a> </li>\n<li><a href=\"instance_norm/index.html\">Instance Normalization</a> </li>\n<li><a href=\"group_norm/index.html\">Group Normalization</a> </li>\n<li><a href=\"weight_standardization/index.html\">Weight Standardization</a> </li>\n<li><a href=\"batch_channel_norm/index.html\">Batch-Channel Normalization</a> </li>\n<li><a href=\"deep_norm/index.html\">DeepNorm</a></li></ul>\n": "<h1>\u6b63\u898f\u5316\u30ec\u30a4\u30e4\u30fc</h1>\n<ul><li><a href=\"batch_norm/index.html\">\u30d0\u30c3\u30c1\u6b63\u898f\u5316</a></li>\n<li><a href=\"layer_norm/index.html\">\u30ec\u30a4\u30e4\u30fc\u6b63\u898f\u5316</a></li>\n<li><a href=\"instance_norm/index.html\">\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u6b63\u898f\u5316</a></li>\n<li><a href=\"group_norm/index.html\">\u30b0\u30eb\u30fc\u30d7\u6b63\u898f\u5316</a></li>\n<li><a href=\"weight_standardization/index.html\">\u91cd\u91cf\u6a19\u6e96\u5316</a></li>\n<li><a href=\"batch_channel_norm/index.html\">\u30d0\u30c3\u30c1\u30c1\u30e3\u30cd\u30eb\u6b63\u898f\u5316</a></li>\n</ul><li><a href=\"deep_norm/index.html\">\u30c7\u30a3\u30fc\u30d7\u30fb\u30ce\u30fc\u30e0</a></li>\n",
 "A set of PyTorch implementations/tutorials of normalization layers.": "\u6b63\u898f\u5316\u30ec\u30a4\u30e4\u30fc\u306ePyTorch\u5b9f\u88c5/\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e\u30bb\u30c3\u30c8\u3002",
 "Normalization Layers": "\u6b63\u898f\u5316\u30ec\u30a4\u30e4\u30fc"
}