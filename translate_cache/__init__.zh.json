{
 "<h1><a href=\"index.html\">labml.ai Annotated PyTorch Paper Implementations</a></h1>\n": "<h1><a href=\"index.html\">labml.ai \u5e26\u6ce8\u91ca\u7684 pyTorch \u8bba\u6587\u5b9e\u73b0</a></h1>\n",
 "<h2>Highlighted Research Paper PDFs</h2>\n": "<h2>\u91cd\u70b9\u7814\u7a76\u8bba\u6587 PDF</h2>\n",
 "<h2>Paper Implementations</h2>\n": "<h2>\u7eb8\u8d28\u5b9e\u73b0</h2>\n",
 "<h2>Translations</h2>\n": "<h2>\u7ffb\u8bd1</h2>\n",
 "<h3><strong><a href=\"https://nn.labml.ai\">English (original)</a></strong></h3>\n": "<h3><strong><a href=\"https://nn.labml.ai\">\u82f1\u8bed\uff08\u539f\u7248\uff09</a></strong></h3>\n",
 "<h3><strong><a href=\"https://nn.labml.ai/ja/\">Japanese (translated)</a></strong></h3>\n": "</a><h3><strong><a href=\"https://nn.labml.ai/ja/\">\u65e5\u8bed\uff08\u5df2\u7ffb\u8bd1\uff09</strong></h3>\n",
 "<h3><strong><a href=\"https://nn.labml.ai/zh/\">Chinese (translated)</a></strong></h3>\n": "</a><h3><strong><a href=\"https://nn.labml.ai/zh/\">\u4e2d\u6587\uff08\u7ffb\u8bd1\uff09</strong></h3>\n",
 "<h3>Citing LabML</h3>\n": "<h3>\u5f15\u7528 LabML</h3>\n",
 "<h3>Installation</h3>\n": "<h3>\u5b89\u88c5</h3>\n",
 "<h4>\u2728 <a href=\"activations/index.html\">Activations</a></h4>\n": "<h4>\u2728 <a href=\"activations/index.html\">\u6fc0\u6d3b</a></h4>\n",
 "<h4>\u2728 <a href=\"adaptive_computation/index.html\">Adaptive Computation</a></h4>\n": "<h4>\u2728 <a href=\"adaptive_computation/index.html\">\u81ea\u9002\u5e94\u8ba1\u7b97</a></h4>\n",
 "<h4>\u2728 <a href=\"capsule_networks/index.html\">Capsule Networks</a></h4>\n": "<h4>\u2728 <a href=\"capsule_networks/index.html\">\u80f6\u56ca\u7f51\u7edc</a></h4>\n",
 "<h4>\u2728 <a href=\"cfr/index.html\">Counterfactual Regret Minimization (CFR)</a></h4>\n": "<h4>\u2728 <a href=\"cfr/index.html\">\u53cd\u4e8b\u5b9e\u9057\u61be\u6700\u5c0f\u5316\uff08CFR\uff09</a></h4>\n",
 "<h4>\u2728 <a href=\"conv_mixer/index.html\">ConvMixer</a></h4>\n": "<h4>\u2728 <a href=\"conv_mixer/index.html\">\u6df7\u97f3\u5668</a></h4>\n",
 "<h4>\u2728 <a href=\"diffusion/index.html\">Diffusion models</a></h4>\n": "<h4>\u2728 <a href=\"diffusion/index.html\">\u6269\u6563\u6a21\u578b</a></h4>\n",
 "<h4>\u2728 <a href=\"distillation/index.html\">Distillation</a></h4>\n": "<h4>\u2728 <a href=\"distillation/index.html\">\u84b8\u998f</a></h4>\n",
 "<h4>\u2728 <a href=\"gan/index.html\">Generative Adversarial Networks</a></h4>\n": "<h4>\u2728 <a href=\"gan/index.html\">\u751f\u6210\u5bf9\u6297\u7f51\u7edc</a></h4>\n",
 "<h4>\u2728 <a href=\"hypernetworks/hyper_lstm.html\">HyperNetworks - HyperLSTM</a></h4>\n": "<h4>\u2728 <a href=\"hypernetworks/hyper_lstm.html\">\u8d85\u7ea7\u7f51\u7edc-HyperLSTM</a></h4>\n",
 "<h4>\u2728 <a href=\"lstm/index.html\">LSTM</a></h4>\n": "<h4>\u2728 <a href=\"lstm/index.html\">LSTM</a></h4>\n",
 "<h4>\u2728 <a href=\"neox/index.html\">Eleuther GPT-NeoX</a></h4>\n": "<h4>\u2728 <a href=\"neox/index.html\">Eleuther GPT-neox</a></h4>\n",
 "<h4>\u2728 <a href=\"normalization/index.html\">Normalization Layers</a></h4>\n": "<h4>\u2728 <a href=\"normalization/index.html\">\u89c4\u8303\u5316\u5c42</a></h4>\n",
 "<h4>\u2728 <a href=\"optimizers/index.html\">Optimizers</a></h4>\n": "<h4>\u2728 <a href=\"optimizers/index.html\">\u4f18\u5316\u5668</a></h4>\n",
 "<h4>\u2728 <a href=\"recurrent_highway_networks/index.html\">Recurrent Highway Networks</a></h4>\n": "<h4>\u2728 <a href=\"recurrent_highway_networks/index.html\">\u5faa\u73af\u9ad8\u901f\u516c\u8def\u7f51\u7edc</a></h4>\n",
 "<h4>\u2728 <a href=\"resnet/index.html\">ResNet</a></h4>\n": "<h4>\u2728 <a href=\"resnet/index.html\">ResNet</a></h4>\n",
 "<h4>\u2728 <a href=\"rl/index.html\">Reinforcement Learning</a></h4>\n": "<h4>\u2728 <a href=\"rl/index.html\">\u5f3a\u5316\u5b66\u4e60</a></h4>\n",
 "<h4>\u2728 <a href=\"sampling/index.html\">Language Model Sampling Techniques</a></h4>\n": "<h4>\u2728 <a href=\"sampling/index.html\">\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u6280\u672f</a></h4>\n",
 "<h4>\u2728 <a href=\"scaling/index.html\">Scalable Training/Inference</a></h4>\n": "<h4>\u2728 <a href=\"scaling/index.html\">\u53ef\u6269\u5c55\u7684\u8bad\u7ec3/\u63a8\u7406</a></h4>\n",
 "<h4>\u2728 <a href=\"sketch_rnn/index.html\">Sketch RNN</a></h4>\n": "<h4>\u2728 <a href=\"sketch_rnn/index.html\">\u7d20\u63cf RNN</a></h4>\n",
 "<h4>\u2728 <a href=\"transformers/index.html\">Transformers</a></h4>\n": "<h4>\u2728 <a href=\"transformers/index.html\">\u53d8\u5f62\u91d1\u521a</a></h4>\n",
 "<h4>\u2728 <a href=\"uncertainty/index.html\">Uncertainty</a></h4>\n": "<h4>\u2728 <a href=\"uncertainty/index.html\">\u4e0d\u786e\u5b9a\u6027</a></h4>\n",
 "<h4>\u2728 <a href=\"unet/index.html\">U-Net</a></h4>\n": "<h4>\u2728 <a href=\"unet/index.html\">U-Net</a></h4>\n",
 "<h4>\u2728 Graph Neural Networks</h4>\n": "<h4>\u2728 \u56fe\u5f62\u795e\u7ecf\u7f51\u7edc</h4>\n",
 "<p><span translate=no>_^_0_^_</span></p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p>If you use this for academic research, please cite it using the following BibTeX entry.</p>\n": "<p>\u5982\u679c\u60a8\u5c06\u5176\u7528\u4e8e\u5b66\u672f\u7814\u7a76\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b BibTeX \u6761\u76ee\u5f15\u7528\u5b83\u3002</p>\n",
 "<p>Solving games with incomplete information such as poker with CFR.</p>\n": "<p>\u4f7f\u7528CFR\u89e3\u51b3\u4fe1\u606f\u4e0d\u5b8c\u6574\u7684\u6e38\u620f\uff0c\u4f8b\u5982\u4f7f\u7528CFR\u7684\u6251\u514b\u3002</p>\n",
 "<p>This is a collection of simple PyTorch implementations of neural networks and related algorithms. <a href=\"https://github.com/labmlai/annotated_deep_learning_paper_implementations\">These implementations</a> are documented with explanations, and the <a href=\"index.html\">website</a> renders these as side-by-side formatted notes. We believe these would help you understand these algorithms better.</p>\n": "<p>\u8fd9\u662f\u795e\u7ecf\u7f51\u7edc\u548c\u76f8\u5173\u7b97\u6cd5\u7684\u7b80\u5355 PyTorch \u5b9e\u73b0\u7684\u96c6\u5408\u3002<a href=\"https://github.com/labmlai/annotated_deep_learning_paper_implementations\">\u8fd9\u4e9b\u5b9e\u73b0</a>\u4e0e\u89e3\u91ca\u4e00\u8d77\u8bb0\u5f55\uff0c<a href=\"index.html\">\u7f51\u7ad9\u5c06\u8fd9\u4e9b\u5185\u5bb9</a>\u5448\u73b0\u4e3a\u5e76\u6392\u683c\u5f0f\u7684\u6ce8\u91ca\u3002\u6211\u4eec\u76f8\u4fe1\u8fd9\u4e9b\u5c06\u5e2e\u52a9\u60a8\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u7b97\u6cd5\u3002</p>\n",
 "<p>We are actively maintaining this repo and adding new implementations. <a href=\"https://twitter.com/labmlai\"><span translate=no>_^_0_^_</span></a> for updates.</p>\n": "<p>\u6211\u4eec\u6b63\u5728\u79ef\u6781\u7ef4\u62a4\u8fd9\u4e2a\u4ed3\u5e93\u5e76\u6dfb\u52a0\u65b0\u7684\u5b9e\u73b0\u3002<a href=\"https://twitter.com/labmlai\"><span translate=no>_^_0_^_</span></a>\u4ee5\u83b7\u53d6\u66f4\u65b0\u3002</p>\n",
 "<span translate=no>_^_0_^_</span>": "<span translate=no>_^_0_^_</span>",
 "<ul><li><a href=\"activations/fta/index.html\">Fuzzy Tiling Activations</a></li></ul>\n": "<ul><li><a href=\"activations/fta/index.html\">\u6a21\u7cca\u5e73\u94fa\u6fc0\u6d3b</a></li></ul>\n",
 "<ul><li><a href=\"adaptive_computation/ponder_net/index.html\">PonderNet</a></li></ul>\n": "<ul><li><a href=\"adaptive_computation/ponder_net/index.html\">PonderNet</a></li></ul>\n",
 "<ul><li><a href=\"cfr/kuhn/index.html\">Kuhn Poker</a></li></ul>\n": "<ul><li><a href=\"cfr/kuhn/index.html\">\u5e93\u6069\u6251\u514b</a></li></ul>\n",
 "<ul><li><a href=\"diffusion/ddpm/index.html\">Denoising Diffusion Probabilistic Models (DDPM)</a> </li>\n<li><a href=\"diffusion/stable_diffusion/sampler/ddim.html\">Denoising Diffusion Implicit Models (DDIM)</a> </li>\n<li><a href=\"diffusion/stable_diffusion/latent_diffusion.html\">Latent Diffusion Models</a> </li>\n<li><a href=\"diffusion/stable_diffusion/index.html\">Stable Diffusion</a></li></ul>\n": "<ul><li><a href=\"diffusion/ddpm/index.html\">\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b (DDPM)</a></li>\n<li><a href=\"diffusion/stable_diffusion/sampler/ddim.html\">\u964d\u566a\u6269\u6563\u9690\u542b\u6a21\u578b (DDIM)</a></li>\n<li><a href=\"diffusion/stable_diffusion/latent_diffusion.html\">\u6f5c\u5728\u6269\u6563\u6a21\u578b</a></li>\n<li><a href=\"diffusion/stable_diffusion/index.html\">\u7a33\u5b9a\u7684\u6269\u6563</a></li></ul>\n",
 "<ul><li><a href=\"gan/original/index.html\">Original GAN</a> </li>\n<li><a href=\"gan/dcgan/index.html\">GAN with deep convolutional network</a> </li>\n<li><a href=\"gan/cycle_gan/index.html\">Cycle GAN</a> </li>\n<li><a href=\"gan/wasserstein/index.html\">Wasserstein GAN</a> </li>\n<li><a href=\"gan/wasserstein/gradient_penalty/index.html\">Wasserstein GAN with Gradient Penalty</a> </li>\n<li><a href=\"gan/stylegan/index.html\">StyleGAN 2</a></li></ul>\n": "<ul><li><a href=\"gan/original/index.html\">\u539f\u88c5 GAN</a></li>\n<li><a href=\"gan/dcgan/index.html\">\u5177\u6709\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc\u7684 GAN</a></li>\n<li><a href=\"gan/cycle_gan/index.html\">\u5faa\u73af\u589e\u76ca</a></li>\n<li><a href=\"gan/wasserstein/index.html\">Wasserstein GAN</a></li>\n<li><a href=\"gan/wasserstein/gradient_penalty/index.html\">Wasserstein GAN \u5e26\u68af\u5ea6\u60e9\u7f5a</a></li>\n<li><a href=\"gan/stylegan/index.html\">StyleGan 2</a></li></ul>\n",
 "<ul><li><a href=\"graphs/gat/index.html\">Graph Attention Networks (GAT)</a> </li>\n<li><a href=\"graphs/gatv2/index.html\">Graph Attention Networks v2 (GATv2)</a></li></ul>\n": "<ul><li><a href=\"graphs/gat/index.html\">\u56fe\u5173\u6ce8\u7f51\u7edc (GAT)</a></li>\n<li><a href=\"graphs/gatv2/index.html\">Graph \u6ce8\u610f\u529b\u7f51\u7edc v2 (GATv2)</a></li></ul>\n",
 "<ul><li><a href=\"neox/samples/generate.html\">Generate on a 48GB GPU</a> </li>\n<li><a href=\"neox/samples/finetune.html\">Finetune on two 48GB GPUs</a> </li>\n<li><a href=\"neox/utils/llm_int8.html\">LLM.int8()</a></li></ul>\n": "<li><a href=\"neox/samples/generate.html\">\u5728 48GB GPU \u4e0a\u751f\u6210</a></li> <ul>\n<li><a href=\"neox/samples/finetune.html\">\u4e24\u4e2a 48GB GPU \u4e0a\u7684 Finetune</a></li>\n<li><a href=\"neox/utils/llm_int8.html\">llm.int8 ()</a></li></ul>\n",
 "<ul><li><a href=\"normalization/batch_norm/index.html\">Batch Normalization</a> </li>\n<li><a href=\"normalization/layer_norm/index.html\">Layer Normalization</a> </li>\n<li><a href=\"normalization/instance_norm/index.html\">Instance Normalization</a> </li>\n<li><a href=\"normalization/group_norm/index.html\">Group Normalization</a> </li>\n<li><a href=\"normalization/weight_standardization/index.html\">Weight Standardization</a> </li>\n<li><a href=\"normalization/batch_channel_norm/index.html\">Batch-Channel Normalization</a> </li>\n<li><a href=\"normalization/deep_norm/index.html\">DeepNorm</a></li></ul>\n": "<ul><li><a href=\"normalization/batch_norm/index.html\">\u6279\u91cf\u6807\u51c6\u5316</a></li>\n<li><a href=\"normalization/layer_norm/index.html\">\u5c42\u89c4\u8303\u5316</a></li>\n<li><a href=\"normalization/instance_norm/index.html\">\u5b9e\u4f8b\u89c4\u8303\u5316</a></li>\n<li><a href=\"normalization/group_norm/index.html\">\u7fa4\u7ec4\u89c4\u8303\u5316</a></li>\n<li><a href=\"normalization/weight_standardization/index.html\">\u91cd\u91cf\u6807\u51c6\u5316</a></li>\n<li><a href=\"normalization/batch_channel_norm/index.html\">\u6279\u91cf\u4fe1\u9053\u89c4\u8303\u5316</a></li>\n<li><a href=\"normalization/deep_norm/index.html\">\u6df1\u5ea6\u89c4\u8303</a></li></ul>\n",
 "<ul><li><a href=\"optimizers/adam.html\">Adam</a> </li>\n<li><a href=\"optimizers/amsgrad.html\">AMSGrad</a> </li>\n<li><a href=\"optimizers/adam_warmup.html\">Adam Optimizer with warmup</a> </li>\n<li><a href=\"optimizers/noam.html\">Noam Optimizer</a> </li>\n<li><a href=\"optimizers/radam.html\">Rectified Adam Optimizer</a> </li>\n<li><a href=\"optimizers/ada_belief.html\">AdaBelief Optimizer</a></li></ul>\n": "<ul><li><a href=\"optimizers/adam.html\">\u4e9a\u5f53</a></li>\n<li><a href=\"optimizers/amsgrad.html\">\u963f\u59c6\u65af\u683c\u62c9\u5fb7</a></li>\n<li><a href=\"optimizers/adam_warmup.html\">Adam Optimizer \u5e26\u70ed\u8eab</a></li>\n<li><a href=\"optimizers/noam.html\">Noam \u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/radam.html\">\u7ea0\u6b63\u4e9a\u5f53\u4f18\u5316\u5668</a></li>\n<li><a href=\"optimizers/ada_belief.html\">adaBelief \u4f18\u5316\u5668</a></li></ul>\n",
 "<ul><li><a href=\"rl/ppo/index.html\">Proximal Policy Optimization</a> with  <a href=\"rl/ppo/gae.html\">Generalized Advantage Estimation</a> </li>\n<li><a href=\"rl/dqn/index.html\">Deep Q Networks</a> with  with <a href=\"rl/dqn/model.html\">Dueling Network</a>,  <a href=\"rl/dqn/replay_buffer.html\">Prioritized Replay</a>  and Double Q Network.</li></ul>\n": "<li>\u57fa\u4e8e<a href=\"rl/ppo/gae.html\">\u5e7f\u4e49<a href=\"rl/ppo/index.html\">\u4f18\u52bf\u4f30\u8ba1\u7684\u8fd1\u7aef\u7b56\u7565</a>\u4f18</a>\u5316</li> <ul>\nD@@ <li><a href=\"rl/dqn/index.html\">eep Q Network</a> s \u5e26\u6709<a href=\"rl/dqn/model.html\">\u51b3\u6597\u7f51\u7edc</a>\u3001<a href=\"rl/dqn/replay_buffer.html\">\u4f18\u5148\u91cd\u64ad</a>\u548c Double Q Network\u3002</li></ul>\n",
 "<ul><li><a href=\"sampling/greedy.html\">Greedy Sampling</a> </li>\n<li><a href=\"sampling/temperature.html\">Temperature Sampling</a> </li>\n<li><a href=\"sampling/top_k.html\">Top-k Sampling</a> </li>\n<li><a href=\"sampling/nucleus.html\">Nucleus Sampling</a></li></ul>\n": "<ul><li><a href=\"sampling/greedy.html\">\u8d2a\u5a6a\u91c7\u6837</a></li>\n<li><a href=\"sampling/temperature.html\">\u6e29\u5ea6\u91c7\u6837</a></li>\n<li><a href=\"sampling/top_k.html\">\u524d k \u4e2a\u91c7\u6837</a></li>\n<li><a href=\"sampling/nucleus.html\">\u539f\u5b50\u6838\u91c7\u6837</a></li></ul>\n",
 "<ul><li><a href=\"scaling/zero3/index.html\">Zero3 memory optimizations</a></li></ul>\n": "<ul><li><a href=\"scaling/zero3/index.html\">Zero3 \u5185\u5b58\u4f18\u5316</a></li></ul>\n",
 "<ul><li><a href=\"transformers/mha.html\">Multi-headed attention</a> </li>\n<li><a href=\"transformers/models.html\">Transformer building blocks</a> </li>\n<li><a href=\"transformers/xl/index.html\">Transformer XL</a>  </li>\n<li><a href=\"transformers/xl/relative_mha.html\">Relative multi-headed attention</a> </li>\n<li><a href=\"transformers/rope/index.html\">Rotary Positional Embeddings (RoPE)</a> </li>\n<li><a href=\"transformers/alibi/index.html\">Attention with Linear Biases (ALiBi)</a> </li>\n<li><a href=\"transformers/retro/index.html\">RETRO</a> </li>\n<li><a href=\"transformers/compressive/index.html\">Compressive Transformer</a> </li>\n<li><a href=\"transformers/gpt/index.html\">GPT Architecture</a> </li>\n<li><a href=\"transformers/glu_variants/simple.html\">GLU Variants</a> </li>\n<li><a href=\"transformers/knn/index.html\">kNN-LM: Generalization through Memorization</a> </li>\n<li><a href=\"transformers/feedback/index.html\">Feedback Transformer</a> </li>\n<li><a href=\"transformers/switch/index.html\">Switch Transformer</a> </li>\n<li><a href=\"transformers/fast_weights/index.html\">Fast Weights Transformer</a> </li>\n<li><a href=\"transformers/fnet/index.html\">FNet</a> </li>\n<li><a href=\"transformers/aft/index.html\">Attention Free Transformer</a> </li>\n<li><a href=\"transformers/mlm/index.html\">Masked Language Model</a> </li>\n<li><a href=\"transformers/mlp_mixer/index.html\">MLP-Mixer: An all-MLP Architecture for Vision</a> </li>\n<li><a href=\"transformers/gmlp/index.html\">Pay Attention to MLPs (gMLP)</a> </li>\n<li><a href=\"transformers/vit/index.html\">Vision Transformer (ViT)</a> </li>\n<li><a href=\"transformers/primer_ez/index.html\">Primer EZ</a> </li>\n<li><a href=\"transformers/hour_glass/index.html\">Hourglass</a></li></ul>\n": "<ul><li><a href=\"transformers/mha.html\">\u591a\u5934\u5173\u6ce8</a></li>\n<li><a href=\"transformers/models.html\">\u53d8\u538b\u5668\u79ef\u6728</a></li>\n<li><a href=\"transformers/xl/index.html\">\u53d8\u538b\u5668 XL</a></li>\n<li><a href=\"transformers/xl/relative_mha.html\">\u76f8\u5bf9\u591a\u5934\u7684\u6ce8\u610f\u529b</a></li>\n<li><a href=\"transformers/rope/index.html\">\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165 (ROPE)</a></li>\n<li><a href=\"transformers/alibi/index.html\">\u6ce8\u610f\u7ebf\u6027\u504f\u5dee (AliBI)</a></li>\n<li><a href=\"transformers/retro/index.html\">\u590d\u53e4</a></li>\n<li><a href=\"transformers/compressive/index.html\">\u538b\u7f29\u53d8\u538b\u5668</a></li>\n<li><a href=\"transformers/gpt/index.html\">GPT \u67b6\u6784</a></li>\n<li><a href=\"transformers/glu_variants/simple.html\">GLU \u53d8\u4f53</a></li>\n<li><a href=\"transformers/knn/index.html\">knn-LM\uff1a\u901a\u8fc7\u8bb0\u5fc6\u8fdb\u884c\u6cdb\u5316</a></li>\n<li><a href=\"transformers/feedback/index.html\">\u53cd\u9988\u53d8\u538b\u5668</a></li>\n<li><a href=\"transformers/switch/index.html\">\u5f00\u5173\u53d8\u538b\u5668</a></li>\n<li><a href=\"transformers/fast_weights/index.html\">\u5feb\u901f\u91cd\u91cf\u53d8\u538b\u5668</a></li>\n<li><a href=\"transformers/fnet/index.html\">FNet</a></li>\n<li><a href=\"transformers/aft/index.html\">\u514d\u6ce8\u610f\u53d8\u538b\u5668</a></li>\n<li><a href=\"transformers/mlm/index.html\">\u5c4f\u853d\u8bed\u8a00\u6a21\u578b</a></li>\n<li><a href=\"transformers/mlp_mixer/index.html\">MLP \u6df7\u97f3\u5668\uff1a\u9762\u5411\u89c6\u89c9\u7684\u5168 MLP \u67b6\u6784</a></li>\n<li><a href=\"transformers/gmlp/index.html\">\u6ce8\u610f MLP (gMLP)</a></li>\n<li><a href=\"transformers/vit/index.html\">\u89c6\u89c9\u53d8\u538b\u5668 (ViT)</a></li>\n<li><a href=\"transformers/primer_ez/index.html\">Primer</a></li>\n<li><a href=\"transformers/hour_glass/index.html\">\u6c99\u6f0f</a></li></ul>\n",
 "<ul><li><a href=\"uncertainty/evidence/index.html\">Evidential Deep Learning to Quantify Classification Uncertainty</a></li></ul>\n": "<ul><li><a href=\"uncertainty/evidence/index.html\">\u7528\u4e8e\u91cf\u5316\u5206\u7c7b\u4e0d\u786e\u5b9a\u6027\u7684\u8bc1\u636e\u6027\u6df1\u5ea6\u5b66\u4e60</a></li></ul>\n",
 "labml.ai Annotated PyTorch Paper Implementations": "labml.ai \u5e26\u6ce8\u91ca\u7684 pyTorch \u8bba\u6587\u5b9e\u73b0"
}