{
 "<h1>Deep Residual Learning for Image Recognition (ResNet)</h1>\n<p>This is a <a href=\"https://pytorch.org\">PyTorch</a> implementation of the paper <a href=\"https://papers.labml.ai/paper/1512.03385\">Deep Residual Learning for Image Recognition</a>.</p>\n<p>ResNets train layers as residual functions to overcome the <em>degradation problem</em>. The degradation problem is the accuracy of deep neural networks degrading when the number of layers becomes very high. The accuracy increases as the number of layers increase, then saturates, and then starts to degrade.</p>\n<p>The paper argues that deeper models should perform at least as well as shallower models because the extra layers can just learn to perform an identity mapping.</p>\n<h2>Residual Learning</h2>\n<p>If <span translate=no>_^_0_^_</span> is the mapping that needs to be learned by a few layers, they train the residual function</p>\n<p><span translate=no>_^_1_^_</span></p>\n<p>instead. And the original function becomes <span translate=no>_^_2_^_</span>.</p>\n<p>In this case, learning identity mapping for <span translate=no>_^_3_^_</span> is equivalent to learning <span translate=no>_^_4_^_</span> to be <span translate=no>_^_5_^_</span>, which is easier to learn.</p>\n<p>In the parameterized form this can be written as,</p>\n<p><span translate=no>_^_6_^_</span></p>\n<p>and when the feature map sizes of <span translate=no>_^_7_^_</span> and <span translate=no>_^_8_^_</span> are different the paper suggests doing a linear projection, with learned weights <span translate=no>_^_9_^_</span>.</p>\n<p><span translate=no>_^_10_^_</span></p>\n<p>Paper experimented with zero padding instead of linear projections and found linear projections to work better. Also when the feature map sizes match they found identity mapping to be better than linear projections.</p>\n<p><span translate=no>_^_11_^_</span> should have more than one layer, otherwise the sum <span translate=no>_^_12_^_</span> also won&#x27;t have non-linearities and will be like a linear layer.</p>\n<p>Here is <a href=\"experiment.html\">the training code</a> for training a ResNet on CIFAR-10.</p>\n": "<h1>\u7528\u4e8e\u56fe\u50cf\u8bc6\u522b\u7684\u6df1\u5ea6\u6b8b\u5dee\u5b66\u4e60 (ResNet)</h1>\n<p>\u8fd9\u662f <a href=\"https://pytorch.org\">PyTorch</a> \u5bf9\u300a<a href=\"https://papers.labml.ai/paper/1512.03385\">\u7528\u4e8e\u56fe\u50cf\u8bc6\u522b\u7684\u6df1\u5ea6\u6b8b\u5dee\u5b66\u4e60</a>\u300b\u8bba\u6587\u7684\u5b9e\u73b0\u3002</p>\n<p>ResNet \u5c06\u56fe\u5c42\u8bad\u7ec3\u4e3a\u6b8b\u5dee\u51fd\u6570\u4ee5\u514b\u670d<em>\u9000\u5316\u95ee\u9898</em>\u3002\u9000\u5316\u95ee\u9898\u662f\u5f53\u5c42\u6570\u53d8\u5f97\u975e\u5e38\u9ad8\u65f6\uff0c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u7cbe\u5ea6\u4f1a\u964d\u4f4e\u3002\u968f\u7740\u5c42\u6570\u7684\u589e\u52a0\uff0c\u7cbe\u5ea6\u4f1a\u589e\u52a0\uff0c\u7136\u540e\u9971\u548c\uff0c\u7136\u540e\u5f00\u59cb\u964d\u7ea7\u3002</p>\n<p>\u8be5\u8bba\u6587\u8ba4\u4e3a\uff0c\u6df1\u5c42\u6a21\u578b\u7684\u6027\u80fd\u81f3\u5c11\u5e94\u4e0e\u8f83\u6d45\u7684\u6a21\u578b\u4e00\u6837\u597d\uff0c\u56e0\u4e3a\u989d\u5916\u7684\u5c42\u53ea\u80fd\u5b66\u4f1a\u8fdb\u884c\u8eab\u4efd\u6620\u5c04\u3002</p>\n<h2>\u5269\u4f59\u5b66\u4e60</h2>\n<p>\u5982\u679c<span translate=no>_^_0_^_</span>\u662f\u9700\u8981\u51e0\u5c42\u5b66\u4e60\u7684\u6620\u5c04\uff0c\u4ed6\u4eec\u4f1a\u8bad\u7ec3\u6b8b\u5dee\u51fd\u6570</p>\n<p><span translate=no>_^_1_^_</span></p>\n<p>\u76f8\u53cd\u3002\u539f\u6765\u7684\u51fd\u6570\u53d8\u6210<span translate=no>_^_2_^_</span>\u3002</p>\n<p>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5b66\u4e60\u8eab\u4efd\u6620\u5c04\u7b49\u540c<span translate=no>_^_4_^_</span>\u4e8e\u5b66\u4f1a\u6210\u4e3a<span translate=no>_^_5_^_</span>\uff0c\u540e\u8005\u66f4\u5bb9\u6613\u5b66\u4e60\u3002<span translate=no>_^_3_^_</span></p>\n<p>\u5728\u53c2\u6570\u5316\u5f62\u5f0f\u4e2d\uff0c\u8fd9\u53ef\u4ee5\u5199\u6210\uff0c</p>\n<p><span translate=no>_^_6_^_</span></p>\n<p>\u5f53\u548c\u7684\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u540c\u65f6\uff0c\u8bba\u6587\u5efa\u8bae\u4f7f\u7528<span translate=no>_^_8_^_</span>\u5df2\u5b66\u5230\u7684\u6743\u91cd\u8fdb\u884c\u7ebf\u6027\u6295\u5f71<span translate=no>_^_9_^_</span>\u3002<span translate=no>_^_7_^_</span></p>\n<p><span translate=no>_^_10_^_</span></p>\n<p>Paper \u5c1d\u8bd5\u7528\u96f6\u586b\u5145\u4ee3\u66ff\u7ebf\u6027\u6295\u5f71\uff0c\u53d1\u73b0\u7ebf\u6027\u6295\u5f71\u6548\u679c\u66f4\u597d\u3002\u6b64\u5916\uff0c\u5f53\u8981\u7d20\u56fe\u5927\u5c0f\u5339\u914d\u65f6\uff0c\u4ed6\u4eec\u53d1\u73b0\u8eab\u4efd\u6620\u5c04\u6bd4\u7ebf\u6027\u6295\u5f71\u66f4\u597d\u3002</p>\n<p><span translate=no>_^_11_^_</span>\u5e94\u8be5\u6709\u591a\u4e2a\u5c42\uff0c\u5426\u5219\u603b\u548c<span translate=no>_^_12_^_</span>\u4e5f\u4e0d\u4f1a\u6709\u975e\u7ebf\u6027\uff0c\u5c31\u50cf\u7ebf\u6027\u56fe\u5c42\u4e00\u6837\u3002</p>\n<p>\u4ee5\u4e0b\u662f<a href=\"experiment.html\">\u5728 CIFAR-10 \u4e0a\u8bad\u7ec3 ResNet \u7684\u8bad\u7ec3\u4ee3\u7801</a>\u3002</p>\n",
 "<h2>Linear projections for shortcut connection</h2>\n<p>This does the <span translate=no>_^_0_^_</span> projection described above.</p>\n": "<h2>\u7528\u4e8e\u5feb\u6377\u8fde\u63a5\u7684\u7ebf\u6027\u6295\u5f71</h2>\n<p>\u8fd9\u662f\u4e0a\u9762\u63cf\u8ff0\u7684<span translate=no>_^_0_^_</span>\u6295\u5f71\u3002</p>\n",
 "<h2>ResNet Model</h2>\n<p>This is a the base of the resnet model without the final linear layer and softmax for classification.</p>\n<p>The resnet is made of stacked <a href=\"#residual_block\">residual blocks</a> or <a href=\"#bottleneck_residual_block\">bottleneck residual blocks</a>. The feature map size is halved after a few blocks with a block of stride length <span translate=no>_^_0_^_</span>. The number of channels is increased when the feature map size is reduced. Finally the feature map is average pooled to get a vector representation.</p>\n": "<h2>ResNet \u6a21\u578b</h2>\n<p>\u8fd9\u662f resnet \u6a21\u578b\u7684\u57fa\u7840\uff0c\u6ca1\u6709\u6700\u7ec8\u7684\u7ebf\u6027\u5c42\u548c\u7528\u4e8e\u5206\u7c7b\u7684 softmax\u3002</p>\n<p>resnet \u7531\u5806\u53e0\u7684<a href=\"#residual_block\">\u6b8b\u5dee\u5757</a>\u6216<a href=\"#bottleneck_residual_block\">\u74f6\u9888\u6b8b\u5dee\u5757</a>\u7ec4\u6210\u3002\u8981\u7d20\u5730\u56fe\u7684\u5927\u5c0f\u5728\u7ecf\u8fc7\u51e0\u4e2a\u65b9\u5757\u7684\u6b65\u957f\u540e\u51cf\u534a<span translate=no>_^_0_^_</span>\u3002\u7f29\u5c0f\u8981\u7d20\u56fe\u5927\u5c0f\u65f6\uff0c\u4fe1\u9053\u7684\u6570\u91cf\u4f1a\u589e\u52a0\u3002\u6700\u540e\uff0c\u5c06\u8981\u7d20\u5730\u56fe\u5e73\u5747\u5408\u5e76\u4ee5\u83b7\u5f97\u77e2\u91cf\u5236\u56fe\u8868\u8fbe\u3002</p>\n",
 "<p> <a id=\"bottleneck_residual_block\"></a></p>\n<h2>Bottleneck Residual Block</h2>\n<p>This implements the bottleneck block described in the paper. It has <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>, and <span translate=no>_^_2_^_</span> convolution layers.</p>\n<p><span translate=no>_^_3_^_</span></p>\n<p>The first convolution layer maps from <span translate=no>_^_4_^_</span> to <span translate=no>_^_5_^_</span> with a <span translate=no>_^_6_^_</span> convolution, where the <span translate=no>_^_7_^_</span> is lower than <span translate=no>_^_8_^_</span>.</p>\n<p>The second <span translate=no>_^_9_^_</span> convolution layer maps from <span translate=no>_^_10_^_</span> to <span translate=no>_^_11_^_</span>. This can have a stride length greater than <span translate=no>_^_12_^_</span> when we want to compress the feature map size.</p>\n<p>The third, final <span translate=no>_^_13_^_</span> convolution layer maps to <span translate=no>_^_14_^_</span>. <span translate=no>_^_15_^_</span> is higher than <span translate=no>_^_16_^_</span> if the stride length is greater than <span translate=no>_^_17_^_</span>; otherwise, <span translate=no>_^_18_^_</span> is equal to <span translate=no>_^_19_^_</span>.</p>\n<p><span translate=no>_^_20_^_</span> is less than <span translate=no>_^_21_^_</span> and the <span translate=no>_^_22_^_</span> convolution is performed on this shrunk space (hence the bottleneck). The two <span translate=no>_^_23_^_</span> convolution decreases and increases the number of channels.</p>\n": "<p><a id=\"bottleneck_residual_block\"></a></p>\n<h2>\u74f6\u9888\u6b8b\u7559\u5757</h2>\n<p>\u8fd9\u5b9e\u73b0\u4e86\u672c\u6587\u4e2d\u63cf\u8ff0\u7684\u74f6\u9888\u5757\u3002\u5b83\u6709<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u3001\u548c<span translate=no>_^_2_^_</span>\u5377\u79ef\u5c42\u3002</p>\n<p><span translate=no>_^_3_^_</span></p>\n<p>\u7b2c\u4e00\u4e2a\u5377\u79ef\u56fe\u5c42<span translate=no>_^_5_^_</span>\u4f7f\u7528<span translate=no>_^_6_^_</span>\u5377\u79ef\u4ece\u6620\u5c04<span translate=no>_^_4_^_</span>\u5230\uff0c\u5176\u4e2d\u5c0f<span translate=no>_^_7_^_</span>\u4e8e<span translate=no>_^_8_^_</span>\u3002</p>\n<p>\u7b2c\u4e8c\u4e2a<span translate=no>_^_9_^_</span>\u5377\u79ef\u56fe\u5c42\u4ece\u6620\u5c04<span translate=no>_^_10_^_</span>\u5230<span translate=no>_^_11_^_</span>\u3002\u8fd9\u53ef\u4ee5\u4f7f\u6b65\u5e45\u957f\u5ea6\u5927\u4e8e<span translate=no>_^_12_^_</span>\u6211\u4eec\u60f3\u8981\u538b\u7f29\u8981\u7d20\u8d34\u56fe\u5927\u5c0f\u7684\u6b65\u957f\u3002</p>\n<p>\u7b2c\u4e09\u4e2a\u4e5f\u662f\u6700\u540e\u4e00\u4e2a<span translate=no>_^_13_^_</span>\u5377\u79ef\u5c42\u6620\u5c04\u5230<span translate=no>_^_14_^_</span>\u3002<span translate=no>_^_15_^_</span><span translate=no>_^_16_^_</span>\u5982\u679c\u6b65\u5e45\u957f\u5ea6\u5927\u4e8e\uff0c\u5219\u5927\u4e8e<span translate=no>_^_17_^_</span>\uff1b\u5426\u5219\u7b49<span translate=no>_^_18_^_</span>\u4e8e<span translate=no>_^_19_^_</span>\u3002</p>\n<p><span translate=no>_^_20_^_</span>\u5c0f\u4e8e<span translate=no>_^_21_^_</span>\uff0c<span translate=no>_^_22_^_</span>\u5377\u79ef\u662f\u5728\u8fd9\u4e2a\u7f29\u5c0f\u7684\u7a7a\u95f4\u4e0a\u6267\u884c\u7684\uff08\u56e0\u6b64\u662f\u74f6\u9888\uff09\u3002\u4e24\u4e2a<span translate=no>_^_23_^_</span>\u5377\u79ef\u4f1a\u51cf\u5c11\u5e76\u589e\u52a0\u901a\u9053\u7684\u6570\u91cf\u3002</p>\n",
 "<p> <a id=\"residual_block\"></a></p>\n<h2>Residual Block</h2>\n<p>This implements the residual block described in the paper. It has two <span translate=no>_^_0_^_</span> convolution layers.</p>\n<p><span translate=no>_^_1_^_</span></p>\n<p>The first convolution layer maps from <span translate=no>_^_2_^_</span> to <span translate=no>_^_3_^_</span>, where the <span translate=no>_^_4_^_</span> is higher than <span translate=no>_^_5_^_</span> when we reduce the feature map size with a stride length greater than <span translate=no>_^_6_^_</span>.</p>\n<p>The second convolution layer maps from <span translate=no>_^_7_^_</span> to <span translate=no>_^_8_^_</span> and always has a stride length of 1.</p>\n<p>Both convolution layers are followed by batch normalization.</p>\n": "<p><a id=\"residual_block\"></a></p>\n<h2>\u5269\u4f59\u65b9\u5757</h2>\n<p>\u8fd9\u5b9e\u73b0\u4e86\u672c\u6587\u4e2d\u63cf\u8ff0\u7684\u6b8b\u7559\u5757\u3002\u5b83\u6709\u4e24\u4e2a<span translate=no>_^_0_^_</span>\u5377\u79ef\u5c42\u3002</p>\n<p><span translate=no>_^_1_^_</span></p>\n<p>\u7b2c\u4e00\u4e2a\u5377\u79ef\u56fe\u5c42\u6620\u5c04\u4ece<span translate=no>_^_2_^_</span>\u5230<span translate=no>_^_3_^_</span>\uff0c\u5176\u4e2d\u9ad8<span translate=no>_^_4_^_</span>\u4e8e\u6211\u4eec\u4f7f\u7528\u6b65\u5e45\u7f29\u5c0f\u8981\u7d20\u5730\u56fe\u5927\u5c0f<span translate=no>_^_5_^_</span>\u65f6\u7684\u503c\u5927\u4e8e<span translate=no>_^_6_^_</span>\u3002</p>\n<p>\u7b2c\u4e8c\u4e2a\u5377\u79ef\u56fe\u5c42\u4ece\u6620\u5c04<span translate=no>_^_7_^_</span>\u5230<span translate=no>_^_8_^_</span>\uff0c\u6b65\u957f\u59cb\u7ec8\u4e3a 1\u3002</p>\n<p>\u4e24\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u90fd\u662f\u6279\u91cf\u5f52\u4e00\u5316\u3002</p>\n",
 "<p><a href=\"#bottleneck_residual_block\">bottleneck residual blocks</a> </p>\n": "<p><a href=\"#bottleneck_residual_block\">\u74f6\u9888\u6b8b\u7559\u5757</a></p>\n",
 "<p><a href=\"#bottleneck_residual_block\">bottleneck residual blocks</a> that maps from <span translate=no>_^_0_^_</span> to <span translate=no>_^_1_^_</span> </p>\n": "<p>\u4ece\u6620\u5c04\u5230<span translate=no>_^_0_^_</span>\u7684<a href=\"#bottleneck_residual_block\">\u74f6\u9888\u6b8b\u5dee\u5757</a><span translate=no>_^_1_^_</span></p>\n",
 "<p><a href=\"#residual_block\">residual blocks</a> </p>\n": "<p><a href=\"#residual_block\">\u5269\u4f59\u65b9\u5757</a></p>\n",
 "<p><a href=\"#residual_block\">residual blocks</a> that maps from <span translate=no>_^_0_^_</span> to <span translate=no>_^_1_^_</span> </p>\n": "<p>\u4ece\u6620\u5c04<span translate=no>_^_0_^_</span>\u5230\u7684<a href=\"#residual_block\">\u6b8b\u5dee\u5757</a><span translate=no>_^_1_^_</span></p>\n",
 "<p>Activation function after adding the shortcut </p>\n": "<p>\u6dfb\u52a0\u5feb\u6377\u952e\u540e\u6fc0\u6d3b\u529f\u80fd</p>\n",
 "<p>Add rest of the blocks - no change in feature map size or channels </p>\n": "<p>\u6dfb\u52a0\u5176\u4f59\u65b9\u5757-\u7279\u5f81\u56fe\u5927\u5c0f\u6216\u9891\u9053\u6ca1\u6709\u53d8\u5316</p>\n",
 "<p>Batch norm after initial convolution </p>\n": "<p>\u521d\u59cb\u5377\u79ef\u540e\u7684\u6279\u91cf\u8303\u6570</p>\n",
 "<p>Batch normalization after the first convolution </p>\n": "<p>\u7b2c\u4e00\u6b21\u5377\u79ef\u540e\u7684\u6279\u91cf\u5f52\u4e00\u5316</p>\n",
 "<p>Batch normalization after the second convolution </p>\n": "<p>\u7b2c\u4e8c\u6b21\u5377\u79ef\u540e\u7684\u6279\u91cf\u5f52\u4e00\u5316</p>\n",
 "<p>Change <span translate=no>_^_0_^_</span> from shape <span translate=no>_^_1_^_</span> to <span translate=no>_^_2_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span>\u4ece\u5f62\u72b6\u6539<span translate=no>_^_1_^_</span>\u4e3a<span translate=no>_^_2_^_</span></p>\n",
 "<p>Change the number of channels </p>\n": "<p>\u66f4\u6539\u9891\u9053\u6570\u91cf</p>\n",
 "<p>Convolution and batch normalization </p>\n": "<p>\u5377\u79ef\u548c\u6279\u91cf\u5f52\u4e00\u5316</p>\n",
 "<p>Convolution layer for linear projection <span translate=no>_^_0_^_</span> </p>\n": "<p>\u7ebf\u6027\u6295\u5f71\u7684\u5377\u79ef\u5c42<span translate=no>_^_0_^_</span></p>\n",
 "<p>First <span translate=no>_^_0_^_</span> convolution layer, this maps to <span translate=no>_^_1_^_</span> </p>\n": "<p>\u7b2c\u4e00\u4e2a<span translate=no>_^_0_^_</span>\u5377\u79ef\u5c42\uff0c\u5b83\u6620\u5c04\u5230<span translate=no>_^_1_^_</span></p>\n",
 "<p>First activation function (ReLU) </p>\n": "<p>\u7b2c\u4e00\u4e2a\u6fc0\u6d3b\u51fd\u6570 (ReLU)</p>\n",
 "<p>First convolution and activation </p>\n": "<p>\u7b2c\u4e00\u6b21\u5377\u79ef\u548c\u6fc0\u6d3b</p>\n",
 "<p>Get the shortcut connection </p>\n": "<p>\u83b7\u53d6\u5feb\u6377\u65b9\u5f0f\u8fde\u63a5</p>\n",
 "<p>Global average pooling </p>\n": "<p>\u5168\u7403\u5e73\u5747\u6c47\u96c6</p>\n",
 "<p>Identity <span translate=no>_^_0_^_</span> </p>\n": "<p>\u8eab\u4efd<span translate=no>_^_0_^_</span></p>\n",
 "<p>If <a href=\"#bottleneck_residual_block\">bottleneck residual blocks</a> are used, the number of channels in bottlenecks should be provided for each feature map size </p>\n": "<p>\u5982\u679c\u4f7f\u7528<a href=\"#bottleneck_residual_block\">\u74f6\u9888\u6b8b\u5dee\u5757</a>\uff0c\u5219\u5e94\u4e3a\u6bcf\u4e2a\u8981\u7d20\u6620\u5c04\u5927\u5c0f\u63d0\u4f9b\u74f6\u9888\u4e2d\u7684\u901a\u9053\u6570</p>\n",
 "<p>Initial convolution and batch normalization </p>\n": "<p>\u521d\u59cb\u5377\u79ef\u548c\u6279\u91cf\u5f52\u4e00\u5316</p>\n",
 "<p>Initial convolution layer maps from <span translate=no>_^_0_^_</span> to number of channels in the first residual block (<span translate=no>_^_1_^_</span>) </p>\n": "<p>\u521d\u59cb\u5377\u79ef\u5c42\u4ece\u6620\u5c04<span translate=no>_^_0_^_</span>\u5230\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u4e2d\u7684\u901a\u9053\u6570 (<span translate=no>_^_1_^_</span>)</p>\n",
 "<p>List of blocks </p>\n": "<p>\u533a\u5757\u6e05\u5355</p>\n",
 "<p>Loop through each feature map size </p>\n": "<p>\u5faa\u73af\u6d4f\u89c8\u6bcf\u4e2a\u8981\u7d20\u5730\u56fe\u5927\u5c0f</p>\n",
 "<p>Number of blocks and number of channels for each feature map size </p>\n": "<p>\u6bcf\u4e2a\u8981\u7d20\u6620\u5c04\u5927\u5c0f\u7684\u533a\u5757\u6570\u548c\u901a\u9053\u6570</p>\n",
 "<p>Number of channels from previous layer (or block) </p>\n": "<p>\u6765\u81ea\u4e0a\u4e00\u5c42\uff08\u6216\u5757\uff09\u7684\u901a\u9053\u6570</p>\n",
 "<p>Paper suggests adding batch normalization after each convolution operation </p>\n": "<p>\u8bba\u6587\u5efa\u8bae\u5728\u6bcf\u6b21\u5377\u79ef\u64cd\u4f5c\u540e\u6dfb\u52a0\u6279\u91cf\u5f52\u4e00\u5316</p>\n",
 "<p>Projection <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6295\u5f71<span translate=no>_^_0_^_</span></p>\n",
 "<p>Residual (or bottleneck) blocks </p>\n": "<p>\u6b8b\u7559\uff08\u6216\u74f6\u9888\uff09\u5757</p>\n",
 "<p>Second <span translate=no>_^_0_^_</span> convolution layer </p>\n": "<p>\u7b2c\u4e8c\u4e2a<span translate=no>_^_0_^_</span>\u5377\u79ef\u5c42</p>\n",
 "<p>Second activation function (ReLU) (after adding the shortcut) </p>\n": "<p>\u7b2c\u4e8c\u4e2a\u6fc0\u6d3b\u529f\u80fd\uff08RelU\uff09\uff08\u6dfb\u52a0\u5feb\u6377\u65b9\u5f0f\u540e\uff09</p>\n",
 "<p>Second activation function (ReLU) </p>\n": "<p>\u7b2c\u4e8c\u4e2a\u6fc0\u6d3b\u51fd\u6570 (ReLU)</p>\n",
 "<p>Second convolution </p>\n": "<p>\u7b2c\u4e8c\u6b21\u5377\u79ef</p>\n",
 "<p>Second convolution and activation </p>\n": "<p>\u7b2c\u4e8c\u6b21\u5377\u79ef\u548c\u6fc0\u6d3b</p>\n",
 "<p>Shortcut connection should be a projection if the stride length is not <span translate=no>_^_0_^_</span> of if the number of channels change </p>\n": "<p>\u5982\u679c\u6b65\u957f\u4e0d<span translate=no>_^_0_^_</span>\u662f\uff0c\u5982\u679c\u901a\u9053\u6570\u53d1\u751f\u53d8\u5316\uff0c\u5219\u5feb\u6377\u8fde\u63a5\u5e94\u4e3a\u6295\u5f71</p>\n",
 "<p>Stack the blocks </p>\n": "<p>\u5806\u53e0\u65b9\u5757</p>\n",
 "<p>The first block for the new feature map size, will have a stride length of <span translate=no>_^_0_^_</span> except fro the very first block </p>\n": "<p>\u65b0\u8981\u7d20\u5730\u56fe\u5927\u5c0f\u7684\u7b2c\u4e00\u4e2a\u65b9\u5757\u7684\u6b65\u5e45\u957f\u5ea6\u5c06\u4e3a<span translate=no>_^_0_^_</span>\u9664\u7b2c\u4e00\u4e2a\u65b9\u5757\u5916</p>\n",
 "<p>Third <span translate=no>_^_0_^_</span> convolution layer, this maps to <span translate=no>_^_1_^_</span>. </p>\n": "<p>\u7b2c\u4e09\u4e2a<span translate=no>_^_0_^_</span>\u5377\u79ef\u5c42\uff0c\u6620\u5c04\u5230<span translate=no>_^_1_^_</span>\u3002</p>\n",
 "<p>Third convolution </p>\n": "<p>\u7b2c\u4e09\u6b21\u5377\u79ef</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> has shape <span translate=no>_^_1_^_</span></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u6709\u5f62\u72b6<span translate=no>_^_1_^_</span></li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is a list of of number of blocks for each feature map size. </li>\n<li><span translate=no>_^_1_^_</span> is the number of channels for each feature map size. </li>\n<li><span translate=no>_^_2_^_</span> is the number of channels the bottlenecks. If this is <span translate=no>_^_3_^_</span>, <a href=\"#residual_block\">residual blocks</a> are used. </li>\n<li><span translate=no>_^_4_^_</span> is the number of channels in the input. </li>\n<li><span translate=no>_^_5_^_</span> is the kernel size of the initial convolution layer</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u6bcf\u4e2a\u8981\u7d20\u56fe\u5927\u5c0f\u7684\u533a\u5757\u6570\u7684\u5217\u8868\u3002</li>\n<li><span translate=no>_^_1_^_</span>\u662f\u6bcf\u4e2a\u8981\u7d20\u6620\u5c04\u5927\u5c0f\u7684\u901a\u9053\u6570\u3002</li>\n<li><span translate=no>_^_2_^_</span>\u662f\u74f6\u9888\u7684\u6e20\u9053\u6570\u91cf\u3002\u5982\u679c\u662f<span translate=no>_^_3_^_</span>\uff0c\u5219\u4f7f\u7528<a href=\"#residual_block\">\u6b8b\u5dee\u5757</a>\u3002</li>\n<li><span translate=no>_^_4_^_</span>\u662f\u8f93\u5165\u4e2d\u7684\u58f0\u9053\u6570\u3002</li>\n<li><span translate=no>_^_5_^_</span>\u662f\u521d\u59cb\u5377\u79ef\u5c42\u7684\u5185\u6838\u5927\u5c0f</li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the input of shape <span translate=no>_^_1_^_</span></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u5f62\u72b6\u7684\u8f93\u5165<span translate=no>_^_1_^_</span></li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the number of channels in <span translate=no>_^_1_^_</span> </li>\n<li><span translate=no>_^_2_^_</span> is the number of channels for the <span translate=no>_^_3_^_</span> convlution </li>\n<li><span translate=no>_^_4_^_</span> is the number of output channels </li>\n<li><span translate=no>_^_5_^_</span> is the stride length in the <span translate=no>_^_6_^_</span> convolution operation.</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u5176\u4e2d\u7684\u9891\u9053\u6570\u91cf<span translate=no>_^_1_^_</span></li>\n<li><span translate=no>_^_2_^_</span>\u662f<span translate=no>_^_3_^_</span>\u5377\u79ef\u7684\u901a\u9053\u6570</li>\n<li><span translate=no>_^_4_^_</span>\u662f\u8f93\u51fa\u58f0\u9053\u7684\u6570\u91cf</li>\n<li><span translate=no>_^_5_^_</span>\u662f<span translate=no>_^_6_^_</span>\u5377\u79ef\u8fd0\u7b97\u4e2d\u7684\u6b65\u957f\u3002</li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the number of channels in <span translate=no>_^_1_^_</span> </li>\n<li><span translate=no>_^_2_^_</span> is the number of channels in <span translate=no>_^_3_^_</span> </li>\n<li><span translate=no>_^_4_^_</span> is the stride length in the convolution operation for <span translate=no>_^_5_^_</span>. We do the same stride on the shortcut connection, to match the feature-map size.</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u5176\u4e2d\u7684\u9891\u9053\u6570\u91cf<span translate=no>_^_1_^_</span></li>\n<li><span translate=no>_^_2_^_</span>\u662f\u5176\u4e2d\u7684\u9891\u9053\u6570\u91cf<span translate=no>_^_3_^_</span></li>\n<li><span translate=no>_^_4_^_</span>\u662f\u7684\u5377\u79ef\u8fd0\u7b97\u4e2d\u7684\u6b65\u957f<span translate=no>_^_5_^_</span>\u3002\u6211\u4eec\u5728\u5feb\u6377\u65b9\u5f0f\u8fde\u63a5\u4e0a\u505a\u540c\u6837\u7684\u6b65\u4f10\uff0c\u4ee5\u5339\u914d\u8981\u7d20\u6620\u5c04\u7684\u5927\u5c0f\u3002</li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the number of channels in <span translate=no>_^_1_^_</span> </li>\n<li><span translate=no>_^_2_^_</span> is the number of output channels </li>\n<li><span translate=no>_^_3_^_</span> is the stride length in the convolution operation.</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u5176\u4e2d\u7684\u9891\u9053\u6570\u91cf<span translate=no>_^_1_^_</span></li>\n<li><span translate=no>_^_2_^_</span>\u662f\u8f93\u51fa\u58f0\u9053\u7684\u6570\u91cf</li>\n<li><span translate=no>_^_3_^_</span>\u662f\u5377\u79ef\u8fd0\u7b97\u4e2d\u7684\u6b65\u957f\u3002</li></ul>\n",
 "A PyTorch implementation/tutorial of Deep Residual Learning for Image Recognition (ResNet).": "\u7528\u4e8e\u56fe\u50cf\u8bc6\u522b\u7684\u6df1\u5ea6\u6b8b\u5dee\u5b66\u4e60\uff08ResNet\uff09\u7684 PyTorch \u5b9e\u73b0/\u6559\u7a0b\u3002",
 "Deep Residual Learning for Image Recognition (ResNet)": "\u7528\u4e8e\u56fe\u50cf\u8bc6\u522b\u7684\u6df1\u5ea6\u6b8b\u5dee\u5b66\u4e60 (ResNet)"
}