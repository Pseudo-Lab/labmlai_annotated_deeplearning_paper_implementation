{
 "<h1>Train a Graph Attention Network v2 (GATv2) on Cora dataset</h1>\n": "<h1>\u5728 Cora \u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u56fe\u6ce8\u610f\u529b\u7f51\u7edc v2 (Gatv2)</h1>\n",
 "<h2>Configurations</h2>\n<p>Since the experiment is same as <a href=\"../gat/experiment.html\">GAT experiment</a> but with <a href=\"index.html\">GATv2 model</a> we extend the same configs and change the model.</p>\n": "<h2>\u914d\u7f6e</h2>\n<p>\u7531\u4e8e\u5b9e\u9a8c\u4e0e <a href=\"../gat/experiment.html\">GAT \u5b9e\u9a8c</a>\u76f8\u540c\uff0c\u4f46\u4f7f\u7528 G <a href=\"index.html\">ATv2 \u6a21\u578b</a>\uff0c\u6211\u4eec\u6269\u5c55\u4e86\u76f8\u540c\u7684\u914d\u7f6e\u5e76\u66f4\u6539\u4e86\u6a21\u578b\u3002</p>\n",
 "<h2>Graph Attention Network v2 (GATv2)</h2>\n<p>This graph attention network has two <a href=\"index.html\">graph attention layers</a>.</p>\n": "<h2>Graph \u6ce8\u610f\u529b\u7f51\u7edc v2 (GATv2)</h2>\n<p>\u8fd9\u4e2a\u56fe\u5f62\u5173\u6ce8\u7f51\u7edc\u6709\u4e24\u4e2a<a href=\"index.html\">\u56fe\u5f62\u5173\u6ce8\u5c42</a>\u3002</p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> Create GATv2 model</p>\n": "<p>\u521b\u5efa GATv2 \u6a21\u578b</p>\n",
 "<p>Activation function </p>\n": "<p>\u6fc0\u6d3b\u529f\u80fd</p>\n",
 "<p>Activation function after first graph attention layer </p>\n": "<p>\u7b2c\u4e00\u4e2a\u56fe\u5f62\u5173\u6ce8\u5c42\u4e4b\u540e\u7684\u6fc0\u6d3b\u529f\u80fd</p>\n",
 "<p>Adam optimizer </p>\n": "<p>Adam \u4f18\u5316\u5668</p>\n",
 "<p>Apply dropout to the input </p>\n": "<p>\u5c06\u4e22\u5931\u5e94\u7528\u4e8e\u8f93\u5165</p>\n",
 "<p>Calculate configurations. </p>\n": "<p>\u8ba1\u7b97\u914d\u7f6e\u3002</p>\n",
 "<p>Create an experiment </p>\n": "<p>\u521b\u5efa\u5b9e\u9a8c</p>\n",
 "<p>Create configurations </p>\n": "<p>\u521b\u5efa\u914d\u7f6e</p>\n",
 "<p>Dropout </p>\n": "<p>\u8f8d\u5b66</p>\n",
 "<p>Final graph attention layer where we average the heads </p>\n": "<p>\u6700\u540e\u4e00\u5f20\u56fe\u5173\u6ce8\u5c42\uff0c\u6211\u4eec\u5e73\u5747\u5934\u90e8</p>\n",
 "<p>First graph attention layer </p>\n": "<p>\u7b2c\u4e00\u4e2a\u56fe\u5f62\u5173\u6ce8\u5c42</p>\n",
 "<p>First graph attention layer where we concatenate the heads </p>\n": "<p>\u6211\u4eec\u8fde\u63a5\u5934\u90e8\u7684\u7b2c\u4e00\u4e2a\u56fe\u5f62\u6ce8\u610f\u5c42</p>\n",
 "<p>Output layer (without activation) for logits </p>\n": "<p>logits \u7684\u8f93\u51fa\u5c42\uff08\u672a\u6fc0\u6d3b\uff09</p>\n",
 "<p>Run the training </p>\n": "<p>\u8fd0\u884c\u8bad\u7ec3</p>\n",
 "<p>Set the model </p>\n": "<p>\u8bbe\u7f6e\u6a21\u578b</p>\n",
 "<p>Start and watch the experiment </p>\n": "<p>\u5f00\u59cb\u89c2\u770b\u5b9e\u9a8c</p>\n",
 "<p>Whether to share weights for source and target nodes of edges </p>\n": "<p>\u662f\u5426\u5171\u4eab\u8fb9\u7684\u6e90\u8282\u70b9\u548c\u76ee\u6807\u8282\u70b9\u7684\u6743\u91cd</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the features vectors of shape <span translate=no>_^_1_^_</span> </li>\n<li><span translate=no>_^_2_^_</span> is the adjacency matrix of the form  <span translate=no>_^_3_^_</span> or <span translate=no>_^_4_^_</span></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u5f62\u72b6\u7684\u7279\u5f81\u5411\u91cf<span translate=no>_^_1_^_</span></li>\n<li><span translate=no>_^_2_^_</span>\u662f\u5f62\u5f0f\u7684\u90bb\u63a5\u77e9\u9635<span translate=no>_^_3_^_</span>\u6216<span translate=no>_^_4_^_</span></li></ul>\n",
 "<ul><li><span translate=no>_^_0_^_</span> is the number of features per node </li>\n<li><span translate=no>_^_1_^_</span> is the number of features in the first graph attention layer </li>\n<li><span translate=no>_^_2_^_</span> is the number of classes </li>\n<li><span translate=no>_^_3_^_</span> is the number of heads in the graph attention layers </li>\n<li><span translate=no>_^_4_^_</span> is the dropout probability </li>\n<li><span translate=no>_^_5_^_</span> if set to True, the same matrix will be applied to the source and the target node of every edge</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u662f\u6bcf\u4e2a\u8282\u70b9\u7684\u8981\u7d20\u6570</li>\n<li><span translate=no>_^_1_^_</span>\u662f\u7b2c\u4e00\u4e2a\u56fe\u5f62\u5173\u6ce8\u5c42\u4e2d\u7684\u8981\u7d20\u6570</li>\n<li><span translate=no>_^_2_^_</span>\u662f\u7c7b\u7684\u6570\u91cf</li>\n<li><span translate=no>_^_3_^_</span>\u662f\u56fe\u8868\u5173\u6ce8\u5c42\u4e2d\u7684\u5934\u90e8\u6570\u91cf</li>\n<li><span translate=no>_^_4_^_</span>\u662f\u8f8d\u5b66\u6982\u7387</li>\n<li><span translate=no>_^_5_^_</span>\u5982\u679c\u8bbe\u7f6e\u4e3a True\uff0c\u5219\u540c\u4e00\u77e9\u9635\u5c06\u5e94\u7528\u4e8e\u6bcf\u6761\u8fb9\u7684\u6e90\u8282\u70b9\u548c\u76ee\u6807\u8282\u70b9</li></ul>\n",
 "This trains is a  Graph Attention Network v2 (GATv2) on Cora dataset": "\u8fd9\u5217\u706b\u8f66\u662f Cora \u6570\u636e\u96c6\u4e0a\u7684 Graph \u6ce8\u610f\u529b\u7f51\u7edc v2 (GATv2)",
 "Train a Graph Attention Network v2 (GATv2) on Cora dataset": "\u5728 Cora \u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u56fe\u5f62\u6ce8\u610f\u529b\u7f51\u7edc v2 (GATv2)"
}