{
 "<h1>Sketch RNN</h1>\n<p>This is an annotated <a href=\"https://pytorch.org\">PyTorch</a> implementation of the paper <a href=\"https://papers.labml.ai/paper/1704.03477\">A Neural Representation of Sketch Drawings</a>.</p>\n<p>Sketch RNN is a sequence-to-sequence variational auto-encoder. Both encoder and decoder are recurrent neural network models. It learns to reconstruct stroke based simple drawings, by predicting a series of strokes. Decoder predicts each stroke as a mixture of Gaussian&#x27;s.</p>\n<h3>Getting data</h3>\n<p>Download data from <a href=\"https://github.com/googlecreativelab/quickdraw-dataset\">Quick, Draw! Dataset</a>. There is a link to download <span translate=no>_^_0_^_</span> files in <em>Sketch-RNN QuickDraw Dataset</em> section of the readme. Place the downloaded <span translate=no>_^_1_^_</span> file(s) in <span translate=no>_^_2_^_</span> folder. This code is configured to use <span translate=no>_^_3_^_</span> dataset. You can change this in configurations.</p>\n<h3>Acknowledgements</h3>\n<p>Took help from <a href=\"https://github.com/alexis-jacq/Pytorch-Sketch-RNN\">PyTorch Sketch RNN</a> project by <a href=\"https://github.com/alexis-jacq\">Alexis David Jacq</a></p>\n": "<h1>\u7d20\u63cf RNN</h1>\n<p>\u8fd9\u662f\u8bba\u6587\u300a<a href=\"https://papers.labml.ai/paper/1704.03477\">\u7d20\u63cf\u7ed8\u753b\u7684\u795e\u7ecf\u8868\u793a</a>\u300b\u7684\u5e26\u6ce8\u91ca\u7684 <a href=\"https://pytorch.org\">PyTorch</a> \u5b9e\u73b0\u3002</p>\n<p>Sketch RNN \u662f\u4e00\u79cd\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u3002\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u90fd\u662f\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002\u5b83\u901a\u8fc7\u9884\u6d4b\u4e00\u7cfb\u5217\u7b14\u753b\u6765\u5b66\u4e60\u91cd\u5efa\u57fa\u4e8e\u7b14\u89e6\u7684\u7b80\u5355\u7ed8\u753b\u3002\u89e3\u7801\u5668\u5c06\u6bcf\u4e2a\u7b14\u5212\u9884\u6d4b\u4e3a\u9ad8\u65af\u7b14\u753b\u7684\u6df7\u5408\u3002</p>\n<h3>\u83b7\u53d6\u6570\u636e</h3>\n<p>\u4ece <a href=\"https://github.com/googlecreativelab/quickdraw-dataset\">Quick\uff0cDraw! \u4e0b\u8f7d\u6570\u636e\u6570\u636e\u96c6</a>\u3002\u81ea\u8ff0<span translate=no>_^_0_^_</span>\u6587\u4ef6\u7684 Sk <em>etch-RNN QuickDraw \u6570\u636e\u96c6</em>\u90e8\u5206\u6709\u4e00\u4e2a\u4e0b\u8f7d\u6587\u4ef6\u7684\u94fe\u63a5\u3002\u5c06\u4e0b\u8f7d\u7684<span translate=no>_^_1_^_</span>\u6587\u4ef6\u653e\u5728<span translate=no>_^_2_^_</span>\u6587\u4ef6\u5939\u4e2d\u3002\u6b64\u4ee3\u7801\u914d\u7f6e\u4e3a\u4f7f\u7528<span translate=no>_^_3_^_</span>\u6570\u636e\u96c6\u3002\u4f60\u53ef\u4ee5\u5728\u914d\u7f6e\u4e2d\u66f4\u6539\u6b64\u8bbe\u7f6e\u3002</p>\n<h3>\u81f4\u8c22</h3>\n<p>\u4ece A <a href=\"https://github.com/alexis-jacq\">lexis David Jacq</a> \u7684 <a href=\"https://github.com/alexis-jacq/Pytorch-Sketch-RNN\">PyTorch Sketch RNN</a> \u9879\u76ee</p>\n",
 "<h2>Bi-variate Gaussian mixture</h2>\n<p>The mixture is represented by <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span>. This class adjusts temperatures and creates the categorical and Gaussian distributions from the parameters.</p>\n": "<h2>\u53cc\u53d8\u91cf\u9ad8\u65af\u6df7\u5408</h2>\n<p>\u6df7\u5408\u7269\u7528<span translate=no>_^_0_^_</span>\u548c\u8868\u793a<span translate=no>_^_1_^_</span>\u3002\u6b64\u7c7b\u8c03\u6574\u6e29\u5ea6\uff0c\u5e76\u6839\u636e\u53c2\u6570\u521b\u5efa\u5206\u7c7b\u5206\u5e03\u548c\u9ad8\u65af\u5206\u5e03\u3002</p>\n",
 "<h2>Configurations</h2>\n<p>These are default configurations which can later be adjusted by passing a <span translate=no>_^_0_^_</span>.</p>\n": "<h2>\u914d\u7f6e</h2>\n<p>\u8fd9\u4e9b\u662f\u9ed8\u8ba4\u914d\u7f6e\uff0c\u7a0d\u540e\u53ef\u4ee5\u901a\u8fc7\u4f20\u5165 a \u8fdb\u884c\u8c03\u6574<span translate=no>_^_0_^_</span>\u3002</p>\n",
 "<h2>Dataset</h2>\n<p>This class loads and pre-processes the data.</p>\n": "<h2>\u6570\u636e\u96c6</h2>\n<p>\u6b64\u7c7b\u52a0\u8f7d\u548c\u9884\u5904\u7406\u6570\u636e\u3002</p>\n",
 "<h2>Decoder module</h2>\n<p>This consists of a LSTM</p>\n": "<h2>\u89e3\u7801\u5668\u6a21\u5757</h2>\n<p>\u5b83\u7531\u4e00\u4e2a LSTM \u7ec4\u6210</p>\n",
 "<h2>Encoder module</h2>\n<p>This consists of a bidirectional LSTM</p>\n": "<h2>\u7f16\u7801\u5668\u6a21\u5757</h2>\n<p>\u8fd9\u5305\u62ec\u4e00\u4e2a\u53cc\u5411 LSTM</p>\n",
 "<h2>KL-Divergence loss</h2>\n<p>This calculates the KL divergence between a given normal distribution and <span translate=no>_^_0_^_</span></p>\n": "<h2>KL-\u80cc\u79bb\u635f\u5931</h2>\n<p>\u8fd9\u5c06\u8ba1\u7b97\u7ed9\u5b9a\u6b63\u6001\u5206\u5e03\u4e0e<span translate=no>_^_0_^_</span></p>\n",
 "<h2>Reconstruction Loss</h2>\n": "<h2>\u91cd\u5efa\u635f\u5931</h2>\n",
 "<h2>Sampler</h2>\n<p>This samples a sketch from the decoder and plots it</p>\n": "<h2>\u91c7\u6837\u5668</h2>\n<p>\u8fd9\u5c06\u4ece\u89e3\u7801\u5668\u4e2d\u91c7\u6837\u8349\u56fe\u5e76\u7ed8\u5236\u51fa\u6765</p>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p> <span translate=no>_^_0_^_</span> is a list of numpy arrays of shape <a href=\"seq_len, 3\">seq_len, 3</a>. It is a sequence of strokes, and each stroke is represented by 3 integers. First two are the displacements along x and y (<span translate=no>_^_1_^_</span>, <span translate=no>_^_2_^_</span>) and the last integer represents the state of the pen, <span translate=no>_^_3_^_</span> if it&#x27;s touching the paper and <span translate=no>_^_4_^_</span> otherwise.</p>\n": "<p><span translate=no>_^_0_^_</span>\u662f\u5f62\u72b6\u4e3a <a href=\"seq_len, 3\">seq_len \u7684 numpy \u6570\u7ec4\u7684\u5217\u8868\uff0c3</a>\u3002\u5b83\u662f\u4e00\u4e2a\u7b14\u753b\u5e8f\u5217\uff0c\u6bcf\u4e2a\u7b14\u753b\u7531 3 \u4e2a\u6574\u6570\u8868\u793a\u3002\u524d\u4e24\u4e2a\u662f\u6cbf x \u548c y (<span translate=no>_^_1_^_</span>,<span translate=no>_^_2_^_</span>) \u7684\u4f4d\u79fb\uff0c\u6700\u540e\u4e00\u4e2a\u6574\u6570\u8868\u793a\u7b14\u7684\u72b6\u6001\uff0c<span translate=no>_^_3_^_</span>\u5982\u679c\u5b83\u63a5\u89e6\u7eb8\u5f20\u548c<span translate=no>_^_4_^_</span>\u5426\u5219\u3002</p>\n",
 "<p> Adjust by temperature <span translate=no>_^_0_^_</span></p>\n": "<p>\u6309\u6e29\u5ea6\u8c03\u6574<span translate=no>_^_0_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> Although <span translate=no>_^_1_^_</span> has <span translate=no>_^_2_^_</span> (<span translate=no>_^_3_^_</span>) elements, the sum is only taken upto <span translate=no>_^_4_^_</span> because the rest is masked out.</p>\n<p>It might feel like we should be taking the sum and dividing by <span translate=no>_^_5_^_</span> and not <span translate=no>_^_6_^_</span>, but this will give higher weight for individual predictions in shorter sequences. We give equal weight to each prediction <span translate=no>_^_7_^_</span> when we divide by <span translate=no>_^_8_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span>\u867d\u7136<span translate=no>_^_1_^_</span> has<span translate=no>_^_2_^_</span> (<span translate=no>_^_3_^_</span>) \u5143\u7d20\uff0c\u4f46\u603b\u548c\u53ea\u88ab\u5360\u7528\uff0c<span translate=no>_^_4_^_</span>\u56e0\u4e3a\u5176\u4f59\u7684\u90fd\u662f\u63a9\u76d6\u4e86\u3002</p>\n<p>\u53ef\u80fd\u611f\u89c9\u6211\u4eec\u5e94\u8be5\u53d6\u603b\u548c\u7136\u540e\u9664\u4ee5\u800c\u4e0d\u662f<span translate=no>_^_6_^_</span>\uff0c\u4f46\u8fd9\u5c06\u4e3a\u8f83\u77ed\u5e8f\u5217\u4e2d\u7684\u5355\u4e2a\u9884\u6d4b\u63d0\u4f9b\u66f4\u9ad8\u7684\u6743\u91cd\u3002<span translate=no>_^_5_^_</span>\u5f53\u6211\u4eec\u9664\u4ee5<span translate=no>_^_7_^_</span>\u65f6\uff0c\u6211\u4eec\u5bf9\u6bcf\u4e2a\u9884\u6d4b\u8d4b\u4e88\u76f8\u7b49\u7684\u6743\u91cd<span translate=no>_^_8_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> have shapes <span translate=no>_^_2_^_</span>. We want to shape them to <span translate=no>_^_3_^_</span> because that&#x27;s the shape used in LSTM. </p>\n": "<p><span translate=no>_^_0_^_</span>\u5e76<span translate=no>_^_1_^_</span>\u6709\u5f62\u72b6<span translate=no>_^_2_^_</span>\u3002\u6211\u4eec\u60f3\u8981\u5c06\u5b83\u4eec\u5851\u9020\u6210\u5f62\u72b6\uff0c<span translate=no>_^_3_^_</span>\u56e0\u4e3a\u8fd9\u5c31\u662f LSTM \u4e2d\u4f7f\u7528\u7684\u5f62\u72b6\u3002</p>\n",
 "<p><span translate=no>_^_0_^_</span> file path is <span translate=no>_^_1_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span>\u6587\u4ef6\u8def\u5f84\u662f<span translate=no>_^_1_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> has shape <span translate=no>_^_1_^_</span> where the last dimension is the features <span translate=no>_^_2_^_</span>. We want to get <span translate=no>_^_3_^_</span> y and get the probabilities from each of the distributions in the mixture <span translate=no>_^_4_^_</span>.</p>\n<p><span translate=no>_^_5_^_</span> will have shape <span translate=no>_^_6_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span>\u5177\u6709\u5f62\u72b6\uff0c<span translate=no>_^_1_^_</span>\u5176\u4e2d\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u662f\u8981\u7d20<span translate=no>_^_2_^_</span>\u3002\u6211\u4eec\u60f3\u8981\u5f97\u5230<span translate=no>_^_3_^_</span> y \u5e76\u4ece\u6df7\u5408\u4e2d\u7684\u6bcf\u4e2a\u5206\u5e03\u4e2d\u83b7\u5f97\u6982\u7387<span translate=no>_^_4_^_</span>\u3002</p>\n<p><span translate=no>_^_5_^_</span>\u4f1a\u6709\u5f62\u72b6<span translate=no>_^_6_^_</span></p>\n",
 "<p><span translate=no>_^_0_^_</span> is the input to the decoder </p>\n": "<p><span translate=no>_^_0_^_</span>\u662f\u89e3\u7801\u5668\u7684\u8f93\u5165</p>\n",
 "<p>Add batch dimension and move it to device </p>\n": "<p>\u6dfb\u52a0\u6279\u91cf\u7ef4\u5ea6\u5e76\u5c06\u5176\u79fb\u81f3\u8bbe\u5907</p>\n",
 "<p>Add hooks to monitor layer outputs on Tensorboard </p>\n": "<p>\u6dfb\u52a0\u6302\u94a9\u4ee5\u76d1\u63a7 Tensorboard \u4e0a\u7684\u56fe\u5c42\u8f93\u51fa</p>\n",
 "<p>Add the new stroke to the sequence of strokes </p>\n": "<p>\u5c06\u65b0\u7b14\u5212\u6dfb\u52a0\u5230\u7b14\u753b\u5e8f\u5217\u4e2d</p>\n",
 "<p>Batch size </p>\n": "<p>\u6279\u91cf\u5927\u5c0f</p>\n",
 "<p>Calculate the initial state </p>\n": "<p>\u8ba1\u7b97\u521d\u59cb\u72b6\u6001</p>\n",
 "<p>Calculate the probabilities <span translate=no>_^_0_^_</span> </p>\n": "<p>\u8ba1\u7b97\u6982\u7387<span translate=no>_^_0_^_</span></p>\n",
 "<p>Clamp <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span> and <span translate=no>_^_2_^_</span> to avoid getting <span translate=no>_^_3_^_</span>s </p>\n": "<p>Clamp<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\uff0c<span translate=no>_^_2_^_</span>\u4e3a\u4e86\u907f\u514d\u5f97\u5230<span translate=no>_^_3_^_</span> s</p>\n",
 "<p>Clamp <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span> to <span translate=no>_^_2_^_</span> </p>\n": "<p>Clamp<span translate=no>_^_0_^_</span>\uff0c<span translate=no>_^_1_^_</span>\u5230<span translate=no>_^_2_^_</span></p>\n",
 "<p>Clip gradients </p>\n": "<p>\u526a\u8f91\u6e10\u53d8</p>\n",
 "<p>Compute gradients </p>\n": "<p>\u8ba1\u7b97\u68af\u5ea6</p>\n",
 "<p>Compute the loss </p>\n": "<p>\u8ba1\u7b97\u635f\u5931</p>\n",
 "<p>Concatenate <span translate=no>_^_0_^_</span> </p>\n": "<p>\u4e32\u8054<span translate=no>_^_0_^_</span></p>\n",
 "<p>Configure the tracker to print the total train/validation loss </p>\n": "<p>\u914d\u7f6e\u8ddf\u8e2a\u5668\u4ee5\u6253\u5370\u603b\u8bad\u7ec3/\u9a8c\u8bc1\u635f\u5931</p>\n",
 "<p>Convert to a floating point array and add to <span translate=no>_^_0_^_</span> </p>\n": "<p>\u8f6c\u6362\u4e3a\u6d6e\u70b9\u6570\u7ec4\u5e76\u6dfb\u52a0\u5230<span translate=no>_^_0_^_</span></p>\n",
 "<p>Create a PyTorch tensor of the sequence of strokes </p>\n": "<p>\u521b\u5efa\u7b14\u753b\u5e8f\u5217\u7684 PyTorch \u5f20\u91cf</p>\n",
 "<p>Create a bi-variate Gaussian mixture <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> where <span translate=no>_^_2_^_</span> and <span translate=no>_^_3_^_</span></p>\n<p><span translate=no>_^_4_^_</span> is the categorical probabilities of choosing the distribution out of the mixture <span translate=no>_^_5_^_</span>. </p>\n": "<p>\u521b\u5efa\u53cc\u53d8\u91cf\u9ad8\u65af\u6df7\u5408<span translate=no>_^_0_^_</span>\uff0c<span translate=no>_^_1_^_</span>\u5728\u54ea\u91cc<span translate=no>_^_2_^_</span>\u548c<span translate=no>_^_3_^_</span></p>\n<p><span translate=no>_^_4_^_</span>\u662f\u4ece\u6df7\u5408\u7269\u4e2d\u9009\u62e9\u5206\u5e03\u7684\u7edd\u5bf9\u6982\u7387<span translate=no>_^_5_^_</span>\u3002</p>\n",
 "<p>Create a bidirectional LSTM taking a sequence of <span translate=no>_^_0_^_</span> as input. </p>\n": "<p>\u521b\u5efa\u53cc\u5411 LSTM\uff0c\u5c06\u5e8f\u5217<span translate=no>_^_0_^_</span>\u4f5c\u4e3a\u8f93\u5165\u3002</p>\n",
 "<p>Create a new numpy array of the form <span translate=no>_^_0_^_</span> </p>\n": "<p>\u521b\u5efa\u4e00\u4e2a\u683c\u5f0f\u4e3a numpy \u7684\u65b0 numpy \u6570\u7ec4<span translate=no>_^_0_^_</span></p>\n",
 "<p>Create an empty stroke <span translate=no>_^_0_^_</span> </p>\n": "<p>\u521b\u5efa\u7a7a\u63cf\u8fb9<span translate=no>_^_0_^_</span></p>\n",
 "<p>Create bi-variate normal distribution.</p>\n<p>\ud83d\udcdd It would be efficient to <span translate=no>_^_0_^_</span> matrix as <span translate=no>_^_1_^_</span> where <span translate=no>_^_2_^_</span>. But for simplicity we use co-variance matrix. <a href=\"https://www2.stat.duke.edu/courses/Spring12/sta104.1/Lectures/Lec22.pdf\">This is a good resource</a> if you want to read up more about bi-variate distributions, their co-variance matrix, and probability density function. </p>\n": "<p>\u521b\u5efa\u53cc\u53d8\u91cf\u6b63\u6001\u5206\u5e03\u3002</p>\n<p>\ud83d\udcdd \u5c06<span translate=no>_^_0_^_</span>\u77e9\u9635\u4f5c\u4e3a<span translate=no>_^_1_^_</span>\u4f55\u5904\u8fdb\u884c\u77e9\u9635\u4f1a\u5f88\u6709\u6548<span translate=no>_^_2_^_</span>\u3002\u4f46\u4e3a\u4e86\u7b80\u5355\u8d77\u89c1\uff0c\u6211\u4eec\u4f7f\u7528\u534f\u65b9\u5dee\u77e9\u9635\u3002\u5982\u679c\u4f60\u60f3\u9605\u8bfb\u66f4\u591a\u5173\u4e8e\u53cc\u53d8\u91cf\u5206\u5e03\u3001\u5b83\u4eec\u7684\u534f\u65b9\u5dee\u77e9\u9635\u548c\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u7684\u4fe1\u606f\uff0c<a href=\"https://www2.stat.duke.edu/courses/Spring12/sta104.1/Lectures/Lec22.pdf\">\u8fd9\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u8d44\u6e90</a>\u3002</p>\n",
 "<p>Create categorical distribution <span translate=no>_^_0_^_</span> from logits </p>\n": "<p>\u6839\u636e\u5bf9\u6570\u521b\u5efa\u5206\u7c7b<span translate=no>_^_0_^_</span>\u5206\u5e03</p>\n",
 "<p>Create categorical distribution <span translate=no>_^_0_^_</span> with log-probabilities <span translate=no>_^_1_^_</span> or <span translate=no>_^_2_^_</span> </p>\n": "<p>\u4f7f\u7528\u5bf9\u6570\u6982\u7387\u521b\u5efa\u7c7b\u522b\u5206\u5e03<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u6216<span translate=no>_^_2_^_</span></p>\n",
 "<p>Create sampler </p>\n": "<p>\u521b\u5efa\u91c7\u6837\u5668</p>\n",
 "<p>Create training data loader </p>\n": "<p>\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u52a0\u8f7d\u5668</p>\n",
 "<p>Create training dataset </p>\n": "<p>\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u96c6</p>\n",
 "<p>Create validation data loader </p>\n": "<p>\u521b\u5efa\u9a8c\u8bc1\u6570\u636e\u52a0\u8f7d\u5668</p>\n",
 "<p>Create validation dataset </p>\n": "<p>\u521b\u5efa\u9a8c\u8bc1\u6570\u636e\u96c6</p>\n",
 "<p>Decode the mixture of distributions and <span translate=no>_^_0_^_</span> </p>\n": "<p>\u89e3\u7801\u5206\u5e03\u548c\u5206\u5e03\u7684\u6df7\u5408<span translate=no>_^_0_^_</span></p>\n",
 "<p>Device configurations to pick the device to run the experiment </p>\n": "<p>\u7528\u4e8e\u9009\u62e9\u8981\u8fd0\u884c\u5b9e\u9a8c\u7684\u8bbe\u5907\u7684\u8bbe\u5907\u914d\u7f6e</p>\n",
 "<p>Don&#x27;t show axes </p>\n": "<p>\u4e0d\u8981\u663e\u793a\u8f74</p>\n",
 "<p>Encode the sequence of strokes </p>\n": "<p>\u5bf9\u7b14\u753b\u5e8f\u5217\u8fdb\u884c\u7f16\u7801</p>\n",
 "<p>Encoder and decoder sizes </p>\n": "<p>\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5c3a\u5bf8</p>\n",
 "<p>Filter if the length of the sequence of strokes is within our range </p>\n": "<p>\u7b5b\u9009\u7b14\u753b\u5e8f\u5217\u7684\u957f\u5ea6\u662f\u5426\u5728\u6211\u4eec\u7684\u8303\u56f4\u5185</p>\n",
 "<p>Filter out stroke sequences longer than <span translate=no>_^_0_^_</span> </p>\n": "<p>\u7b5b\u9009\u51fa\u957f\u5ea6\u5927\u4e8e<span translate=no>_^_0_^_</span></p>\n",
 "<p>Get <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5f97\u5230<span translate=no>_^_0_^_</span></p>\n",
 "<p>Get <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> </p>\n": "<p>\u83b7\u53d6<span translate=no>_^_0_^_</span>\u548c<span translate=no>_^_1_^_</span></p>\n",
 "<p>Get <span translate=no>_^_0_^_</span> from the encoder </p>\n": "<p><span translate=no>_^_0_^_</span>\u4ece\u7f16\u7801\u5668\u83b7\u53d6</p>\n",
 "<p>Get <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>, <span translate=no>_^_2_^_</span> and the next state from the decoder </p>\n": "<p>\u4ece\u89e3\u7801\u5668\u83b7\u53d6<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u3001<span translate=no>_^_2_^_</span>\u548c\u4e0b\u4e00\u4e2a\u72b6\u6001</p>\n",
 "<p>Get <span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>, and <span translate=no>_^_2_^_</span> </p>\n": "<p>\u83b7\u53d6<span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u3001\u548c<span translate=no>_^_2_^_</span></p>\n",
 "<p>Get <span translate=no>_^_0_^_</span>. <span translate=no>_^_1_^_</span> splits the output into 6 tensors of size <span translate=no>_^_2_^_</span> across dimension <span translate=no>_^_3_^_</span>. </p>\n": "<p>\u5f97\u5230<span translate=no>_^_0_^_</span>\u3002<span translate=no>_^_1_^_</span>\u5c06\u8f93\u51fa\u62c6\u5206\u4e3a<span translate=no>_^_2_^_</span>\u8de8\u7ef4\u5ea6\u5927\u5c0f\u7684 6 \u4e2a\u5f20\u91cf<span translate=no>_^_3_^_</span>\u3002</p>\n",
 "<p>Get a sample </p>\n": "<p>\u83b7\u53d6\u6837\u54c1</p>\n",
 "<p>Get covariance matrix </p>\n": "<p>\u83b7\u53d6\u534f\u65b9\u5dee\u77e9\u9635</p>\n",
 "<p>Get means </p>\n": "<p>\u83b7\u53d6\u624b\u6bb5</p>\n",
 "<p>Get mixture of distributions and <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6df7\u5408\u5206\u5e03\u548c<span translate=no>_^_0_^_</span></p>\n",
 "<p>Get temperature adjusted <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> </p>\n": "<p>\u8c03\u6574\u6e29\u5ea6<span translate=no>_^_0_^_</span>\u548c<span translate=no>_^_1_^_</span></p>\n",
 "<p>Get the longest sequence length among all sequences </p>\n": "<p>\u83b7\u53d6\u6240\u6709\u5e8f\u5217\u4e2d\u6700\u957f\u7684\u5e8f\u5217\u957f\u5ea6</p>\n",
 "<p>Gradient clipping </p>\n": "<p>\u6e10\u53d8\u526a\u5207</p>\n",
 "<p>Head to get <span translate=no>_^_0_^_</span> </p>\n": "<p>\u53bb\u5f97\u5230<span translate=no>_^_0_^_</span></p>\n",
 "<p>Increment step in training mode </p>\n": "<p>\u5728\u8bad\u7ec3\u6a21\u5f0f\u4e2d\u589e\u52a0\u6b65\u6570</p>\n",
 "<p>Initial decoder is <span translate=no>_^_0_^_</span>. The decoder will initialize it to <span translate=no>_^_1_^_</span> </p>\n": "<p>\u521d\u59cb\u89e3\u7801\u5668\u662f<span translate=no>_^_0_^_</span>\u3002\u89e3\u7801\u5668\u4f1a\u5c06\u5176\u521d\u59cb\u5316\u4e3a<span translate=no>_^_1_^_</span></p>\n",
 "<p>Initial state of the LSTM is <span translate=no>_^_0_^_</span>. <span translate=no>_^_1_^_</span> is the linear transformation for this </p>\n": "<p>LSTM \u7684\u521d\u59cb\u72b6\u6001\u4e3a<span translate=no>_^_0_^_</span>\u3002<span translate=no>_^_1_^_</span>\u662f\u8fd9\u4e2a\u7684\u7ebf\u6027\u53d8\u6362</p>\n",
 "<p>Initialize encoder &amp; decoder </p>\n": "<p>\u521d\u59cb\u5316\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668</p>\n",
 "<p>LSTM takes <span translate=no>_^_0_^_</span> as input </p>\n": "<p>LSTM \u5c06<span translate=no>_^_0_^_</span>\u4f5c\u4e3a\u8f93\u5165</p>\n",
 "<p>Load the numpy file </p>\n": "<p>\u52a0\u8f7d\u90a3\u4e2a numpy \u6587\u4ef6</p>\n",
 "<p>Log model parameters and gradients </p>\n": "<p>\u8bb0\u5f55\u6a21\u578b\u53c2\u6570\u548c\u68af\u5ea6</p>\n",
 "<p>Mask is on until end of sequence </p>\n": "<p>\u906e\u7f69\u5f00\u542f\u76f4\u5230\u5e8f\u5217\u7ed3\u675f</p>\n",
 "<p>Move <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> to device and swap the sequence and batch dimensions. <span translate=no>_^_2_^_</span> will have shape <span translate=no>_^_3_^_</span> and <span translate=no>_^_4_^_</span> will have shape <span translate=no>_^_5_^_</span>. </p>\n": "<p>\u5c06<span translate=no>_^_0_^_</span>\u548c\u79fb<span translate=no>_^_1_^_</span>\u81f3\u8bbe\u5907\u5e76\u4ea4\u6362\u5e8f\u5217\u548c\u6279\u6b21\u7ef4\u5ea6\u3002<span translate=no>_^_2_^_</span>\u5c06\u6709\u5f62\u72b6<span translate=no>_^_3_^_</span>\u548c<span translate=no>_^_4_^_</span>\u5f62\u72b6<span translate=no>_^_5_^_</span>\u3002</p>\n",
 "<p>Name of the dataset </p>\n": "<p>\u6570\u636e\u96c6\u7684\u540d\u79f0</p>\n",
 "<p>Number of distributions in the mixture, <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6df7\u5408\u7269\u4e2d\u7684\u5206\u5e03\u6570\uff0c<span translate=no>_^_0_^_</span></p>\n",
 "<p>Number of features in <span translate=no>_^_0_^_</span> </p>\n": "<p>\u4e2d\u7684\u8981\u7d20\u6570\u91cf<span translate=no>_^_0_^_</span></p>\n",
 "<p>Number of inner iterations within an epoch to switch between training, validation and sampling. </p>\n": "<p>\u4e00\u4e2a\u7eaa\u5143\u5185\u8981\u5728\u8bad\u7ec3\u3001\u9a8c\u8bc1\u548c\u91c7\u6837\u4e4b\u95f4\u5207\u6362\u7684\u5185\u90e8\u8fed\u4ee3\u6b21\u6570\u3002</p>\n",
 "<p>Only if we are in training state </p>\n": "<p>\u53ea\u6709\u5f53\u6211\u4eec\u5904\u4e8e\u8bad\u7ec3\u72b6\u6001\u65f6</p>\n",
 "<p>Optimize </p>\n": "<p>\u4f18\u5316</p>\n",
 "<p>Pass a dictionary of configurations </p>\n": "<p>\u4f20\u9012\u914d\u7f6e\u5b57\u5178</p>\n",
 "<p>Plot each sequence of strokes </p>\n": "<p>\u7ed8\u5236\u6bcf\u4e2a\u7b14\u753b\u5e8f\u5217</p>\n",
 "<p>Plot the sequence of strokes </p>\n": "<p>\u7ed8\u5236\u7b14\u753b\u987a\u5e8f</p>\n",
 "<p>Randomly pick a sample from validation dataset to encoder </p>\n": "<p>\u4ece\u9a8c\u8bc1\u6570\u636e\u96c6\u4e2d\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u6837\u672c\u5230\u7f16\u7801\u5668</p>\n",
 "<p>Run optimizer </p>\n": "<p>\u8fd0\u884c\u4f18\u5316\u5668</p>\n",
 "<p>Run the LSTM </p>\n": "<p>\u8fd0\u884c LSTM</p>\n",
 "<p>Run the experiment </p>\n": "<p>\u8fd0\u884c\u5b9e\u9a8c</p>\n",
 "<p>Sample </p>\n": "<p>\u6837\u672c</p>\n",
 "<p>Sample <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6837\u672c<span translate=no>_^_0_^_</span></p>\n",
 "<p>Sample <span translate=no>_^_0_^_</span> strokes </p>\n": "<p><span translate=no>_^_0_^_</span>\u7b14\u753b\u6837\u672c</p>\n",
 "<p>Sample a stroke </p>\n": "<p>\u5bf9\u7b14\u753b\u8fdb\u884c\u91c7\u6837</p>\n",
 "<p>Sample from <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6837\u672c\u6765\u81ea<span translate=no>_^_0_^_</span></p>\n",
 "<p>Sample from <span translate=no>_^_0_^_</span> the index of the distribution to use from the mixture </p>\n": "<p>\u4ece\u6df7\u5408\u7269<span translate=no>_^_0_^_</span>\u4e2d\u4f7f\u7528\u7684\u5206\u5e03\u6307\u6570\u4e2d\u7684\u6837\u54c1</p>\n",
 "<p>Sample from the normal distributions in the mixture and pick the one indexed by <span translate=no>_^_0_^_</span> </p>\n": "<p>\u4ece\u6df7\u5408\u7269\u4e2d\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u53d6\u6837\uff0c\u7136\u540e\u9009\u53d6\u7d22\u5f15\u7684\u6b63\u6001\u5206\u5e03<span translate=no>_^_0_^_</span></p>\n",
 "<p>Scale and set <span translate=no>_^_0_^_</span> </p>\n": "<p>\u7f29\u653e\u548c\u8bbe\u7f6e<span translate=no>_^_0_^_</span></p>\n",
 "<p>Set <span translate=no>_^_0_^_</span> </p>\n": "<p>\u8bbe\u7f6e<span translate=no>_^_0_^_</span></p>\n",
 "<p>Set <span translate=no>_^_0_^_</span> to zero </p>\n": "<p>\u8bbe<span translate=no>_^_0_^_</span>\u4e3a\u96f6</p>\n",
 "<p>Set optimizer. Things like type of optimizer and learning rate are configurable </p>\n": "<p>\u8bbe\u7f6e\u4f18\u5316\u5668\u3002\u4f18\u5316\u5668\u7c7b\u578b\u548c\u5b66\u4e60\u7387\u7b49\u5185\u5bb9\u662f\u53ef\u914d\u7f6e\u7684</p>\n",
 "<p>Set temperature <span translate=no>_^_0_^_</span> for sampling. This is implemented in class <span translate=no>_^_1_^_</span>. </p>\n": "<p>\u8bbe\u5b9a\u91c7\u6837\u6e29\u5ea6<span translate=no>_^_0_^_</span>\u3002\u8fd9\u662f\u5728\u8bfe\u5802\u4e0a\u5b9e\u73b0\u7684<span translate=no>_^_1_^_</span>\u3002</p>\n",
 "<p>Show the plot </p>\n": "<p>\u663e\u793a\u5267\u60c5</p>\n",
 "<p>Size of the dataset </p>\n": "<p>\u6570\u636e\u96c6\u7684\u5927\u5c0f</p>\n",
 "<p>Split the array at points where <span translate=no>_^_0_^_</span> is <span translate=no>_^_1_^_</span>. i.e. split the array of strokes at the points where the pen is lifted from the paper. This gives a list of sequence of strokes. </p>\n": "<p>\u5c06\u6570\u7ec4\u62c6\u5206\u4e3a where<span translate=no>_^_0_^_</span> is<span translate=no>_^_1_^_</span>\u3002\u5373\u5728\u7b14\u4ece\u7eb8\u5f20\u4e0a\u62ac\u8d77\u7684\u70b9\u5206\u5272\u7b14\u5212\u6570\u7ec4\u3002\u8fd9\u7ed9\u51fa\u4e86\u7b14\u753b\u5e8f\u5217\u7684\u5217\u8868\u3002</p>\n",
 "<p>Start-of-sequence is <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5e8f\u5217\u5f00\u5934\u662f<span translate=no>_^_0_^_</span></p>\n",
 "<p>Start-of-sequence stroke is <span translate=no>_^_0_^_</span> </p>\n": "<p>\u5e8f\u5217\u8d77\u59cb\u884c\u7a0b\u4e3a<span translate=no>_^_0_^_</span></p>\n",
 "<p>Stop sampling if <span translate=no>_^_0_^_</span>. This indicates that sketching has stopped </p>\n": "<p>\u5982\u679c\u505c\u6b62\u91c7\u6837<span translate=no>_^_0_^_</span>\u3002\u8fd9\u8868\u793a\u8349\u7ed8\u5df2\u505c\u6b62</p>\n",
 "<p>Take the cumulative sums of <span translate=no>_^_0_^_</span> to get <span translate=no>_^_1_^_</span> </p>\n": "<p>\u53d6\u7684\u7d2f\u8ba1\u603b\u548c\u5f97<span translate=no>_^_0_^_</span>\u5230<span translate=no>_^_1_^_</span></p>\n",
 "<p>Temperature <span translate=no>_^_0_^_</span> for sampling </p>\n": "<p>\u91c7\u6837\u6e29\u5ea6<span translate=no>_^_0_^_</span></p>\n",
 "<p>The hidden state of the bidirectional LSTM is the concatenation of the output of the last token in the forward direction and first token in the reverse direction, which is what we want. <span translate=no>_^_0_^_</span> </p>\n": "<p>\u53cc\u5411LSTM\u7684\u9690\u85cf\u72b6\u6001\u662f\u5411\u524d\u65b9\u5411\u7684\u6700\u540e\u4e00\u4e2a\u4ee4\u724c\u7684\u8f93\u51fa\u548c\u76f8\u53cd\u65b9\u5411\u7684\u7b2c\u4e00\u4e2a\u4ee4\u724c\u7684\u8f93\u51fa\u4e32\u8054\uff0c\u8fd9\u6b63\u662f\u6211\u4eec\u60f3\u8981\u7684\u3002<span translate=no>_^_0_^_</span></p>\n",
 "<p>The mask array needs only one extra-step since it is for the outputs of the decoder, which takes in <span translate=no>_^_0_^_</span> and predicts next step. </p>\n": "<p>\u63a9\u7801\u6570\u7ec4\u53ea\u9700\u8981\u4e00\u4e2a\u989d\u5916\u7684\u6b65\u9aa4\uff0c\u56e0\u4e3a\u5b83\u662f\u7528\u4e8e\u89e3\u7801\u5668\u7684\u8f93\u51fa\uff0c\u89e3\u7801\u5668\u63a5\u6536<span translate=no>_^_0_^_</span>\u5e76\u9884\u6d4b\u4e0b\u4e00\u6b65\u3002</p>\n",
 "<p>The state has shape <span translate=no>_^_0_^_</span>, where the first dimension is the direction. We rearrange it to get <span translate=no>_^_1_^_</span> </p>\n": "<p>\u72b6\u6001\u5177\u6709\u5f62\u72b6<span translate=no>_^_0_^_</span>\uff0c\u5176\u4e2d\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u662f\u65b9\u5411\u3002\u6211\u4eec\u91cd\u65b0\u6392\u5217\u5b83\u6765\u83b7\u5f97<span translate=no>_^_1_^_</span></p>\n",
 "<p>These parameters are stored for future reference </p>\n": "<p>\u8fd9\u4e9b\u53c2\u6570\u5b58\u50a8\u8d77\u6765\u4ee5\u5907\u5c06\u6765\u53c2\u8003</p>\n",
 "<p>This head is for the logits <span translate=no>_^_0_^_</span> </p>\n": "<p>\u8fd9\u4e2a\u5934\u662f\u4e3a logits \u51c6\u5907\u7684<span translate=no>_^_0_^_</span></p>\n",
 "<p>This is to calculate <span translate=no>_^_0_^_</span> where <span translate=no>_^_1_^_</span> </p>\n": "<p>\u8fd9\u662f\u4e3a\u4e86\u8ba1\u7b97<span translate=no>_^_0_^_</span>\u5728\u54ea\u91cc<span translate=no>_^_1_^_</span></p>\n",
 "<p>This layer produces outputs for each of the <span translate=no>_^_0_^_</span>. Each distribution needs six parameters <span translate=no>_^_1_^_</span> </p>\n": "<p>\u8be5\u5c42\u4e3a\u6bcf\u4e2a\u751f\u6210\u8f93\u51fa<span translate=no>_^_0_^_</span>\u3002\u6bcf\u4e2a\u5206\u5e03\u9700\u8981\u516d\u4e2a\u53c2\u6570<span translate=no>_^_1_^_</span></p>\n",
 "<p>Track losses </p>\n": "<p>\u8ffd\u8e2a\u635f\u5931</p>\n",
 "<p>We don&#x27;t need gradients </p>\n": "<p>\u6211\u4eec\u4e0d\u9700\u8981\u6e10\u53d8</p>\n",
 "<p>We initialize PyTorch data array with two extra steps for start-of-sequence (sos) and end-of-sequence (eos). Each step is a vector <span translate=no>_^_0_^_</span>. Only one of <span translate=no>_^_1_^_</span> is <span translate=no>_^_2_^_</span> and the others are <span translate=no>_^_3_^_</span>. They represent <em>pen down</em>, <em>pen up</em> and <em>end-of-sequence</em> in that order. <span translate=no>_^_4_^_</span> is <span translate=no>_^_5_^_</span> if the pen touches the paper in the next step. <span translate=no>_^_6_^_</span> is <span translate=no>_^_7_^_</span> if the pen doesn&#x27;t touch the paper in the next step. <span translate=no>_^_8_^_</span> is <span translate=no>_^_9_^_</span> if it is the end of the drawing. </p>\n": "<p>\u6211\u4eec\u5728\u521d\u59cb\u5316 PyTorch \u6570\u636e\u6570\u7ec4\u65f6\u6dfb\u52a0\u4e86\u4e24\u4e2a\u989d\u5916\u7684\u6b65\u9aa4\uff0c\u5206\u522b\u662f\u5e8f\u5217\u5f00\u59cb (sos) \u548c\u5e8f\u5217\u7ed3\u675f (eos)\u3002\u6bcf\u4e00\u6b65\u90fd\u662f\u4e00\u4e2a\u5411\u91cf<span translate=no>_^_0_^_</span>\u3002\u53ea\u6709\u4e00\u4e2a<span translate=no>_^_1_^_</span>\u662f<span translate=no>_^_2_^_</span>\uff0c\u5176\u4ed6\u7684\u662f<span translate=no>_^_3_^_</span>\u3002\u5b83\u4eec\u6309\u8be5\u987a\u5e8f\u8868\u793a<em>\u7b14\u5411\u4e0b\u3001\u5411</em><em>\u4e0a</em>\u548c<em>\u5e8f\u5217\u7ed3\u5c3e</em>\u3002<span translate=no>_^_4_^_</span>\u662f<span translate=no>_^_5_^_</span>\u5982\u679c\u7b14\u5728\u4e0b\u4e00\u6b65\u4e2d\u78b0\u5230\u7eb8\u5f20\u3002<span translate=no>_^_6_^_</span><span translate=no>_^_7_^_</span>\u5982\u679c\u5728\u4e0b\u4e00\u6b65\u4e2d\u7b14\u6ca1\u6709\u78b0\u5230\u7eb8\u5f20\u3002<span translate=no>_^_8_^_</span><span translate=no>_^_9_^_</span>\u5982\u679c\u662f\u7ed8\u56fe\u7684\u7ed3\u5c3e\u3002</p>\n",
 "<p>We iterate through each of the sequences and filter </p>\n": "<p>\u6211\u4eec\u904d\u5386\u6bcf\u4e2a\u5e8f\u5217\u5e76\u8fdb\u884c\u8fc7\u6ee4</p>\n",
 "<p>We then calculate the scaling factor which is the standard deviation of (<span translate=no>_^_0_^_</span>, <span translate=no>_^_1_^_</span>) combined. Paper notes that the mean is not adjusted for simplicity, since the mean is anyway close to <span translate=no>_^_2_^_</span>. </p>\n": "<p>\u7136\u540e\uff0c\u6211\u4eec\u8ba1\u7b97\u7f29\u653e\u7cfb\u6570\uff0c\u5373 (<span translate=no>_^_0_^_</span>,<span translate=no>_^_1_^_</span>) \u7ec4\u5408\u7684\u6807\u51c6\u5dee\u3002\u8bba\u6587\u6307\u51fa\uff0c\u4e3a\u4e86\u7b80\u5355\u8d77\u89c1\uff0c\u5747\u503c\u6ca1\u6709\u8fdb\u884c\u8c03\u6574\uff0c\u56e0\u4e3a\u5747\u503c\u65e0\u8bba\u5982\u4f55\u90fd\u63a5\u8fd1<span translate=no>_^_2_^_</span>\u3002</p>\n",
 "<p>We use a learning rate of <span translate=no>_^_0_^_</span> because we can see results faster. Paper had suggested <span translate=no>_^_1_^_</span>. </p>\n": "<p>\u6211\u4eec\u4f7f\u7528\u5b66\u4e60\u901f\u7387<span translate=no>_^_0_^_</span>\u662f\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u66f4\u5feb\u5730\u770b\u5230\u7ed3\u679c\u3002Paper \u66fe\u6697\u793a\u8fc7<span translate=no>_^_1_^_</span>\u3002</p>\n",
 "<p>Weight of KL divergence loss, <span translate=no>_^_0_^_</span> </p>\n": "<p>KL \u80cc\u79bb\u635f\u5931\u7684\u6743\u91cd\uff0c<span translate=no>_^_0_^_</span></p>\n",
 "Sketch RNN": "\u7d20\u63cf RNN",
 "This is an annotated PyTorch implementation of the Sketch RNN from paper A Neural Representation of Sketch Drawings. Sketch RNN is a sequence-to-sequence model that generates sketches of objects such as bicycles, cats, etc.": "\u8fd9\u662f\u8bba\u6587\u300a\u7d20\u63cf\u7ed8\u753b\u7684\u795e\u7ecf\u8868\u793a\u300b\u4e2d\u5e26\u6ce8\u91ca\u7684 PyTorch \u5b9e\u73b0 Sketch RNN\u3002Sketch RNN \u662f\u4e00\u79cd\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\uff0c\u53ef\u751f\u6210\u81ea\u884c\u8f66\u3001\u732b\u7b49\u7269\u4f53\u7684\u8349\u56fe\u3002"
}