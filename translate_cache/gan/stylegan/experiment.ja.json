{
 "<h1><a href=\"index.html\">StyleGAN 2</a> Model Training</h1>\n<p>This is the training code for <a href=\"index.html\">StyleGAN 2</a> model.</p>\n<p><span translate=no>_^_0_^_</span></p>\n<p><small><em>These are <span translate=no>_^_1_^_</span> images generated after training for about 80K steps.</em></small></p>\n<p><em>Our implementation is a minimalistic StyleGAN 2 model training code. Only single GPU training is supported to keep the implementation simple. We managed to shrink it to keep it at less than 500 lines of code, including the training loop.</em></p>\n<p><em>Without DDP (distributed data parallel) and multi-gpu training it will not be possible to train the model for large resolutions (128+). If you want training code with fp16 and DDP take a look at <a href=\"https://github.com/lucidrains/stylegan2-pytorch\">lucidrains/stylegan2-pytorch</a>.</em></p>\n<p>We trained this on <a href=\"https://github.com/tkarras/progressive_growing_of_gans\">CelebA-HQ dataset</a>. You can find the download instruction in this <a href=\"https://forums.fast.ai/t/download-celeba-hq-dataset/45873/3\">discussion on fast.ai</a>. Save the images inside <a href=\"#dataset_path\"><span translate=no>_^_2_^_</span> folder</a>.</p>\n": "<h1><a href=\"index.html\">\u30b9\u30bf\u30a4\u30eb\u30ac\u30f3 2 \u30e2\u30c7\u30eb\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0</a></h1>\n<p><a href=\"index.html\">\u3053\u308c\u306fStyleGAN 2\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b3\u30fc\u30c9\u3067\u3059</a>\u3002</p>\n<p><span translate=no>_^_0_^_</span></p>\n<p><small><em>\u3053\u308c\u3089\u306f\u3001\u7d04 80K <span translate=no>_^_1_^_</span> \u30b9\u30c6\u30c3\u30d7\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u5f8c\u306b\u751f\u6210\u3055\u308c\u305f\u753b\u50cf\u3067\u3059\u3002</em></small></p>\n<p><em>\u79c1\u305f\u3061\u306e\u5b9f\u88c5\u306f\u3001\u6700\u5c0f\u9650\u306eStyleGAN 2\u30e2\u30c7\u30eb\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b3\u30fc\u30c9\u3067\u3059\u3002\u5b9f\u88c5\u3092\u30b7\u30f3\u30d7\u30eb\u306b\u4fdd\u3064\u305f\u3081\u3001\u5358\u4e00\u306e GPU \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306e\u307f\u304c\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u306a\u3093\u3068\u304b\u7e2e\u5c0f\u3057\u3066\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30eb\u30fc\u30d7\u3092\u542b\u3081\u3066 500 \u884c\u672a\u6e80\u306e\u30b3\u30fc\u30c9\u306b\u6291\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3057\u305f</em></p>\u3002\n<p><em>DDP (\u5206\u6563\u30c7\u30fc\u30bf\u4e26\u5217) \u3068\u30de\u30eb\u30c1 GPU \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u304c\u306a\u3051\u308c\u3070\u3001\u5927\u304d\u306a\u89e3\u50cf\u5ea6 (128 \u4ee5\u4e0a) \u3067\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093\u3002</em></p><a href=\"https://github.com/lucidrains/stylegan2-pytorch\">fp16\u3068DDP\u3092\u4f7f\u3063\u305f\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b3\u30fc\u30c9\u304c\u5fc5\u8981\u306a\u5834\u5408\u306f\u3001lucidrains/stylegan2-pytorch\u3092\u898b\u3066\u304f\u3060\u3055\u3044\u3002</a>\n<p><a href=\"https://github.com/tkarras/progressive_growing_of_gans\">\u3053\u308c\u3092Celeba-HQ\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3057\u305f</a>\u3002\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u306e\u8aac\u660e\u306f\u3001<a href=\"https://forums.fast.ai/t/download-celeba-hq-dataset/45873/3\">fast.ai \u306e\u3053\u306e\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u306b\u3042\u308a\u307e\u3059</a>\u3002<a href=\"#dataset_path\"><span translate=no>_^_2_^_</span>\u753b\u50cf\u3092\u30d5\u30a9\u30eb\u30c0\u30fc\u306b\u4fdd\u5b58\u3057\u307e\u3059</a>\u3002</p>\n",
 "<h2>Configurations</h2>\n": "<h2>\u30b3\u30f3\u30d5\u30a3\u30ae\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3</h2>\n",
 "<h2>Dataset</h2>\n<p>This loads the training dataset and resize it to the give image size.</p>\n": "<h2>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8</h2>\n<p>\u3053\u308c\u306b\u3088\u308a\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u8aad\u307f\u8fbc\u307e\u308c\u3001\u6307\u5b9a\u3055\u308c\u305f\u753b\u50cf\u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\u3055\u308c\u307e\u3059\u3002</p>\n",
 "<h2>Train model</h2>\n": "<h2>\u9244\u9053\u6a21\u578b</h2>\n",
 "<h3>Generate images</h3>\n<p>This generate images using the generator</p>\n": "<h3>\u753b\u50cf\u3092\u751f\u6210</h3>\n<p>\u3053\u308c\u306b\u3088\u308a\u3001\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u753b\u50cf\u304c\u751f\u6210\u3055\u308c\u307e\u3059</p>\n",
 "<h3>Generate noise</h3>\n<p>This generates noise for each <a href=\"index.html#generator_block\">generator block</a></p>\n": "<h3>\u30ce\u30a4\u30ba\u3092\u751f\u6210</h3>\n<p>\u3053\u308c\u306b\u3088\u308a\u3001<a href=\"index.html#generator_block\">\u5404\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30d6\u30ed\u30c3\u30af\u306b\u30ce\u30a4\u30ba\u304c\u751f\u6210\u3055\u308c\u307e\u3059</a>\u3002</p>\n",
 "<h3>Initialize</h3>\n": "<h3>[\u521d\u671f\u5316]</h3>\n",
 "<h3>Lazy regularization</h3>\n<p>Instead of calculating the regularization losses, the paper proposes lazy regularization where the regularization terms are calculated once in a while. This improves the training efficiency a lot. </p>\n": "<h3>\u30ec\u30a4\u30b8\u30fc\u30fb\u30ec\u30ae\u30e5\u30e9\u30e9\u30a4\u30bc\u30fc\u30b7\u30e7\u30f3</h3>\n<p>\u3053\u306e\u8ad6\u6587\u3067\u306f\u3001\u6b63\u5247\u5316\u640d\u5931\u3092\u8a08\u7b97\u3059\u308b\u4ee3\u308f\u308a\u306b\u3001\u6b63\u898f\u5316\u9805\u3092\u305f\u307e\u306b\u8a08\u7b97\u3059\u308b\u9045\u5ef6\u6b63\u5247\u5316\u3092\u63d0\u6848\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306e\u52b9\u7387\u304c\u5927\u5e45\u306b\u5411\u4e0a\u3057\u307e\u3059\u3002</p>\n",
 "<h3>Sample <span translate=no>_^_0_^_</span></h3>\n<p>This samples <span translate=no>_^_1_^_</span> randomly and get <span translate=no>_^_2_^_</span> from the mapping network.</p>\n<p>We also apply style mixing sometimes where we generate two latent variables <span translate=no>_^_3_^_</span> and <span translate=no>_^_4_^_</span> and get corresponding <span translate=no>_^_5_^_</span> and <span translate=no>_^_6_^_</span>. Then we randomly sample a cross-over point and apply <span translate=no>_^_7_^_</span> to the generator blocks before the cross-over point and <span translate=no>_^_8_^_</span> to the blocks after.</p>\n": "<h3>[\u30b5\u30f3\u30d7\u30eb] <span translate=no>_^_0_^_</span></h3>\n<p><span translate=no>_^_1_^_</span>\u3053\u308c\u306f\u30e9\u30f3\u30c0\u30e0\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u3001<span translate=no>_^_2_^_</span>\u30de\u30c3\u30d4\u30f3\u30b0\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304b\u3089\u53d6\u5f97\u3055\u308c\u307e\u3059\u3002</p>\n<p>\u307e\u305f\u3001\u30b9\u30bf\u30a4\u30eb\u30df\u30ad\u30b7\u30f3\u30b0\u3092\u9069\u7528\u3057\u3066\u3001<span translate=no>_^_3_^_</span> 2\u3064\u306e\u6f5c\u5728\u5909\u6570\u3068\u3092\u751f\u6210\u3057\u3001<span translate=no>_^_4_^_</span><span translate=no>_^_5_^_</span><span translate=no>_^_6_^_</span>\u5bfe\u5fdc\u3059\u308b\u304a\u3088\u3073\u3092\u53d6\u5f97\u3059\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\u6b21\u306b\u3001\u30af\u30ed\u30b9\u30aa\u30fc\u30d0\u30fc\u30dd\u30a4\u30f3\u30c8\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3001<span translate=no>_^_7_^_</span>\u30af\u30ed\u30b9\u30aa\u30fc\u30d0\u30fc\u30dd\u30a4\u30f3\u30c8\u306e\u524d\u306e\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30fc\u30d6\u30ed\u30c3\u30af\u3068\u30af\u30ed\u30b9\u30aa\u30fc\u30d0\u30fc\u30dd\u30a4\u30f3\u30c8\u5f8c\u306e\u30d6\u30ed\u30c3\u30af\u306b\u9069\u7528\u3057\u307e\u3059</p>\u3002<span translate=no>_^_8_^_</span>\n",
 "<h3>Train StyleGAN2</h3>\n": "<h3>\u30c8\u30ec\u30a4\u30f3\u30b9\u30bf\u30a4\u30eb\u30ac\u30f32</h3>\n",
 "<h3>Training Step</h3>\n": "<h3>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b9\u30c6\u30c3\u30d7</h3>\n",
 "<p> </p>\n": "<p></p>\n",
 "<p><a href=\"index.html#discriminator\">StyleGAN2 Discriminator</a> </p>\n": "<p><a href=\"index.html#discriminator\">\u30b9\u30bf\u30a4\u30eb GAN2 \u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc</a></p>\n",
 "<p><a href=\"index.html#generator\">StyleGAN2 Generator</a> </p>\n": "<p><a href=\"index.html#generator\">\u30b9\u30bf\u30a4\u30eb GAN2 \u30b8\u30a7\u30cd\u30ec\u30fc\u30bf</a></p>\n",
 "<p><a href=\"index.html#gradient_penalty\">Gradient Penalty Regularization Loss</a> </p>\n": "<p><a href=\"index.html#gradient_penalty\">\u52fe\u914d\u30da\u30ca\u30eb\u30c6\u30a3\u6b63\u5247\u5316\u640d\u5931</a></p>\n",
 "<p><a href=\"index.html#mapping_network\">Mapping network</a> </p>\n": "<p><a href=\"index.html#mapping_network\">\u30de\u30c3\u30d4\u30f3\u30b0\u30cd\u30c3\u30c8\u30ef\u30fc\u30af</a></p>\n",
 "<p><a href=\"index.html#path_length_penalty\">Path length penalty</a> </p>\n": "<p><a href=\"index.html#path_length_penalty\">\u7d4c\u8def\u9577\u30da\u30ca\u30eb\u30c6\u30a3</a></p>\n",
 "<p><a id=\"dataset_path\"></a> We trained this on <a href=\"https://github.com/tkarras/progressive_growing_of_gans\">CelebA-HQ dataset</a>. You can find the download instruction in this <a href=\"https://forums.fast.ai/t/download-celeba-hq-dataset/45873/3\">discussion on fast.ai</a>. Save the images inside <span translate=no>_^_0_^_</span> folder. </p>\n": "<p><a id=\"dataset_path\"></a><a href=\"https://github.com/tkarras/progressive_growing_of_gans\">\u3053\u308c\u3092Celeba-HQ\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3057\u305f</a>\u3002\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u306e\u8aac\u660e\u306f\u3001<a href=\"https://forums.fast.ai/t/download-celeba-hq-dataset/45873/3\">fast.ai \u306e\u3053\u306e\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u306b\u3042\u308a\u307e\u3059</a>\u3002<span translate=no>_^_0_^_</span>\u753b\u50cf\u3092\u30d5\u30a9\u30eb\u30c0\u30fc\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002</p>\n",
 "<p><span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> for Adam optimizer </p>\n": "<p><span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u305d\u3057\u3066\u30a2\u30c0\u30e0\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306e\u5834\u5408</p>\n",
 "<p><span translate=no>_^_0_^_</span> of image resolution </p>\n": "<p><span translate=no>_^_0_^_</span>\u753b\u50cf\u89e3\u50cf\u5ea6\u306e</p>\n",
 "<p>Accumulate gradients for <span translate=no>_^_0_^_</span> </p>\n": "<p>\u306e\u52fe\u914d\u3092\u7d2f\u7a4d <span translate=no>_^_0_^_</span></p>\n",
 "<p>Add gradient penalty </p>\n": "<p>\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3\u30da\u30ca\u30eb\u30c6\u30a3\u3092\u8ffd\u52a0</p>\n",
 "<p>Add model hooks to monitor layer outputs </p>\n": "<p>\u30e2\u30cb\u30bf\u30fc\u30ec\u30a4\u30e4\u30fc\u51fa\u529b\u3078\u306e\u30e2\u30c7\u30eb\u30d5\u30c3\u30af\u306e\u8ffd\u52a0</p>\n",
 "<p>Add noise tensors to the list </p>\n": "<p>\u30ce\u30a4\u30ba\u30c6\u30f3\u30bd\u30eb\u3092\u30ea\u30b9\u30c8\u306b\u8ffd\u52a0</p>\n",
 "<p>Add path length penalty </p>\n": "<p>\u30d1\u30b9\u9577\u30da\u30ca\u30eb\u30c6\u30a3\u3092\u8ffd\u52a0</p>\n",
 "<p>Batch size </p>\n": "<p>\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba</p>\n",
 "<p>Calculate and log gradient penalty </p>\n": "<p>\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3\u30da\u30ca\u30eb\u30c6\u30a3\u306e\u8a08\u7b97\u3068\u8a18\u9332</p>\n",
 "<p>Calculate gradients </p>\n": "<p>\u52fe\u914d\u306e\u8a08\u7b97</p>\n",
 "<p>Calculate path length penalty </p>\n": "<p>\u7d4c\u8def\u9577\u30da\u30ca\u30eb\u30c6\u30a3\u306e\u8a08\u7b97</p>\n",
 "<p>Clip gradients for stabilization </p>\n": "<p>\u5b89\u5b9a\u5316\u306e\u305f\u3081\u306e\u30af\u30ea\u30c3\u30d7\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3</p>\n",
 "<p>Compute gradients </p>\n": "<p>\u52fe\u914d\u306e\u8a08\u7b97</p>\n",
 "<p>Continuous <a href=\"../../utils.html#cycle_dataloader\">cyclic loader</a> </p>\n": "<p><a href=\"../../utils.html#cycle_dataloader\">\u9023\u7d9a\u30b5\u30a4\u30af\u30eb\u30ed\u30fc\u30c0\u30fc</a></p>\n",
 "<p>Convert to PyTorch tensor </p>\n": "<p>PyTorch \u30c6\u30f3\u30bd\u30eb\u306b\u5909\u63db</p>\n",
 "<p>Create an experiment </p>\n": "<p>\u30c6\u30b9\u30c8\u3092\u4f5c\u6210</p>\n",
 "<p>Create configurations object </p>\n": "<p>\u8a2d\u5b9a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u4f5c\u6210</p>\n",
 "<p>Create data loader </p>\n": "<p>\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306e\u4f5c\u6210</p>\n",
 "<p>Create dataset </p>\n": "<p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4f5c\u6210</p>\n",
 "<p>Create discriminator and generator </p>\n": "<p>\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u3068\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30fc\u306e\u4f5c\u6210</p>\n",
 "<p>Create mapping network </p>\n": "<p>\u30de\u30c3\u30d4\u30f3\u30b0\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u4f5c\u6210</p>\n",
 "<p>Create optimizers </p>\n": "<p>\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306e\u4f5c\u6210</p>\n",
 "<p>Create path length penalty loss </p>\n": "<p>\u30d1\u30b9\u9577\u306e\u30da\u30ca\u30eb\u30c6\u30a3\u30ed\u30b9\u3092\u4f5c\u6210</p>\n",
 "<p>Data loader </p>\n": "<p>\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc</p>\n",
 "<p>Device to train the model on. <a href=\"https://docs.labml.ai/api/helpers.html#labml_helpers.device.DeviceConfigs\"><span translate=no>_^_0_^_</span></a>  picks up an available CUDA device or defaults to CPU. </p>\n": "<p>\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u30c7\u30d0\u30a4\u30b9\u3002<a href=\"https://docs.labml.ai/api/helpers.html#labml_helpers.device.DeviceConfigs\"><span translate=no>_^_0_^_</span></a>\u4f7f\u7528\u53ef\u80fd\u306a CUDA \u30c7\u30d0\u30a4\u30b9\u3092\u9078\u629e\u3059\u308b\u304b\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067 CPU \u306b\u8a2d\u5b9a\u3057\u307e\u3059</p>\u3002\n",
 "<p>Dimensionality of <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> </p>\n": "<p>\u3068\u306e\u6b21\u5143 <span translate=no>_^_0_^_</span> <span translate=no>_^_1_^_</span></p>\n",
 "<p>Discriminator and generator loss functions. We use <a href=\"../wasserstein/index.html\">Wasserstein loss</a> </p>\n": "<p>\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u3068\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u306e\u640d\u5931\u95a2\u6570<a href=\"../wasserstein/index.html\">\u30ef\u30c3\u30b5\u30fc\u30b7\u30e5\u30bf\u30a4\u30f3\u30ed\u30b9\u3092\u4f7f\u3044\u307e\u3059</a></p>\n",
 "<p>Discriminator and generator losses </p>\n": "<p>\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u3068\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u306e\u640d\u5931</p>\n",
 "<p>Discriminator classification for generated images </p>\n": "<p>\u751f\u6210\u3055\u308c\u305f\u753b\u50cf\u306e\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u5206\u985e</p>\n",
 "<p>Discriminator classification for real images </p>\n": "<p>\u5b9f\u753b\u50cf\u306e\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u5206\u985e</p>\n",
 "<p>Expand <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> for the generator blocks and concatenate </p>\n": "<p><span translate=no>_^_0_^_</span><span translate=no>_^_1_^_</span>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30d6\u30ed\u30c3\u30af\u3092\u62e1\u5f35\u3057\u3066\u9023\u7d50\u3059\u308b</p>\n",
 "<p>Expand <span translate=no>_^_0_^_</span> for the generator blocks </p>\n": "<p><span translate=no>_^_0_^_</span>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30d6\u30ed\u30c3\u30af\u7528\u306b\u62e1\u5f35</p>\n",
 "<p>Flush tracker </p>\n": "<p>\u30d5\u30e9\u30c3\u30b7\u30e5\u30c8\u30e9\u30c3\u30ab\u30fc</p>\n",
 "<p>Generate images </p>\n": "<p>\u753b\u50cf\u3092\u751f\u6210</p>\n",
 "<p>Generate noise for each generator block </p>\n": "<p>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30d6\u30ed\u30c3\u30af\u3054\u3068\u306b\u30ce\u30a4\u30ba\u3092\u751f\u6210</p>\n",
 "<p>Generate noise to add after the first convolution layer </p>\n": "<p>\u30ce\u30a4\u30ba\u3092\u751f\u6210\u3057\u3066\u6700\u521d\u306e\u30b3\u30f3\u30dc\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u5c64\u306e\u5f8c\u306b\u8ffd\u52a0\u3057\u307e\u3059</p>\n",
 "<p>Generate noise to add after the second convolution layer </p>\n": "<p>\u30ce\u30a4\u30ba\u3092\u751f\u6210\u3057\u3066 2 \u756a\u76ee\u306e\u30b3\u30f3\u30dc\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u5c64\u306e\u5f8c\u306b\u8ffd\u52a0\u3057\u307e\u3059</p>\n",
 "<p>Generator &amp; Discriminator learning rate </p>\n": "<p>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30fc\u3068\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u306e\u5b66\u7fd2\u7387</p>\n",
 "<p>Get <span translate=no>_^_0_^_</span> </p>\n": "<p>\u53d6\u5f97 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Get <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span>\u53d6\u5f97\u3057\u3066 <span translate=no>_^_1_^_</span></p>\n",
 "<p>Get discriminator loss </p>\n": "<p>\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u640d\u5931\u3092\u53d6\u5f97</p>\n",
 "<p>Get generator loss </p>\n": "<p>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30ed\u30b9\u3092\u53d6\u5f97</p>\n",
 "<p>Get noise </p>\n": "<p>\u30ce\u30a4\u30ba\u304c\u51fa\u308b</p>\n",
 "<p>Get number of generator blocks for creating style and noise inputs </p>\n": "<p>\u30b9\u30bf\u30a4\u30eb\u5165\u529b\u3068\u30ce\u30a4\u30ba\u5165\u529b\u3092\u4f5c\u6210\u3059\u308b\u305f\u3081\u306e\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30d6\u30ed\u30c3\u30af\u306e\u6570\u3092\u53d6\u5f97</p>\n",
 "<p>Get real images from the data loader </p>\n": "<p>\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u5b9f\u969b\u306e\u753b\u50cf\u3092\u53d6\u5f97</p>\n",
 "<p>Get the paths of all <span translate=no>_^_0_^_</span> files </p>\n": "<p><span translate=no>_^_0_^_</span>\u3059\u3079\u3066\u306e\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u53d6\u5f97</p>\n",
 "<p>Get the the <span translate=no>_^_0_^_</span>-th image </p>\n": "<p><span translate=no>_^_0_^_</span>-\u756a\u76ee\u306e\u753b\u50cf\u3092\u53d6\u5f97</p>\n",
 "<p>Gradient penalty coefficient <span translate=no>_^_0_^_</span> </p>\n": "<p>\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3\u30da\u30ca\u30eb\u30c6\u30a3\u4fc2\u6570 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Height/width of the image </p>\n": "<p>\u753b\u50cf\u306e\u9ad8\u3055/\u5e45</p>\n",
 "<p>How often to log generated images </p>\n": "<p>\u751f\u6210\u3055\u308c\u305f\u753b\u50cf\u3092\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b\u983b\u5ea6</p>\n",
 "<p>How often to save model checkpoints </p>\n": "<p>\u30e2\u30c7\u30eb\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u3092\u4fdd\u5b58\u3059\u308b\u983b\u5ea6</p>\n",
 "<p>Ignore if <span translate=no>_^_0_^_</span> </p>\n": "<p>\u6b21\u306e\u5834\u5408\u306f\u7121\u8996 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Initialize </p>\n": "<p>[\u521d\u671f\u5316]</p>\n",
 "<p>List to store noise </p>\n": "<p>\u30ce\u30a4\u30ba\u3092\u4fdd\u5b58\u3059\u308b\u30ea\u30b9\u30c8</p>\n",
 "<p>Log discriminator loss </p>\n": "<p>\u30ed\u30b0\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u640d\u5931</p>\n",
 "<p>Log discriminator model parameters occasionally </p>\n": "<p>\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u30e2\u30c7\u30eb\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u6642\u3005\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b</p>\n",
 "<p>Log generated images </p>\n": "<p>\u751f\u6210\u3055\u308c\u305f\u753b\u50cf\u3092\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b</p>\n",
 "<p>Log generator loss </p>\n": "<p>\u30ed\u30b0\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u306e\u640d\u5931</p>\n",
 "<p>Loop for <span translate=no>_^_0_^_</span> </p>\n": "<p>\u30eb\u30fc\u30d7\u7528 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Mapping network learning rate (<span translate=no>_^_0_^_</span> lower than the others) </p>\n": "<p>\u30de\u30c3\u30d4\u30f3\u30b0\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\u7387 (<span translate=no>_^_0_^_</span>\u4ed6\u3088\u308a\u3082\u4f4e\u3044)</p>\n",
 "<p>Mix styles </p>\n": "<p>\u30df\u30c3\u30af\u30b9\u30b9\u30bf\u30a4\u30eb</p>\n",
 "<p>Multiply by coefficient and add gradient penalty </p>\n": "<p>\u4fc2\u6570\u3092\u639b\u3051\u3066\u52fe\u914d\u30da\u30ca\u30eb\u30c6\u30a3\u3092\u52a0\u3048\u308b</p>\n",
 "<p>Next block has <span translate=no>_^_0_^_</span> resolution </p>\n": "<p><span translate=no>_^_0_^_</span>\u6b21\u306e\u30d6\u30ed\u30c3\u30af\u306b\u306f\u89e3\u50cf\u5ea6\u304c\u3042\u308a\u307e\u3059</p>\n",
 "<p>Noise resolution starts from <span translate=no>_^_0_^_</span> </p>\n": "<p>\u30ce\u30a4\u30ba\u5206\u89e3\u80fd\u306f\u6b21\u304b\u3089\u59cb\u307e\u308a\u307e\u3059 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Number of blocks in the generator (calculated based on image resolution) </p>\n": "<p>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u5185\u306e\u30d6\u30ed\u30c3\u30af\u6570 (\u753b\u50cf\u306e\u89e3\u50cf\u5ea6\u306b\u57fa\u3065\u3044\u3066\u8a08\u7b97)</p>\n",
 "<p>Number of images </p>\n": "<p>\u753b\u50cf\u6570</p>\n",
 "<p>Number of layers in the mapping network </p>\n": "<p>\u30de\u30c3\u30d4\u30f3\u30b0\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30ec\u30a4\u30e4\u30fc\u6570</p>\n",
 "<p>Number of steps to accumulate gradients on. Use this to increase the effective batch size. </p>\n": "<p>\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u84c4\u7a4d\u3059\u308b\u30b9\u30c6\u30c3\u30d7\u306e\u6570\u3002\u3053\u308c\u3092\u4f7f\u3063\u3066\u6709\u52b9\u306a\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u5897\u3084\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>\n",
 "<p>Optimizers </p>\n": "<p>\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc</p>\n",
 "<p>Path length penalty calculation interval </p>\n": "<p>\u30d1\u30b9\u9577\u30da\u30ca\u30eb\u30c6\u30a3\u8a08\u7b97\u9593\u9694</p>\n",
 "<p>Probability of mixing styles </p>\n": "<p>\u30b9\u30bf\u30a4\u30eb\u304c\u6df7\u5728\u3059\u308b\u78ba\u7387</p>\n",
 "<p>Random cross-over point </p>\n": "<p>\u30e9\u30f3\u30c0\u30e0\u30af\u30ed\u30b9\u30aa\u30fc\u30d0\u30fc\u30dd\u30a4\u30f3\u30c8</p>\n",
 "<p>Reset gradients </p>\n": "<p>\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u30ea\u30bb\u30c3\u30c8</p>\n",
 "<p>Resize the image </p>\n": "<p>\u753b\u50cf\u306e\u30b5\u30a4\u30ba\u3092\u5909\u66f4</p>\n",
 "<p>Return images and <span translate=no>_^_0_^_</span> </p>\n": "<p>\u753b\u50cf\u3092\u8fd4\u3059\u3068 <span translate=no>_^_0_^_</span></p>\n",
 "<p>Return noise tensors </p>\n": "<p>\u30ea\u30bf\u30fc\u30f3\u30fb\u30ce\u30a4\u30ba\u30fb\u30c6\u30f3\u30bd\u30eb</p>\n",
 "<p>Run the training loop </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30eb\u30fc\u30d7\u3092\u5b9f\u884c\u3059\u308b</p>\n",
 "<p>Sample <span translate=no>_^_0_^_</span> and <span translate=no>_^_1_^_</span> </p>\n": "<p><span translate=no>_^_0_^_</span>\u30b5\u30f3\u30d7\u30eb\u3068 <span translate=no>_^_1_^_</span></p>\n",
 "<p>Sample images from generator </p>\n": "<p>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u304b\u3089\u306e\u30b5\u30f3\u30d7\u30eb\u753b\u50cf</p>\n",
 "<p>Save model checkpoints </p>\n": "<p>\u30e2\u30c7\u30eb\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u306e\u4fdd\u5b58</p>\n",
 "<p>Set configurations and override some </p>\n": "<p>\u69cb\u6210\u3092\u8a2d\u5b9a\u3057\u3001\u4e00\u90e8\u3092\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3059\u308b</p>\n",
 "<p>Set models for saving and loading </p>\n": "<p>\u4fdd\u5b58\u304a\u3088\u3073\u8aad\u307f\u8fbc\u307f\u7528\u306e\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\u3059\u308b</p>\n",
 "<p>Set tracker configurations </p>\n": "<p>\u30c8\u30e9\u30c3\u30ab\u30fc\u69cb\u6210\u3092\u8a2d\u5b9a</p>\n",
 "<p>Skip calculating path length penalty during the initial phase of training </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306e\u521d\u671f\u6bb5\u968e\u3067\u306f\u3001\u7d4c\u8def\u9577\u306e\u30da\u30ca\u30eb\u30c6\u30a3\u306e\u8a08\u7b97\u3092\u7701\u7565</p>\n",
 "<p>Start the experiment </p>\n": "<p>\u5b9f\u9a13\u3092\u59cb\u3081\u308b</p>\n",
 "<p>Take a training step </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306e\u4e00\u6b69\u3092\u8e0f\u307f\u51fa\u3059</p>\n",
 "<p>Take optimizer step </p>\n": "<p>\u6700\u9069\u5316\u306e\u4e00\u6b69\u3092\u8e0f\u307f\u51fa\u3059</p>\n",
 "<p>The first block has only one <span translate=no>_^_0_^_</span> convolution </p>\n": "<p>\u6700\u521d\u306e\u30d6\u30ed\u30c3\u30af\u306b\u306f\u7573\u307f\u8fbc\u307f\u304c 1 <span translate=no>_^_0_^_</span> \u3064\u3057\u304b\u3042\u308a\u307e\u305b\u3093</p>\n",
 "<p>The interval at which to compute gradient penalty </p>\n": "<p>\u30b0\u30e9\u30c7\u30fc\u30b7\u30e7\u30f3\u30da\u30ca\u30eb\u30c6\u30a3\u3092\u8a08\u7b97\u3059\u308b\u9593\u9694</p>\n",
 "<p>Total number of training steps </p>\n": "<p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b9\u30c6\u30c3\u30d7\u306e\u7dcf\u6570</p>\n",
 "<p>Train the discriminator </p>\n": "<p>\u30c7\u30a3\u30b9\u30af\u30ea\u30df\u30cd\u30fc\u30bf\u30fc\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0</p>\n",
 "<p>Train the generator </p>\n": "<p>\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0</p>\n",
 "<p>Training mode state for logging activations </p>\n": "<p>\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30b7\u30e7\u30f3\u3092\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b\u305f\u3081\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30e2\u30fc\u30c9\u72b6\u614b</p>\n",
 "<p>Transformation </p>\n": "<p>\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30e1\u30fc\u30b7\u30e7\u30f3</p>\n",
 "<p>Update <span translate=no>_^_0_^_</span>. Set whether to log activation </p>\n": "<p>[\u66f4\u65b0] <span translate=no>_^_0_^_</span>\u3002\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30b7\u30e7\u30f3\u3092\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u8a2d\u5b9a</p>\n",
 "<p>We need to calculate gradients w.r.t. real images for gradient penalty </p>\n": "<p>\u52fe\u914d\u30da\u30ca\u30eb\u30c6\u30a3\u306e\u305f\u3081\u306b\u306f\u3001\u5b9f\u969b\u306e\u753b\u50cf\u306b\u5bfe\u3057\u3066\u52fe\u914d\u3092\u8a08\u7b97\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059</p>\n",
 "<p>Whether to log model layer outputs </p>\n": "<p>\u30e2\u30c7\u30eb\u30ec\u30a4\u30e4\u30fc\u306e\u51fa\u529b\u3092\u30ed\u30b0\u306b\u8a18\u9332\u3059\u308b\u304b\u3069\u3046\u304b</p>\n",
 "<p>Without mixing </p>\n": "<p>\u6df7\u5408\u305b\u305a\u306b</p>\n",
 "<ul><li><span translate=no>_^_0_^_</span> path to the folder containing the images </li>\n<li><span translate=no>_^_1_^_</span> size of the image</li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>\u753b\u50cf\u3092\u542b\u3080\u30d5\u30a9\u30eb\u30c0\u30fc\u3078\u306e\u30d1\u30b9</li>\n<li><span translate=no>_^_1_^_</span>\u753b\u50cf\u306e\u30b5\u30a4\u30ba</li></ul>\n",
 "An annotated PyTorch implementation of StyleGAN2 model training code.": "StyleGAN2 \u30e2\u30c7\u30eb\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b3\u30fc\u30c9\u306e\u6ce8\u91c8\u4ed8\u304d PyTorch \u5b9f\u88c5\u3002",
 "StyleGAN 2 Model Training": "\u30b9\u30bf\u30a4\u30eb\u30ac\u30f3 2 \u30e2\u30c7\u30eb\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0"
}